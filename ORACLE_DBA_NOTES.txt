ðŸ“ŒORACLE 19C ARCHITECTURE
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ BLOCK DIAGRAM +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
												   _______________________________________________________
												  |                                                       |
							User Process		  |						  {INSTANCE}		              |
								|				  | _____________________________________________________ |
						        â–¼        		  ||                        SGA                          ||
						   Server Process ----->  ||                                                     ||
								[PGA]			  ||  Shared Pool           DB Buffer       Redo Log     ||                           
												  ||  |                       Cache         Buffer Cache ||
								                  ||  |->Library Cache                                   ||                 
												  ||  |                                                  ||    
												  ||  |->Data Dictionary                                 ||                   
												  ||     Cache                                           ||           
												  ||_____________________________________________________||                                                      
												  |                                                       |
												  |                 {BACKGROUND PROCESSES}                |
												  |      |      |       |     |      |      |       |     |
												  |    PMON   SMON    DBWR   LGWR   CKPT   ARCH   OTHERS  |												    
												  |_______________________________________________________|														    
								[PARAMETER FILE]					|			   â–²
																	â–¼              |
								 [PASSWORD FILE]  -----------------------------------------------  ---------	
												 | [Data Files] [Control Files] [Redo Log Files]| |Archived |
												 | [          ] [             ] [              ]| |   Log   |
												 | [          ]        ðŸ—„ï¸{DATA BASE}            | |  Files  |
												  -----------------------------------------------  ---------                                                      

1) ðŸ“ŒSGA(System Global Area)
   ++++++++++++++++++++++
	=> Whenever user says he wants to perform any query on DB, at that time he cannot directly access DB, the user query passes via DB Instance to the DB. But for that the 
	DB Instance must have some memory to process that instructions to DB, that memory is called SGA(System Global Area). DB Instance ---2 parts--->1)Memory 2)Background Processes
	Background processes are the processes which help to fetch data from DB to DB instance and displaying them to user, etc.
	
																			 SGA
														--------------------------------------------
														|					  |                    |	
												  Shared Pool           DB Buffer Cache       Redo Log Buffer
												 |           |
											  Library	 Data Dictionary
											   Cache        Cache
											   
	>âœ…SHARED POOL
	------------
	i)Library Cache:- Whenever a user connects DB and tries to run a query on DB, at that time oracle Optimizer creates different execution plans to execute that query on basis 
	of statistics(which has info of everything), so now whichever plan has low cost(i.e fast speed to execute that query) is selected by oracle to execute that query, this 
	process is called Cost Based Optimization(CBO). Now if user2 comes and tries to run same query then oracle Optimizer will first go to [Library Cache] and check whether any 
	plan is registered against this query or not, if registered than it will refer that plan from Library Cache and implement it, but now output will be more faster.
	
	ii)Data Dictionary Cache:- All our meta data tables(v$database, v$parameter, v$controlfile, dba_user, dba_profiles, dba_sys_privs, dba_tab_privs, dba_tablespace etc) data 
	is present in Data Dictionary Cache to improve performance.
	
	
	>âœ…DB Buffer Cache
	----------------
	It is temporary memory, whenever a query is fired the optimizer will first look for the output in the temporary memory i.e DB Buffer Cache if not then it will look into
	the DB Data Files fetch the data & copy it inside DB Buffer Cache with help of background process and then show to user(not directly). But after sometime the DB Buffer Cache
	gets full, so now oracle follows an algorithm called as LRU(List Recently Used) to remove the data present in DB Buffer Cache which is present from long time & not used 
	frequently.
	
	
	>âœ…Redo Log Buffer
	----------------
	If user1 writes one query to update the salary from Rs 1000 to 2000, first the data of Rs 1000 will be copied from the DB Data Files to DB Buffer Cache, now due to update 
	query the salary block of rs 1000 sent by DB Data Files by processes to DB Buffer Cache will be updated to Rs 2000 in temporary memory(DB Buffer Cache) now this 
	updated block is called Dirty Block. Now the previous salary of Rs 1000 will be stored inside UNDO Block. Now whatever query transaction we perform are stored inside 
	Redo Log Buffer. Now if you hit COMMIT to save the transaction, the data will be copied from Redo Log Buffer to Redo Log Files with help of LGWR(Log Writer). Now after
	this the final stage i.e the Dirty Block data of Rs 2000 will be permanently copied to DB Data Files with help of DBWR(Database Writer).
	
	{âš ï¸Note 1:- If you hit ROLLBACK instead of COMMIT then the data from UNDO BLOCK will be coppied to Dirty Block and further to DB Data Files with help of DBWR.}
	{âš ï¸Note 2:- DB Data Files & Redo Log Files both can store un-committed data but while displaying DB Data Files will only show committed data with help of background 
			  proccess known as CKPT(Check Point) and after sometime the un-committed data gets flushed.}
	
	
	*âœ…PMON(Process Monitor):- 
	======= 
	Its main role is to monitor and manage server processes and clean up after failed or terminated processes.
	
	*âœ…CKPT(Checkpoint):- 
	=================
	Oracle stores the SCN (System Change Number) of the most recent committed transactions in the Control File, which is a small binary file that maintains critical 
	database metadata. During database startup, the CKPT (Checkpoint Process) compares the SCN stored in the Control File with the SCN stored in the headers of Data Files.
	If the SCNs match, it means all committed transactions have been successfully written from the Redo Log Buffer into the Data Files, and the database is in a consistent state.
	It can open normally. If the SCNs do not match, it means some committed changes are still in the Redo Logs but not yet reflected in the Data Files. This may happen if the 
	database was shut down abnormally (e.g., crash). In such a case, the database enters the recovery phase. The SMON (System Monitor Process) reads the Redo Logs and applies all
	necessary changes to bring the Data Files up to date with the committed transactions. Once all changes are applied, and SCNs are aligned, the database becomes consistent and 
	is allowed to open normally.
	
	ðŸ’¡ Example:
	Letâ€™s say you committed some changes at SCN 1050000, and then a checkpoint writes SCN number in CONTROLFILE and DB HEADER and DBWR(Database Writer) writes all your dirty 
	blocks to disk. Now, the datafiles are safe up to SCN 1050000.

	If the DB crashes later:

	ðŸ”¸ Oracle starts media recovery from SCN 1050000.

	ðŸ”¸ It applies redo logs only for changes after that SCN.

	
	*âœ…SMON(System Monitor):- 
	=======        
	It is responsible to do instance recovery. It performs tasks like instance recovery at startup, cleaning up temporary segments, and recovering terminated 
	transactions when tablespaces or files are brought back online.
	
	When the database starts after an abnormal shutdown or crash, SMON:

	Reads the SCNs from control files and datafile headers.

	Identifies transactions recorded in the redo logs but not yet applied to datafiles.

	Applies those redo entries to bring the database to a consistent state.

	Once SMON completes recovery, the database can open normally.
			  
	
	+âœ…ARCHIVED LOG FILES:- 
	===================
		All this file archive process is done with help of a background process known as ARCH(ARCHIVER).

		Online Redo Logs: These are the current log files used to record changes made to the database. They are used to ensure data consistency and to allow for 
		                  recovery in case of failures. 
		
		Archived Redo Logs: When an online redo log group is filled, it's copied to an offline destination, creating an archived redo log file. These files are then used for various 
						    purposes, including recovery and point-in-time restoration.
							
		ðŸ”¸ A redo log group is a set of one or more redo log members (files) that Oracle treats as a unit.					
 					
		ðŸ”¸ When a group is being written, itâ€™s CURRENT.
		
		ðŸ”¸ After a log switch, the just-used group becomes ACTIVE (until its redo information is no longer needed).
		
		ðŸ”¸ Once the redo information is no longer needed (all changes are safely written and archived), the group becomes INACTIVE.
			
		ARCHIVELOG Mode: This mode ensures that archived redo log files are created, allowing for more comprehensive recovery options. 
			
		NOARCHIVELOG Mode: In this mode, online redo log groups are simply discarded after being filled, making point-in-time recovery impossible. 
		
		ðŸ”¸ Log switching :- is the event when Oracle stops writing to the current active redo log group and starts writing to the next one in a cyclic manner.

		This happens:
		
			When the current redo log group fills up.
		
			When the DBA manually forces a log switch (ALTER SYSTEM SWITCH LOGFILE).
		
			Log switching allows Oracle to cycle through redo log groups continuously.
		
2) ðŸ“ŒPGA(PROGRAM GLOBAL AREA)
   ++++++++++++++++++++++++
   => The Program Global Area (PGA) is a private memory region dedicated to a single session process, containing data and control information for that session.
	  More PGA = faster queries (if properly used), especially for:
		ðŸ”¹Large sorts
		ðŸ”¹Complex joins
		ðŸ”¹Aggregations
   PGA = personal counter (private, fast)

   SGA = shared pantry (used by everyone, for common stuff like caching)



   
3) ðŸ“ŒParameter file:- 
   ++++++++++++++++
   These are text files that contain initialization parameters and their corresponding values, defining the characteristics of the Oracle instance after starting the DB.
   
    1)âœ…SP File(spfileprim.ora):- Binary file.(SP file gets first preference after DB is started if this file is not there then P file is checked.)
	
    2)âœ…P File(initprim.ora):- Text file.
		 {âš ï¸Note :- If these two files are missing DB won't start.}
				ðŸ”¹SQL> show parameter spfile;
		
		NAME                                 TYPE        VALUE
		------------------------------------ ----------- ------------------------------
		spfile                               string      /data/app/oracle/product/19C/dbhome_3/dbs/spfileprim.ora
                                                 

	3)âœ…To check any parameter from spfile eg) open_cursor
		 
				ðŸ”¹SQL> show parameters open_cursors;
		
		NAME                                 TYPE        VALUE
		------------------------------------ ----------- ------------------------------
		open_cursors                         integer     300
		
	4)âœ…To update any parameter
		 
				ðŸ”¹SQL> alter system set open_cursors=400 scope=both;
				
				System altered.

			NAME                                 TYPE        VALUE
		------------------------------------ ----------- ------------------------------
		open_cursors                            integer     400
		 
		 
	5)âœ…There are 2 types of changes in parameters.
		 
		 i)Dynamic(Immediate)(we can write scope as both & spfile) ii)Static(Needs to Restart DB for changes to get reflected.)(always scope as spfile)
		 
		 If we want to change something from v$parameter and want to know whether it is Dynamic or Static.
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------		 
		 ðŸ”¹SQL> alter system set open_cursors=400 scope=both;-----------------> Dynamic parameters directly changes done in both memory as well as spfile.
				
				System altered.
		 
		 ðŸ”¹SQL> select name, ISSYS_MODIFIABLE from v$parameter where name='open_cursors';

		NAME
		--------------------------------------------------------------------------------
		ISSYS_MOD
		---------
		open_cursors
		IMMEDIATE ---------------> this means it is Dynamic no restart required.
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------		
		->Now we try parameter processes
		
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx.ðŸš«If we use scope as both for static file it won't allow and give ORA error as below.xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
		
		ðŸ”¹SQL> alter system set processes=400 scope=both;
		alter system set processes=400 scope=both
						*
		ERROR at line 1:
		ORA-02095: specified initialization parameter cannot be modified
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------		
		so we try changing scope from (both) to (spfile);
		
		ðŸ”¹SQL> alter system set processes=400 scope=spfile;------------------> Static parameters where only changes to spfile allowed, after restart changes visible to memory.
		
		System altered.
		
		ðŸ”¹SQL> select name, ISSYS_MODIFIABLE from v$parameter where name='processes';

		NAME
		--------------------------------------------------------------------------------
		ISSYS_MOD
		---------
		processes
		FALSE---------------> this means we need to restart the DB to reflect the changes.
		
	6) After doing changes to spfile we need to copy changes in pfile after doing DB Shutdown go to /data/app/oracle/product/19C/dbhome_3/dbs/initprim.ora cat in this file
	   initprim.ora and check, if changes not done then 
	   Go to SQL ---> 
	   ðŸ”¹SQL> create pfile from spfile;

			File created.
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
4) ðŸ“ŒPassword File :-
   ++++++++++++++++++

	i) It's a special file that stores hashed passwords for administrative users (like SYSDBA or SYSOPER).

	ii) It allows remote and local authentication of users who need privileged access to the database, even when the database is down or operating in restricted modes.

	iii) Normal user passwords are stored securely inside the database in hashed form, within system tables.

Password file is only for privileged users authentication (SYSDBA/SYSOPER), especially before the database is open.


5) ðŸ“ŒSCOPE:- used while alterring the parameters from spfile.
   ++++++++++
   3 Types:-
	i)spfile
	ii)memory(for that particular session)
	iii)both
		
		

6) ðŸ“ŒCONTROL FILE:- 
    ++++++++++++++++
	When DB is installed this file is automatically installed. It has information like DB-name, Data File location, System Change Number (SCN) of committed transactions, etc.
	(.ctl extension)
	ðŸ”¹SQL> select name from v$controlfile;
	
	NAME
	--------------------------------------------------------------------------------
	/data/app/oracle/oradata/PRIM/control01.ctl
	/data/app/oracle/oradata/PRIM/control02.ctl


spfile has location of --> Control File has location of --> Data file & Online Redo Log File.

=> To check DB FILES.

	ðŸ”¹SQL> select file_name from dba_data_files;
	
	FILE_NAME
	--------------------------------------------------------------------------------
	/data/app/oracle/oradata/PRIM/system01.dbf
	/data/app/oracle/oradata/PRIM/sysaux01.dbf
	/data/app/oracle/oradata/PRIM/undotbs01.dbf
	/data/app/oracle/oradata/PRIM/users01.dbf
	
	a) Control File Multiplexing:- In this case we create an extra control file for backup but on different location since all control files contain same data inside them 
								   to create new file we just have to copy the existing file into new control file. But before that we have to edit spfile and add location of
								   3rd spfile inside it.
								   {âš ï¸Note:- After creating path inside spfile, shutdown DB and only after that we can create new Control File}
								   
	1. ALTER SYSTEM SET CONTROL_FILES='/data/app/oracle/oradata/PRIM/control01.ctl','/data/app/oracle/oradata/PRIM/control02.ctl','/data/app/oracle/oradata/PRIM/control03.ctl' SCOPE=spfile;
	2. shutdown immediate.
	3. cp /data/app/oracle/oradata/PRIM/control01.ctl /data/app/oracle/oradata/PRIM/control03.ctl
	4. ðŸ”¹SQL> select name from v$controlfile;

		NAME
		--------------------------------------------------------------------------------
		/data/app/oracle/oradata/PRIM/control01.ctl
		/data/app/oracle/oradata/PRIM/control02.ctl
		/data/app/oracle/oradata/PRIM/control03.ctl


	The control file contains:
	Records of:
		ðŸ”¹Backup sets (datafile, control file, SPFILE, archived logs)
		ðŸ”¹Backup pieces (physical files on disk/tape)
		ðŸ”¹Backup history		
		ðŸ”¹Archived redo logs
		ðŸ”¹Datafile and tablespace info		
		ðŸ”¹Restore points		
		ðŸ”¹Checkpoints and SCNs


ðŸ“ŒComplete Example with User Processes, Server Processes, and Background Processes
	Scenario: 10 users connect to the database

	| Component                | Number/Size                           | Description                                                                                 |
	| ------------------------ | ------------------------------------- | ------------------------------------------------------------------------------------------- |
	| **User Processes**       | 10 (on client machines)               | Client-side processes sending requests to the DB.                                           |
	| **Server Processes**     | 10 (one per user session)             | Oracle server processes running SQL for each user.                                          |
	| **PGA**                  | 10 PGAs (one per server proc)         | Private memory for each server process (sorts, session state, etc.).                        |
	| **SGA**                  | 1 (shared among all server processes) | Shared memory area on DB server containing buffer cache, shared pool, redo log buffer, etc. |
	| **Background Processes** | Fixed number (e.g., LGWR, DBWR, SMON) | Oracle system processes running in background for DB management tasks.                      |
	
	How they interact:
	
	| Step                    | Explanation                                                                                     |
	| ----------------------- | ----------------------------------------------------------------------------------------------- |
	| 1. User Process         | Sends a SQL query from client machine.                                                          |
	| 2. Server Process       | Receives and executes the query. Uses its **PGA** for session memory (sorts, joins).            |
	| 3. Server Process       | Reads data from **SGA** (shared pool, buffer cache) or from disk if needed.                     |
	| 4. Background Processes | Manage writing dirty blocks to disk (DBWR), writing redo logs (LGWR), and other internal tasks. |
	| 5. Server Process       | Sends results back to User Process.



______________________________________________________________________________ðŸ“ŒSTARTUP SEQUENCE OF DB___________________________________________________________________________________________________

1) startup command.
2) After startup command DB needs spfile to start DB.
3) Then DB goes in (nomount state)(If DB is in "nomount state" then only DB Instance is started DB is not started.)
4) Now as soon as spfile gets location of Control File inside it, DB goes in (mount state).
5) Now as soon as Control File gets location of Data file & Online Redo Log File the DB goes in (open state) i,e read,write mode so all users now can to DB and perform DDL,DML operation on it.

=> Inside of startup command
1) startup nomount; (spfile)
2) alter database mount;
	ðŸ”¹SQL> select name,open_mode from v$database;
	
	NAME      OPEN_MODE
	--------- --------------------
	PRIM      MOUNTED

3) alter database open;
	ðŸ”¹SQL> select name,open_mode from v$database;
	
	NAME      OPEN_MODE
	--------- --------------------
	PRIM      READ WRITE
â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–

ðŸ“ŒMULTITENANT ARCHITECTURE

It is also known as CDB & PDB Architecture, introduced since 12c and compulsory from 21c.
Non CDB's don't have containers inside them, need to install another 19c or any version if two DB's are required.

Inside our DB "PRIM" there is a container called CDB(Container Database) known as "CDB$ROOT". Now inside this container there are Pluggable DB's known as PDB(Pluggable Database).
The version of this DB's is same as the DB version we downloaded i.e 19c. The applications will connected to their respective PDB's.

Advantages:-
------------
1) We can assign combine memory to the CDB itself so the PDB's inside it can share that memory(increases resource utilization).
2) For upgradation we just need to update the CDB itself, the PDB's inside it will be automatically upgraded.
3) Patching only to the CDB the PDB's inside it will be automatically patched.
4) Common Background processes for all the PDB's inside the CDB.
5) Easily Unplug and Plug the PDB's.
6) Licensing Cost is less compared to Non CDB.

Disadvantages:-
---------------
1) If container(CDB) is down then the PDB's will also be down.
______________________________
|            PRIM             |        
|  _________________________  |
| |           CDB           | |
| |                         | |
| | [PDB 1]        [PDB 2]  | |
| |_________________________| | 
|_____________________________|  
__________________________________________________________________________________________________________________________________________________________________________________
    ++++++++
----+ CDB:-+--ðŸ“Œ-------------------------------------------------------------------------------------------------------------------------------------------------------------------
    ++++++++

To check we are in which container.
	ðŸ”¹SQL> show con_name;
	
	Firstly, we are bydefault in CDB. 
	
	CON_NAME
	------------------------------
	CDB$ROOT
__________________________________________________________________________________________________________________________________________________________________________________

    ++++++++
----+ PDB:-+--ðŸ“Œ--------------------------------------------------------------------------------------------------------------------------------------------------------------------
    ++++++++

	ðŸ”¹SQL> show pdbs;

    CON_ID CON_NAME                       OPEN MODE  RESTRICTED
---------- ------------------------------ ---------- ----------
         2 PDB$SEED                       READ ONLY  NO
         3 PDBPRIM                        MOUNTED


In this "PDB$SEED" is automatically downloaded always in Read only mode, and "PDBPRIM" we have downloaded.

Now to go inside PDB.

	ðŸ”¹SQL> alter session set container=PDBPRIM;
	ðŸ”¹SQL> show con_name;
	
	CON_NAME
	------------------------------
	PDBPRIM

Now we are inside PDB (PDBPRIM).

now since we are inside PDB if we hit startup command we start PDB (PDBPRIM).
	ðŸ”¹SQL> startup
	Pluggable Database opened.

	ðŸ”¹SQL> show pdbs;
	
		CON_ID CON_NAME                       OPEN MODE  RESTRICTED
	---------- ------------------------------ ---------- ----------
			3 PDBPRIM                        READ WRITE NO
		 
Now we are in read/write mode we can run all operations.
now since we are inside PDB if we hit shutdown command we will close PDB (PDBPRIM).
ðŸ”¹SQL> shutdown immediate
Pluggable Database closed.

	ðŸ”¹SQL> alter session set container=CDB$ROOT; ---------------------->go back to CDB.
	
	Session altered.

Now we can add one more PDB by calling dbca in ORACLE_HOME path.
â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–


ðŸ“ŒUSER MANAGEMENT DBA

There are two types of user in container DB's.
{The metadata table to find info for all the users is "dba_users".}

1)Common User:- This user is present in the container(CDB) as well as all the PDB's inside it.
                eg:- "sys" user =>but this user is system generated user.
                If we want to make our own common user then the command is type=> create user C##username identified by password.
				
2)Local User:- This user is specific to that PDB itself.
               If we want to make our local user then the command is type=> create user username identified by password.
			   
  {âš ï¸Note:- You cannot create a local user inside container CDB}
  

===> âœ…Creating common user in CDB

		ðŸ”¹SQL> show con_name;
		
		CON_NAME
		------------------------------
		CDB$ROOT
		
		ðŸ”¹SQL> create user C##CDBUSER identified by CDBUSER;
		
		User created.

--> âœ…Now checking whether the user is created in PDB.

--> âœ…Now create user in PDBPRIM

		ðŸ”¹SQL> create user u1 identified by u1;
		
		
		
		User created.
		
		ðŸ”¹SQL> select username from dba_users where username='U1';
		
		USERNAME
		--------------------------------------------------------------------------------
		U1 -----------> Stored in Capital Letters

--> âœ…Now give create session permission to u1.

		ðŸ”¹SQL> show user;
		USER is "SYS"
		ðŸ”¹SQL>
		ðŸ”¹SQL> grant create session to u1;
		
		Grant succeeded.

--> âœ…To change the password of user u1 as u11.

		ðŸ”¹SQL> alter user u1 identified by u11;
		
		User altered.
		
		{âš ï¸Note:- All this tasks regarding the permissions and all of other users can be done using "sys" user only}

--> âœ…To check and change account status of the user.

		ðŸ”¹SQL> select username, account_status from dba_users where username='U1';
		
		USERNAME
		--------------------------------------------------------------------------------
		ACCOUNT_STATUS
		--------------------------------
		U1
		OPEN
		
		ðŸ”¹SQL> alter user u1 account lock;
		
		User altered.	
		
		ðŸ”¹SQL> alter user u1 account unlock;
		
		User altered.

--> âœ…To login with user type=> username/password@pdbname (eg:- u1/u1@pdbprim)

--> âœ…To expire password so that the user himself can set new password while logging in.

	1) By sysdba user 
		ðŸ”¹SQL> alter user u1 password expire;
	
		User altered.
		
	2) By u1 user
	
	[oracle@node1 admin]$ sqlplus u1/u1@pdbprim
	ERROR:
	ORA-28001: the password has expired

	Changing password for u1
	New password:
	Retype new password:
	Password changed


++++âœ… Tablespace++++
-------------------
Whenever a user is created we need to assign him 2 tablespaces.

	1)Default -"USERS" Tablespace is created by default while installing DB.         
	2)Temporary - "TEMP" Tablespace is created by default while installing DB.

CREATE USER myuser IDENTIFIED BY MyPassword123 DEFAULT TABLESPACE users TEMPORARY TABLESPACE temp PROFILE app_profile QUOTA 500M ON users;



==>ðŸ“ŒPROFILE
-----------
Consider a DB and it has lots of users in it. Generally the password of all the users is set/reset at same time generally reset after (90 days). So for eg the DB owner applies 
some set of policies to users like 1)the password should expire within 90 days, 2)after three invalid login the user has to try again after 24 hrs, 3)password should be alphanumeric,etc
on group of users, these sets of policies are combinely called as profile. So we have to create a profile and put these policies inside it.

Now if you don't assign any profile to a new user then it will automaticalley get a default profile known as "DEFAULT" profile.
Now the profile will be same for all users inside that group but that the values may differ as per the user.(for eg: the invalid password attempts may be different for diff users)

--> âœ…To check default profile 

go to pdb search user U1
	ðŸ”¹SQL> select username, profile from dba_users where username='U1';

	USERNAME
	--------------------------------------------------------------------------------
	PROFILE
	--------------------------------------------------------------------------------
	U1
	DEFAULT

--> âœ…To check what inside profile

	ðŸ”¹SQL> select PROFILE, RESOURCE_NAME, RESOURCE_TYPE, LIMIT from dba_profiles where profile='DEFAULT';

--> âœ…To create new profile

	CREATE PROFILE APP2_PROFILE
	LIMIT
	COMPOSITE_LIMIT UNLIMITED
	SESSIONS_PER_USER UNLIMITED
	CPU_PER_SESSION UNLIMITED
	CPU_PER_CALL UNLIMITED
	LOGICAL_READS_PER_SESSION UNLIMITED
	LOGICAL_READS_PER_CALL UNLIMITED
	IDLE_TIME 90
	CONNECT_TIME UNLIMITED
	PRIVATE_SGA UNLIMITED
	FAILED_LOGIN_ATTEMPTS 10
	PASSWORD_LIFE_TIME 30
	PASSWORD_REUSE_TIME UNLIMITED
	PASSWORD_REUSE_MAX UNLIMITED
	PASSWORD_VERIFY_FUNCTION NULL
	PASSWORD_LOCK_TIME UNLIMITED
	PASSWORD_GRACE_TIME UNLIMITED;


--> âœ…To change user profile (eg: from "DEFAULT to APP_PROFILE")

	ðŸ”¹SQL> alter user u1 profile app_profile;
	
	USERNAME                                             PROFILE
	------------------------------------------------- -----------------------------------------------------
	U1                                                   APP_PROFILE

--> âœ…To give quota for user on a specific tablespace.

	ðŸ”¹SQL> ALTER USER u2 QUOTA UNLIMITED ON users;
  or
	ðŸ”¹SQL> ALTER USER u2 QUOTA 50M ON users;



==>ðŸ“ŒPERMISSIONS & PRIVILEGES
----------------------------
To give permissions use command-> "GRANT" & to remove permissions use command-> "REVOKE"
There are two types of permissions:-

1) System Level
   ------------
   a)Scope:- Entire database 
   b)Who uses it:-	DBAs, developers
   c)Examples:- CREATE USER, DROP ANY TABLE
   d)Security risk:- Higher (can affect entire DB)
   
	ðŸ”¹SQL> select distinct privilege from dba_sys_privs;

	PRIVILEGE
	----------------------------------------
	INHERIT ANY PRIVILEGES
	CREATE TABLESPACE
	ALTER USER
	CREATE ANY CONTEXT
	SELECT ANY MINING MODEL
	CREATE LOCKDOWN PROFILE
	CREATE TABLE
	CREATE ANY TABLE
	ADMINISTER KEY MANAGEMENT
	DROP ANY TYPE
	ALTER SYSTEM
	DEBUG CONNECT ANY
	DELETE ANY CUBE DIMENSION
	ALTER ANY CUBE BUILD PROCESS
	DROP ANY SYNONYM
	DROP PUBLIC SYNONYM
	.......
	
	ðŸ”¹SQL> select privilege, grantee from dba_sys_privs where grantee='U1';

	PRIVILEGE                                GR
	---------------------------------------- --
	CREATE SESSION                           U1



2) Object Level
   ------------
	a)Scope:- Specific object (table, view, etc.)
	b)Who uses it:- Application users, data analysts
	c)Examples:- SELECT ON emp, EXECUTE ON proc1
	d)Security risk:- Lower (limited to specific object access)

ðŸ”¹SQL> select distinct privilege from dba_tab_privs;

	PRIVILEGE
	----------------------------------------
	REFERENCES
	USE
	INSERT
	ALTER
	DEQUEUE
	WRITE
	EXECUTE
	INHERIT PRIVILEGES
	DELETE
	UPDATE
	SELECT
	READ
	INHERIT REMOTE PRIVILEGES
	FLASHBACK

Now sys user can give some permissions to other users to perform queries(i.e sys can give permissions to U2 to perform operations on table T1 created bu U1(OWNER))

	ðŸ”¹SQL> grant select on u1.t1 to u2;

	Grant succeeded.

	ðŸ”¹SQL> select grantee,owner,table_name,privilege from dba_tab_privs where grantee='U2';

	GRANTEE                        OWNER                          TABLE_NAME                     PRIVILEGE
	------------------------------ ------------------------------ ------------------------------ ------------------------------
	U2                             U1                             T1                             SELECT
	
	
-->ðŸ“ŒROLE:-
---------
A named group/set of related privileges that can be granted to users or other roles.
They make privilege management simpler and more organized.
Instead of giving same permissions to different users we can give those permissions to role and role will further give them to users.

	ðŸ”¹SQL> create role app_role;
	
	Role created.
	
	ðŸ”¹SQL> grant select on u1.t1 to app_role;
	
	Grant succeeded.
	
	ðŸ”¹SQL> grant create session to app_role;
	
	Grant succeeded.
	
	ðŸ”¹SQL> grant app_role to u1;
	
	Grant succeeded.
	
	ðŸ”¹SQL> select role,privilege from role_sys_privs where role='APP_ROLE';
	
	ROLE                                                                                                                             PRIVILEGE
	-------------------------------------------------------------------------------------------------------------------------------- ---------------------------                                                               ---
	APP_ROLE                                                                                                                         CREATE SESSION
	
	
	ðŸ”¹SQL> select role,owner,table_name,privilege from role_tab_privs where role='APP_ROLE';
	
	ROLE                                                                                                    OWNER                     TABLE_NAME                         PRIVILEGE
	--------------------------------------------------------------------------------------------- ------------------------------ ------------------------------ ------------------------------
	APP_ROLE                                                                                                 U1                            T1                              SELECT

--> Drop Role -> drop role role_name;
â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–


ðŸ“ŒLISTENER

Listener is installed with the server itself, it helps user to connect to DB for the first time, it works as a handshake protocol, listener comes into role only when a new 
request is received. First listener checks whether listener itself is registered with DB or not(process known as registeration), if registered then handshake of user & DB 
is done, later listener is of no use.

There are two files containing the listener name, port, etc.:-
1)tnsnames.ora (present at client side as well as server side $OH/network/admin/tnsnames.ora  while using sqldeveloper contains DB details)     
2)listener.ora (present at server side $OH/network/admin/listener.ora)

======>ðŸ“ŒWe have one utility to start listener known as "lsnrctl" present in ORACLE_HOME/bin
->To start [lsnrctl start] now whenever we start listener it reads a file called "listener.ora" file present at $OH/network/admin. 
->To check status [lsnrctl status]
->To stop [lsnrctl stop]
->To restart[lsnrctl reload]


++> LISTENER REGISTERATION

1) Dynamic Registeration :- Here the name of listener should be "LISTENER" and port "1521". This is default setting.
							It will automatically register we can check after typing-> lsnrctl start.
							here the listener.ora file will have only name of listener and port 1521 no specific database registered.
							
							# listener.ora Network Configuration File: /u01/app/oracle/product/19.3.0/db_home/network/admin/listener.ora
							# Generated by Oracle configuration tools.
							
							LISTENER =
								(DESCRIPTION_LIST =
									(DESCRIPTION =
									(ADDRESS = (PROTOCOL = TCP) (HOST = node1.learnomate.org)(PORT = 1521))
									(ADDRESS = (PROTOCOL = ICP) (KEY = EXTPROC1521))
									)
								)
							
							# tnsnames.ora Network Configuration File: /u01/app/oracle/product/19.3.0/db_home/network/admin/tnsnames.ora
							# Generated by Oracle configuration tools.
							
							LISTENER_PRIM =                                                          #we can give any name in tnsnames.ora as it is at client side.
								(ADDRESS = (PROTOCOL = TCP) (HOST = node1) (PORT = 1521))
							
							PRIM =
                                (DESCRIPTION =
                                	(ADDRESS = (PROTOCOL = TCP)(HOST = node1.learnomate.org)(PORT = 1521))
                                	(CONNECT_DATA =
                                	(SERVER = DEDICATED)
                                	(SERVICE_NAME = prim)
                                	)
							
							
							
2) Static Registeration :- You manually define the instance information in the listener.ora file.
                           Required for Oracle RAC, Dataguard, or special configurations (like when dynamic reg fails).
						   
						   # listener.ora Network Configuration File: /u01/app/oracle/product/19.3.0/db_home/network/admin/listener.ora
						   # Generated by Oracle configuration tools.
						   
						   LISTENER =
						   	(DESCRIPTION_LIST =
						   		(DESCRIPTION =
						   		(ADDRESS = (PROTOCOL = TCP) (HOST = node1.learnomate.org)(PORT = 1521))
						   		(ADDRESS = (PROTOCOL = ICP) (KEY = EXTPROC1521))
						   		)
						   	)
						   
						   SID_LIST_LISTENER =
						     (SID_LIST =
						     	(SID_DESC =
						     		(GLOBAL_DBNAME = prim)
						     		(ORACLE_HOME = /u01/app/oracle/product/19.3.0/db_home)
						     		(SID_NAME = prim)
						     	)
						      )
						   
						   
						   # tnsnames.ora Network Configuration File: /u01/app/oracle/product/19.3.0/db_home/network/admin/tnsnames.ora
						   # Generated by Oracle configuration tools.
						   
						   LISTENER_PRIM =                                                          #we can give any name in tnsnames.ora as it is at client side.
						   	(ADDRESS = (PROTOCOL = TCP) (HOST = node1) (PORT = 1521))
						   
						   PRIM =
						       (DESCRIPTION =
						       	(ADDRESS = (PROTOCOL = TCP)(HOST = node1.learnomate.org)(PORT = 1521))
						       	(CONNECT_DATA =
						       	(SERVER = DEDICATED)
						       	(SERVICE_NAME = prim)
						       	)

[oracle@node1 admin]$ ps -ef | grep tnslsnr
grid      7312     1  0 12:50 ?        00:00:00 /u02/app/grid/product/19c/dbhome/bin/tnslsnr LISTENER -no_crs_notify -inherit
grid      7344     1  0 12:50 ?        00:00:00 /u02/app/grid/product/19c/dbhome/bin/tnslsnr LISTENER_SCAN1 -no_crs_notify -inherit
grid      7385     1  0 12:50 ?        00:00:00 /u02/app/grid/product/19c/dbhome/bin/tnslsnr ASMNET1LSNR_ASM -no_crs_notify -inherit
oracle   11748  8715  0 12:53 pts/0    00:00:00 grep --color=auto tnslsnr
â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–



						  					   
ðŸ“ŒTABLESPACE MANAGEMENT

++>TABLESPACE
--------------
TABLESPACE is collection of DATAFILES. One or more users can be assigned to a single tablespace.
Maximum size that a single DATAFILE inside TABLESPACE can have is 32GB. (Depends on the DB_BLOCK_SIZE = 8KB = 32GB, if 16KB then 64GB)
	ðŸ”¹ðŸ”¹SQL> show parameter db_block;

	NAME                                 TYPE        VALUE
	------------------------------------ ----------- ------------------------------
	db_block_buffers                     integer     0
	db_block_checking                    string      FALSE
	db_block_checksum                    string      TYPICAL
	db_block_size                        integer     8192 --------8KB

Maximum no of DATAFILES inside a single tablespace is 1022 FILES.

Whenever a DB is installed 5 tablespaces are automatically installed.

1)SYSTEM :- Stores the data dictionary (metadata) and core system objects(meta data tables).
2)SYSAUX :- Auxiliary tablespace to offload data from SYSTEM tablespace and has(AWR (Automatic Workload Repository), OEM (ORACLE ENTERPRISE MANAGER)).
3)UNDO :- Stores undo data for transactions to allow rollback and read consistency.
4)TEMP :- Used for sorting, temporary tables, and intermediate query operations when PGA gets full.
5)USERS :- Used when you forget to assign any tablespace to a newly created user.

Metadata table name -> "dba_tablespace"

	ðŸ”¹ðŸ”¹SQL> select username, default_tablespace from dba_users where username='U2';
	
	USERNAME
	--------------------------------------------------------------------------------
	DEFAULT_TABLESPACE
	------------------------------
	U2
	USERS


--> ðŸ“ŒTo create new TABLESPACE
   --------------------------

	ðŸ”¹ðŸ”¹SQL> CREATE TABLESPACE new_tbs DATAFILE '/data/app/oracle/oradata/PRIM/pdbprim/newtbsfile01.dbf' SIZE 100M AUTOEXTEND ON NEXT 10M MAXSIZE 500M EXTENT MANAGEMENT LOCAL
		 SEGMENT SPACE MANAGEMENT AUTO;


--> ðŸ“ŒTo Create a User and Assign the Tablespace
   --------------------------------------------

	ðŸ”¹ðŸ”¹SQL> CREATE USER new_user IDENTIFIED BY strong_password DEFAULT TABLESPACE new_tbs TEMPORARY TABLESPACE temp QUOTA UNLIMITED ON new_tbs;


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ðŸ“ŒSCRIPT FOR TABLESPACE UTILIZATION+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
	set linesize 1234 pages 1234                ======================================================> @table_util.sql
	col tablespace format a24
	col free heading 'Free(Mb)' format 99999999.9
	col total heading 'Total(Mb)' format 999999999.9
	col used heading 'Used(Mb)' format 99999999.9
	col pct_free heading 'Pct|Free' format 99999.9
	col largest heading 'Largest(Mb)' format 99999.9
	compute sum of total on report
	compute sum of free on report
	compute sum of used on report
	break on report
	select substr(a.tablespace_name,1,24) tablespace,
	round(sum(a.total1)/1024/1024, 1) Total,
	round(sum(a.total1)/1024/1024, 1)-round(sum(a.sum1)/1024/1024, 1) used,
	round(sum(a.sum1)/1024/1024, 1) free,
	round(sum(a.sum1)/1024/1024, 1)*100/round(sum(a.total1)/1024/1024, 1) pct_free,
	round(sum(a.maxb)/1024/1024, 1) largest,
	max(a.cnt) fragments
	from
	(select tablespace_name, 0 total1, sum(bytes) sum1,
	max(bytes) MAXB,
	count(bytes) cnt
	from dba_free_space
	group by tablespace_name
	union
	select tablespace_name, sum(bytes) total1, 0, 0, 0 from dba_data_files
	group by tablespace_name
	union
	select tablespace_name, sum(bytes) total1, 0, 0, 0 from dba_temp_files
	group by tablespace_name) a
	group by a.tablespace_name
	/
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
============================================================>ðŸ“ŒTo check and increase Tablespaces size<==============================================================================
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++USERS TABLESPACE++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

âœ…First check whether the the tablespace's auto extension is on or not bydefault it is on to increase it manually we will turn it off.

	TABLESPACE_NAME                 FILE_NAME                                       AUT MAXBYTES/1024/1024/1024
	---------------------- ----------------------------                             --- -----------------------
	USERS                  /data/app/oracle/oradata/PRIM/pdbprim/users01.dbf        YES  31.9999847
	
	ðŸ”¹ðŸ”¹SQL> select TABLESPACE_NAME, FILE_NAME,AUTOEXTENSIBLE,MAXBYTES/1024/1024/1024 from dba_Data_files;
	ðŸ”¹ðŸ”¹SQL> ALTER DATABASE DATAFILE '/data/app/oracle/oradata/PRIM/pdbprim/users01.dbf' AUTOEXTEND OFF;
	
	TABLESPACE_NAME                 FILE_NAME                                       AUT MAXBYTES/1024/1024/1024
	---------------------- ----------------------------                             --- -----------------------
	USERS                  /data/app/oracle/oradata/PRIM/pdbprim/users01.dbf        NO  31.9999847
	
	
	
	
																	Pct
	TABLESPACE                  Total(Mb)    Used(Mb)    Free(Mb)     Free Largest(Mb)  FRAGMENTS
	------------------------ ------------ ----------- ----------- -------- ----------- ----------
	SYSTEM                          270.0       269.8          .2       .1          .2          1
	SYSAUX                          350.0       330.9        19.1      5.5        19.0          2
	UNDOTBS1                        100.0        97.0         3.0      3.0         3.0          1
	TEMP                             36.0        36.0          .0       .0          .0          0
	USERS                             5.0         1.1         3.9     78.0         3.9          1
							------------ ----------- -----------
	sum                             761.0       734.8        26.2


1) âœ…Create user u2 and assign users tablespace to it;
	 SQL> alter user u2 default tablespace users;
2) âœ…Create table inside sql of u2 and try to insert data into it.
	 SQL> ALTER USER u2 QUOTA UNLIMITED ON users;

	create table testtable2 (id number(10), name varchar(20));
	
		BEGIN
		FOR id IN 1..10000000
		loop
		INSERT INTO testtable2(id,name) VALUES(id,'dba');
		END loop;
		END;
		/
	
Now since "USERS tablespace" has only one datafile which is of 5 MB only and we are trying to insert large amount of data leading to fully usage of tablespace.

	TABLESPACE                  Total(Mb)    Used(Mb)    Free(Mb)     Free Largest(Mb)  FRAGMENTS
	------------------------ ------------ ----------- ----------- -------- ----------- ----------
	SYSTEM                          270.0       269.8          .2       .1          .2          1
	SYSAUX                          350.0       330.9        19.1      5.5        19.0          2
	UNDOTBS1                        100.0        96.8         3.2      3.2         1.0          6
	TEMP                             36.0        36.0          .0       .0          .0          0
	USERS                             5.0         4.1          .9     18.0          .9          1           ======================> full usage.
							------------ ----------- -----------
	sum                             761.0       737.6        23.4


3) âœ…Check number of datafiles present in "USERS tablespace" and its size.

	col file_name for a50;
	select file_name,tablespace_name,bytes/1024/1024,status from dba_data_files where tablespace_name='USERS';
	
	FILE_NAME                                          TABLESPACE_NAME                BYTES/1024/1024 STATUS
	-------------------------------------------------- ------------------------------ --------------- ---------
	/data/app/oracle/oradata/PRIM/pdbprim/users01.dbf  USERS                                        5 AVAILABLE

Now we have two options first to add another data file to tablespace or second to increase the size of existing datafile.
we will try first option add new data file of size 10MB.

	ðŸ”¹ðŸ”¹SQL> alter tablespace USERS add datafile '/data/app/oracle/oradata/PRIM/pdbprim/users02.dbf' size 10M;
	
	Tablespace altered.
	
	col file_name for a50;
	select file_name,tablespace_name,bytes/1024/1024,status from dba_data_files where tablespace_name='USERS';
	
		FILE_NAME                                          TABLESPACE_NAME                BYTES/1024/1024 STATUS
	-------------------------------------------------- ------------------------------ --------------- ---------
	/data/app/oracle/oradata/PRIM/pdbprim/users01.dbf  USERS                                        5 AVAILABLE
	/data/app/oracle/oradata/PRIM/pdbprim/users02.dbf  USERS                                       10 AVAILABLE



Now if we check again we will get total space as 15MB and available will be more.
now we will try second option increase size of existing datafile.

	ðŸ”¹ðŸ”¹SQL> alter database datafile '/data/app/oracle/oradata/PRIM/pdbprim/users01.dbf' resize 10M;
	
	Database altered.
	
	ðŸ”¹ðŸ”¹SQL> col file_name for a50;
	select file_name,tablespace_name,bytes/1024/1024,status from dba_data_files where tablespace_name='USERS';
	ðŸ”¹ðŸ”¹SQL>
	FILE_NAME                                          TABLESPACE_NAME                BYTES/1024/1024 STATUS
	-------------------------------------------------- ------------------------------ --------------- ---------
	/data/app/oracle/oradata/PRIM/pdbprim/users01.dbf  USERS                                       10 AVAILABLE
	/data/app/oracle/oradata/PRIM/pdbprim/users02.dbf  USERS                                       10 AVAILABLE

Now if we check again we will get total space as 20MB and available will be more.

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ðŸ“ŒTEMP TABLESPACE+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


If TEMP table space gets full and we want to add new data file then

first check how many temp files

	ðŸ”¹ðŸ”¹SQL> select file#, name, round(bytes/(1024*1024),2) "Temp file SIZE IN MB's" from v$tempfile;

Now create new file

	ðŸ”¹ðŸ”¹SQL> alter tablespace TEMP add tempfile '/data/app/oracle/oradata/PRIM/pdbprim/temp02.dbf' SIZE 10M ;

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++



===>ðŸ“ŒBIGFILE DATAFILE

A bigfile datafile is a datafile in a bigfile tablespace, which allows:

Only one datafile per tablespace

That one file to be very large (up to 32 TB, depending on block size)

	ðŸ”¹ðŸ”¹SQL> CREATE BIGFILE TABLESPACE BIGTBS1 DATAFILE '/data/app/oracle/oradata/PRIM/pdbprim/bigtbs01.dbf' SIZE 10M AUTOEXTEND ON NEXT 20M MAXSIZE 100G;
	
	CHECK BIGFILE & SMALLFILE TABLESPACE
	
	ðŸ”¹ðŸ”¹SQL> select TABLESPACE_NAME, BIGFILE from DBA_TABLESPACES;
	
	TABLESPACE_NAME                BIG
	------------------------------ ---
	SYSTEM                         NO
	SYSAUX                         NO
	UNDOTBS1                       NO
	TEMP                           NO
	USERS                          NO
	BIGTBS1                        YES
â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–


ðŸ“ŒDATAPUMP (EXPDP/IMPDP)

To take backup of logical entities like Schema, Table, Tablespace, DB, etc an utility is used known as EXPDP and if we want to restore the same backup then IMPDP utility is used.

There are two types of entities in a DB.

1) Logical - EXPDP/IMPDP is used for backup & restoration.
eg:- Schema, Table, Tablespace, DB, etc

2) Physical - RMAN is used for backup & restoration.
eg:- Spfile, Controlfile, Datafile, etc

There are two types of Backups.

1) Hot Backup (inconsistent backup):- When DB is Up & running.

2) Cold Backup (consistent backup):- When DB is down.


----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ðŸ“ŒSCENARIO 1 - export/import from u1.t1 to u1.t1 only+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

++STEPS to take backup of any Table++
-------------------------------------

1) âœ…Go to pluggable DB i.e Connect directly to PDBPRIM during expdp.
[oracle@node1 ~]$ export ORACLE_PDB_SID=pdbprim -------->(valid for that session only)
[oracle@node1 ~]$ sqlplus / as sysdba

	ðŸ”¹SQL> show con_name
	
	CON_NAME
	------------------------------
	PDBPRIM
	
2) âœ…Check the table for which backup should be taken.


	ðŸ”¹SQL> select count(*) from u1.t1;
	
	COUNT(*)
	----------
			1
			
3) âœ…Create logical directory in sql first where backup will be taken.

	ðŸ”¹SQL> create directory test_dir as '/data/backup';
	
	Directory created.

4) âœ…Now Create the physical directory in duplicate session where backup will be taken.

	[oracle@node1 ~]$ mkdir -p /data/backup
	
5) âœ…Exit from sql session as we have to take backup from linux session.

6) âœ…Type the expdp command 

	[oracle@node1 ~]$ expdp tables=u1.t1 directory=test_dir dumpfile=t1.dmp logfile=t1.log

	Export: Release 19.0.0.0.0 - Production on Wed May 21 12:22:40 2025
	Version 19.3.0.0.0
	
	Copyright (c) 1982, 2019, Oracle and/or its affiliates.  All rights reserved.
	
	Username: / as sysdba    =========> type this user to monitor the backup
	Password:                ==========> just hit enter dont hit password
	
	Connected to: Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production
	Starting "SYS"."SYS_EXPORT_TABLE_01":  /******** AS SYSDBA tables=u1.t1 directory=test_dir dumpfile=t1.dmp logfile=t1.log
	Processing object type TABLE_EXPORT/TABLE/TABLE_DATA
	Processing object type TABLE_EXPORT/TABLE/STATISTICS/TABLE_STATISTICS
	Processing object type TABLE_EXPORT/TABLE/STATISTICS/MARKER
	Processing object type TABLE_EXPORT/TABLE/TABLE
	Processing object type TABLE_EXPORT/TABLE/GRANT/OWNER_GRANT/OBJECT_GRANT
	. . exported "U1"."T1"                                   5.093 KB       1 rows
	Master table "SYS"."SYS_EXPORT_TABLE_01" successfully loaded/unloaded
	******************************************************************************
	Dump file set for SYS.SYS_EXPORT_TABLE_01 is:
	/data/backup/t1.dmp
	Job "SYS"."SYS_EXPORT_TABLE_01" successfully completed at Wed May 21 12:23:15 2025 elapsed 0 00:00:18

7) âœ…Now the dump file & log files are created in the backup directory that we created.
	[oracle@node1 backup]$ ll
	total 180
	-rw-r-----. 1 oracle oinstall 180224 May 21 12:23 t1.dmp
	-rw-r--r--. 1 oracle oinstall   1086 May 21 12:23 t1.log
	
	Now the dmp and log file consist of all the backup details but we cannot read the .dmp file so if the client asks us we can show the log file to them.



++ðŸ“ŒSTEPS to import(restore) any Table ++
-------------------------------------
 
1) âœ…Now first open sql and drop the table u1.t1.

	ðŸ”¹SQL> show con_name;
	
	CON_NAME
	------------------------------
	PDBPRIM
	ðŸ”¹SQL> drop table u1.t1;
	
	Table dropped.
	
2) âœ…Exit sql and Type impdp command on linux same session.

	[oracle@node1 ~]$ impdp directory=test_dir dumpfile=t1.dmp logfile=t1_imp.log

3) âœ…Import willl start and get completed and we can find find the table again.

	Import: Release 19.0.0.0.0 - Production on Wed May 21 12:44:02 2025
	Version 19.3.0.0.0

	Copyright (c) 1982, 2019, Oracle and/or its affiliates.  All rights reserved.

	Username: / as sysdba
	Password:

	Connected to: Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production
	Master table "SYS"."SYS_IMPORT_FULL_01" successfully loaded/unloaded
	Starting "SYS"."SYS_IMPORT_FULL_01":  /******** AS SYSDBA directory=test_dir dumpfile=t1.dmp logfile=t1_imp.log
	Processing object type TABLE_EXPORT/TABLE/TABLE
	Processing object type TABLE_EXPORT/TABLE/TABLE_DATA
	. . imported "U1"."T1"                                   5.093 KB       1 rows
	Processing object type TABLE_EXPORT/TABLE/GRANT/OWNER_GRANT/OBJECT_GRANT
	Processing object type TABLE_EXPORT/TABLE/STATISTICS/TABLE_STATISTICS
	Processing object type TABLE_EXPORT/TABLE/STATISTICS/MARKER
	Job "SYS"."SYS_IMPORT_FULL_01" successfully completed at Wed May 21 12:45:51 2025 elapsed 0 00:00:38

	[oracle@node1 ~]$ sqlplus / as sysdba

	SQL*Plus: Release 19.0.0.0.0 - Production on Wed May 21 12:46:01 2025
	Version 19.3.0.0.0

	Copyright (c) 1982, 2019, Oracle.  All rights reserved.


	Connected to:
	Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production
	Version 19.3.0.0.0

	ðŸ”¹SQL>
	ðŸ”¹SQL>
	ðŸ”¹SQL> select * from u1.t1;

			ID
	----------
			10

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ðŸ“ŒSCENARIO 2 - export/import of schema +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

SCHEMA :-  a schema is essentially a collection of database objects that belong to a specific database user. These objects can include: tables, views, indexes, triggers , etc.
Schema name	Always the same as the user name who owns it.

1) âœ…Type command.
[oracle@node1 ~]$ expdp schemas=u1 directory=test_dir dumpfile=u1.dmp logfile=u1.log

	Export: Release 19.0.0.0.0 - Production on Wed May 21 13:17:45 2025
	Version 19.3.0.0.0
	
	Copyright (c) 1982, 2019, Oracle and/or its affiliates.  All rights reserved.
	
	Username: / as sysdba
	Password:
	
	Connected to: Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production
	Starting "SYS"."SYS_EXPORT_SCHEMA_01":  /******** AS SYSDBA schemas=u1 directory=test_dir dumpfile=u1.dmp logfile=u1.log
	Processing object type SCHEMA_EXPORT/TABLE/TABLE_DATA
	Processing object type SCHEMA_EXPORT/TABLE/STATISTICS/TABLE_STATISTICS
	Processing object type SCHEMA_EXPORT/STATISTICS/MARKER
	Processing object type SCHEMA_EXPORT/USER
	Processing object type SCHEMA_EXPORT/SYSTEM_GRANT
	Processing object type SCHEMA_EXPORT/ROLE_GRANT
	Processing object type SCHEMA_EXPORT/DEFAULT_ROLE
	Processing object type SCHEMA_EXPORT/PRE_SCHEMA/PROCACT_SCHEMA
	Processing object type SCHEMA_EXPORT/TABLE/TABLE
	Processing object type SCHEMA_EXPORT/TABLE/GRANT/OWNER_GRANT/OBJECT_GRANT
	. . exported "U1"."T2"                                   5.593 KB       6 rows
	. . exported "U1"."T1"                                   5.593 KB       6 rows
	Master table "SYS"."SYS_EXPORT_SCHEMA_01" successfully loaded/unloaded
	******************************************************************************
	Dump file set for SYS.SYS_EXPORT_SCHEMA_01 is:
	/data/backup/u1.dmp
	Job "SYS"."SYS_EXPORT_SCHEMA_01" successfully completed at Wed May 21 13:18:55 2025 elapsed 0 00:00:59

2) âœ…To check schema size

	run script => ðŸ”¹SQL> @schema_size_check.sql

	OWNER           ???SIZE_IN_GB???
	--------------- ----------------
	AUDSYS                  .0013125
	CTXSYS                  .0026875
	DBSNMP                  .0001875
	DVSYS                   .0045625
	GSMADMIN_INTERN             .001
	AL
	
	LBACSYS                 .0003125
	MDSYS                    .122875
	OJVMSYS                  .000375
	ORDDATA                 .0013125
	ORDSYS                   .000375
	SYS                     .4069375
	SYSTEM                  .0013125
	U1                      .0001875
	U2                          .003
	U3                      .0000625
	U4                          .004
	WMSYS                   .0065625
	XDB                      .060875


3)âœ…Now drop u1 schema, cascade means all objects inside it also.

	ðŸ”¹SQL> drop user u1 cascade;
	
	User dropped.

4)âœ…Now import schema back {Note:- Before importing any schema or table, please check the tablespace of that user/schema whether it has suffiecient space or not.}

	[oracle@node1 ~]$ impdp schemas=u1 directory=test_dir dumpfile=u1.dmp logfile=u1.log
	 
	 Import: Release 19.0.0.0.0 - Production on Wed May 21 13:30:17 2025
	 Version 19.3.0.0.0
	 
	 Copyright (c) 1982, 2019, Oracle and/or its affiliates.  All rights reserved.
	 
	 Username: / as sysdba
	 Password:
	 
	 Connected to: Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production
	 Master table "SYS"."SYS_IMPORT_SCHEMA_01" successfully loaded/unloaded
	 Starting "SYS"."SYS_IMPORT_SCHEMA_01":  /******** AS SYSDBA schemas=u1 directory=test_dir dumpfile=u1.dmp logfile=u1.log
	 Processing object type SCHEMA_EXPORT/USER
	 Processing object type SCHEMA_EXPORT/SYSTEM_GRANT
	 Processing object type SCHEMA_EXPORT/ROLE_GRANT
	 Processing object type SCHEMA_EXPORT/DEFAULT_ROLE
	 Processing object type SCHEMA_EXPORT/PRE_SCHEMA/PROCACT_SCHEMA
	 Processing object type SCHEMA_EXPORT/TABLE/TABLE
	 Processing object type SCHEMA_EXPORT/TABLE/TABLE_DATA
	 . . imported "U1"."T2"                                   5.593 KB       6 rows
	 . . imported "U1"."T1"                                   5.593 KB       6 rows
	 Processing object type SCHEMA_EXPORT/TABLE/GRANT/OWNER_GRANT/OBJECT_GRANT
	 Processing object type SCHEMA_EXPORT/TABLE/STATISTICS/TABLE_STATISTICS
	 Processing object type SCHEMA_EXPORT/STATISTICS/MARKER
	 Job "SYS"."SYS_IMPORT_SCHEMA_01" successfully completed at Wed May 21 13:31:14 2025 elapsed 0 00:00:46


=============>ðŸ“ŒEXPDP PARAMETERS

1) âœ…{[Content parameter]}

	There are two types of expdp/impdp backup i.e when we dake backup of any table it has two things inside it.
	
	a)Meta-data backup(the table structure)  
	
	So the command will be [oracle@node1 ~]$ expdp tables=u1.t1 directory=test_dir dumpfile=t1.dmp logfile=t1.log content=metadata_only

	b)Data backup(the content)

	So the command will be [oracle@node1 ~]$ expdp tables=u1.t1 directory=test_dir dumpfile=t1.dmp logfile=t1.log content=data_only


2) âœ…[{Query parameter]} (condition)

	expdp u1/password tables=t1 directory=test_dir dumpfile=t1_date_range.dmp logfile=t1_date_range.log \
	query="WHERE created_date BETWEEN TO_DATE('2024-01-01','YYYY-MM-DD') AND TO_DATE('2024-12-31','YYYY-MM-DD')"


3) âœ…{[Flashback parameter]} (to go back in time and take specific backup)

	two types => 

	a) with repect to scn number.

		ðŸ”¹SQL> select count(*) from u1.t1;
		
		COUNT(*)
		----------
				6
		
		ðŸ”¹SQL> select current_scn from v$database;
		
		CURRENT_SCN
		-----------
			2562309
		
		ðŸ”¹SQL> insert into u1.t1 select* from u1.t1;
		
		6 rows created.
		
		ðŸ”¹SQL> select count(*) from u1.t1;
		
		COUNT(*)
		----------
				12
		ðŸ”¹SQL> select current_scn from v$database;
		
		CURRENT_SCN
		-----------
			2562336
		
		now we want to take backup till 6 records only where scn number was 2562309.
		
	expdp tables=u1.t1 directory=test_dir dumpfile=u1_scn.dmp logfile=u1_scn.log flashback_scn=2562309
	

	b)with repect to timestamp.
		
	expdp u1/password tables=t1 directory=test_dir dumpfile=t1_old.dmp logfile=t1_old.log \ flashback_time="TO_TIMESTAMP('2025-05-20 10:00:00', 'YYYY-MM-DD HH24:MI:SS')"


4) âœ…To Speed up the export by allowing Oracle to process multiple objects simultaneously we use {[parallel parameter]} execution with 3 threads/workers. This will create more than 
	one dump file of file size of 100MB(can be anything as we set) or less.
	
	[oracle@node1 ~]$ export ORACLE_PDB_SID=pdbprim
	[oracle@node1 ~]$ expdp schemas=u2 directory=test_dir dumpfile=u2_schema_%u.dmp logfile=u2.log filesize=100M parallel=3


5) âœ…The {[REMAP parameter]} in impdp (Data Pump Import) are extremely powerful and are used to redirect or transform schema, table, or tablespace names during the import process.
	They let you import exported data into a different schema, tablespace, or table name than in the original export.
	
	  Parameter	                      Purpose
	a) REMAP_SCHEMA	    Change the schema the objects are imported into
		[oracle@test ~]$ impdp system/oracle@pdbprim directory=test_dir dumpfile=u2_schema_%u.dmp logfile=import.log remap_schema=u2:new_user
	
	
	
	b) REMAP_TABLESPACE	Change the tablespace for table/index data
		[oracle@test ~]$ impdp system/password directory=test_dir dumpfile=u2_schema_%u.dmp logfile=import.log remap_tablespace=old_ts:new_ts
	

	c) REMAP_TABLE	        Rename specific tables during import
		[oracle@test ~]$ impdp system/password directory=test_dir dumpfile=u2_schema_%u.dmp logfile=import.log remap_table=u2.old_table:new_table
	

6) âœ…The {[TABLE_EXISTS_ACTION parameter]} controls what Oracle should do if a table already exists in the target schema.
	
		Value													Description
		
	a) SKIP (default)		Skip importing the table if it already exists. No changes made.
		impdp system/password directory=test_dir dumpfile=u2_schema.dmp logfile=imp.log schemas=u2

	b) APPEND				Adds rows from the dump file into the existing table. Existing data is preserved.
		impdp system/password directory=test_dir dumpfile=u2_schema.dmp logfile=imp.log schemas=u2 table_exists_action=append

	c) TRUNCATE			Deletes all rows in the existing table before importing new data. Table structure stays.
		impdp system/password directory=test_dir dumpfile=u2_schema.dmp logfile=imp.log schemas=u2 table_exists_action=truncate

	d) REPLACE				Drops the existing table and recreates it from the dump file. All data and structure are replaced.
		impdp system/password directory=test_dir dumpfile=u2_schema.dmp logfile=imp.log schemas=u2 table_exists_action=replace


ðŸ“Œ Summary Table:-
-------------------

	Parameter	    	 Used In					Purpose Summary
CONTENT					expdp only		Export data only, metadata only, or both
QUERY					expdp only		Export specific rows using WHERE
FLASHBACK_TIME/SCN		expdp only		Export consistent snapshot of data
PARALLEL					both		Multi-threaded performance
REMAP_*					impdp only		Redirect schema/tablespace/table during import
TABLE_EXISTS_ACTION		impdp only		How to handle existing tables on import



+++++ðŸ“ŒEXPDP MULTIPLE DIRECTORIES+++++

[root@node1 ~]# mkdir -p /u01/expdir1
[root@node1 ~]# mkdir -p /u02/expdir2

[root@node1 /]# chown -R oracle:oinstall /u01
[root@node1 /]# chown -R oracle:oinstall /u02


ðŸ”¹SQL> CREATE OR REPLACE DIRECTORY dir1 AS '/u01/expdir1';

Directory created.

ðŸ”¹SQL> CREATE OR REPLACE DIRECTORY dir2 AS '/u02/expdir2';


[oracle@node1 ~]$ expdp schemas=U2 \ dumpfile=dir1:hr_exp1.dmp,dir2:hr_exp2.dmp \ logfile=hr_exp.log \ directory=dir1

[root@node1 expdir1]# ll
total 620856
-rw-r-----. 1 oracle oinstall 635752448 May 24 19:29 hr_exp1.dmp
-rw-r--r--. 1 oracle oinstall      1603 May 24 19:29 hr_exp.log

[root@node1 expdir2]# ll
total 8
-rw-r-----. 1 oracle oinstall 4096 May 24 19:29 hr_exp2.dmp
-rw-r--r--. 1 oracle oinstall  342 May 24 19:27 hr_exp.log

EXAMPLE :- 

SQL> alter session set container = pdbprim;

Session altered.

SQL> create or replace directory dir1 as '/u02/back1';

Directory created.

SQL> create or replace directory dir2 as '/u02/back2';

Directory created.


SQL> GRANT READ, WRITE ON DIRECTORY dir1 TO PUBLIC;

Grant succeeded.

SQL> GRANT READ, WRITE ON DIRECTORY dir2 TO PUBLIC;

Grant succeeded.

[root@node1 ~]# mkdir -p /u02/back1
[root@node1 ~]# mkdir -p /u02/back2
[root@node1 ~]# chmod -R 755 /u02/back1
[root@node1 ~]# chmod -R 755 /u02/back2
[root@node1 ~]# chown oracle:oinstall /u02/back1
[root@node1 ~]# chown oracle:oinstall /u02/back2
[root@node1 ~]# ls -ld /u02/back1
drwxr-xr-x. 2 oracle oinstall 6 Jul 28 22:29 /u02/back1
[root@node1 ~]# ls -ld /u02/back2
drwxr-xr-x. 2 oracle oinstall 6 Jul 28 22:29 /u02/back2

[oracle@node1 data]$ sqlplus u1/u1@pdbprim
SQL> CREATE TABLE employees (
    emp_id     NUMBER,
    emp_name   VARCHAR2(50),
    salary     NUMBER
);
  2    3    4    5
Table created.

SQL> BEGIN
  FOR i IN 1..100 LOOP
    INSERT INTO employees (emp_id, emp_name, salary)
    VALUES (
      i,
      'Employee_' || i,
      30000 + (i * 100)
    );
  END LOOP;
  COMMIT;
END;
/
  2    3    4    5    6    7    8    9   10   11   12
PL/SQL procedure successfully completed.

SQL> select count(*) from employees;

  COUNT(*)
----------
       100

[oracle@node1 ~]$ expdp u1/u1@pdbprim tables=u1.employees directory=dir1 dumpfile=dir1:dump1.dmp,dir2:dump2.dmp logfile=u1_employees.log

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Export: Release 19.0.0.0.0 - Production on Mon Jul 28 23:03:34 2025
Version 19.3.0.0.0

Copyright (c) 1982, 2019, Oracle and/or its affiliates.  All rights reserved.

Connected to: Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production
Starting "U1"."SYS_EXPORT_TABLE_01":  u1/********@pdbprim tables=u1.employees dumpfile=dir1:dump1.dmp,dir2:dump2.dmp logfile=u1_employees.log directory=dir1
Processing object type TABLE_EXPORT/TABLE/TABLE_DATA
Processing object type TABLE_EXPORT/TABLE/STATISTICS/TABLE_STATISTICS
Processing object type TABLE_EXPORT/TABLE/STATISTICS/MARKER
Processing object type TABLE_EXPORT/TABLE/TABLE
. . exported "U1"."EMPLOYEES"                            8.132 KB     100 rows
Master table "U1"."SYS_EXPORT_TABLE_01" successfully loaded/unloaded
******************************************************************************
Dump file set for U1.SYS_EXPORT_TABLE_01 is:
  /u02/back1/dump1.dmp
Job "U1"."SYS_EXPORT_TABLE_01" successfully completed at Mon Jul 28 23:04:06 2025 elapsed 0 00:00:31
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

[oracle@node1 back2]$ ll
total 4
-rw-r-----. 1 oracle oinstall 4096 Jul 28 23:04 dump2.dmp
[oracle@node1 back2]$ cd ../back1
[oracle@node1 back1]$ ll
total 180
-rw-r-----. 1 oracle oinstall 180224 Jul 28 23:04 dump1.dmp
-rw-r--r--. 1 oracle oinstall   1046 Jul 28 23:04 u1_employees.log



[oracle@node1 back1]$ sqlplus u2/u2@pdbprim

SQL> desc employees;
 Name                                      Null?    Type
 ----------------------------------------- -------- ----------------------------
 EMP_ID                                             NUMBER
 EMP_NAME                                           VARCHAR2(50)
 SALARY                                             NUMBER

[oracle@node1 back1]$ impdp u2/u2@pdbprim tables=u1.employees directory=dir1 dumpfile=dir1:dump1.dmp,dir2:dump2.dmp logfile=imp_u2.log remap_schema=u1:u2 table_exists_action=append

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Import: Release 19.0.0.0.0 - Production on Mon Jul 28 23:37:04 2025
Version 19.3.0.0.0

Copyright (c) 1982, 2019, Oracle and/or its affiliates.  All rights reserved.

Connected to: Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production
Master table "U2"."SYS_IMPORT_TABLE_01" successfully loaded/unloaded
Starting "U2"."SYS_IMPORT_TABLE_01":  u2/********@pdbprim tables=u1.employees directory=dir1 dumpfile=dir1:dump1.dmp,dir2:dump2.dmp logfile=imp_u2.log remap_schema=u1:u2 table_exists_action=append
Processing object type TABLE_EXPORT/TABLE/TABLE
Table "U2"."EMPLOYEES" exists. Data will be appended to existing table but all dependent metadata will be skipped due to table_exists_action of append
Processing object type TABLE_EXPORT/TABLE/TABLE_DATA
. . imported "U2"."EMPLOYEES"                            8.132 KB     100 rows
Processing object type TABLE_EXPORT/TABLE/STATISTICS/TABLE_STATISTICS
Processing object type TABLE_EXPORT/TABLE/STATISTICS/MARKER
Job "U2"."SYS_IMPORT_TABLE_01" successfully completed at Mon Jul 28 23:37:09 2025 elapsed 0 00:00:04
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

[oracle@node1 back1]$ sqlplus u2/u2@pdbprim

SQL> select count(*) from employees;

  COUNT(*)
----------
       100


[root@node1 back1]# ll
total 184
-rw-r-----. 1 oracle oinstall 180224 Jul 28 23:04 dump1.dmp
-rw-r--r--. 1 oracle oinstall   1090 Jul 28 23:37 imp_u2.log
-rw-r--r--. 1 oracle oinstall   1046 Jul 28 23:04 u1_employees.log
[root@node1 back1]# pwd
/u02/back1
â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–


ðŸ“ŒRMAN (Recovery Manager)
--------------------------

To take backup of physical entities like Spfile, Controlfile, Datafile, Archive log file  an utility is used known as RMAN and if we want to restore the same backup then 
same RMAN utility is used.
RMAN backup metadata â€” including the names, locations, and statuses of backup files â€” is stored in the control file of the Oracle database (and optionally in a recovery catalog,
if used).

ðŸ§  Recovery Catalogue:-
	ðŸ”¸The Recovery Catalog is an optional but powerful RMAN feature.
	ðŸ”¸It stores backup metadata externally and permanently, making it ideal for large, critical, or multi-database environments.


Two Types:-

1) Full Database Backup:- Backs up the entire database or a specific datafile/block. Taken mostly in weekends.
						  Typically used for quick, one-time full copies or as a baseline without planning further incremental backups.
						  {âš ï¸Note:- Use Full Backup for standalone or ad hoc backups not tied to incremental strategies.}
						  =>RMAN> BACKUP DATABASE PLUS ARCHIVELOG INCLUDE CURRENT CONTROLFILE;

2) Incremental Backup:-  

	a) Level 0:- Also backs up all blocks, just like a full backup.It acts as a baseline for future Level 1 incremental backups, which only back up changed blocks.
				{âš ï¸Note:- Use Level 0 if you're planning incremental Level 1 backups.}
				 =>RMAN> BACKUP INCREMENTAL LEVEL 0 DATABASE;

	
	b) Level 1:- Backs up only the changed data blocks since the last backup.
				 =>RMAN> BACKUP INCREMENTAL LEVEL 1 DATABASE;

	
3) Archive log Backup :- Which we can take every 2-3 hours.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ðŸ“ŒBACKUP of spfile+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
	[oracle@node1 ~]$ sqlplus / as sysdba
	ðŸ”¹ðŸ”¹SQL> startup
	ðŸ”¹ðŸ”¹SQL> alter session set container=pdbprim;
	
	  Session altered.
	
	ðŸ”¹ðŸ”¹SQL> exit
	
	[oracle@node1 ~]$ rman target /
	ðŸ”¹RMAN> backup spfile;
	
	Starting backup at 27-MAY-25
	using target database control file instead of recovery catalog
	allocated channel: ORA_DISK_1
	channel ORA_DISK_1: SID=439 device type=DISK   =============================>channel means no of threads/processes
	channel ORA_DISK_1: starting full datafile backup set
	channel ORA_DISK_1: specifying datafile(s) in backup set
	including current SPFILE in backup set
	channel ORA_DISK_1: starting piece 1 at 27-MAY-25
	channel ORA_DISK_1: finished piece 1 at 27-MAY-25
	piece handle=/data/app/oracle/product/19C/dbhome_3/dbs/013qhh3e_1_1 tag=TAG20250527T201749 comment=NONE  =======>piece handle is the filename (or unique identifier) of a 																									 
	channel ORA_DISK_1: backup set complete, elapsed time: 00:00:01													 backup piece.
	Finished backup at 27-MAY-25
	
	Starting Control File and SPFILE Autobackup at 27-MAY-25
	piece handle=/data/app/oracle/product/19C/dbhome_3/dbs/c-196814088-20250527-00 comment=NONE
	Finished Control File and SPFILE Autobackup at 27-MAY-25


âœ…Now in "piece handle" the path for backup is "/data/app/oracle/product/19C/dbhome_3/dbs/013qhh3e_1_1 tag=TAG20250527T201749" which is dbs location. But we can change the backup
  location by below command. "013qhh3e_1_1" is the dumpfile name which is auto renamed with help of "%u"(generates random alphanumeric) so the problem of naming resolves.

âœ…Now it also takes bydefault backup of spfile and control file "Starting Control File and SPFILE Autobackup at 27-MAY-25"

âœ…To change backup file destination
	
	ðŸ”¹RMAN> backup spfile format '/data/backup/spfile_%u';      ==============>"%u"(generates random alphanumeric)
	
	Starting backup at 27-MAY-25
	using target database control file instead of recovery catalog
	allocated channel: ORA_DISK_1
	channel ORA_DISK_1: SID=29 device type=DISK
	channel ORA_DISK_1: starting full datafile backup set
	channel ORA_DISK_1: specifying datafile(s) in backup set
	including current SPFILE in backup set
	channel ORA_DISK_1: starting piece 1 at 27-MAY-25
	channel ORA_DISK_1: finished piece 1 at 27-MAY-25
	piece handle=/data/backup/spfile_033qhn28 tag=TAG20250527T215936 comment=NONE ============> Location changed.
	channel ORA_DISK_1: backup set complete, elapsed time: 00:00:01
	Finished backup at 27-MAY-25

	ðŸ”¹RMAN> list backup;
	
	using target database control file instead of recovery catalog

	List of Backup Sets
	===================
	
	
	BS Key  Type LV Size       Device Type Elapsed Time Completion Time
	------- ---- -- ---------- ----------- ------------ ---------------
	1       Full    96.00K     DISK        00:00:00     27-MAY-25
			BP Key: 1   Status: AVAILABLE  Compressed: NO  Tag: TAG20250527T201749
			Piece Name: /data/app/oracle/product/19C/dbhome_3/dbs/013qhh3e_1_1
	SPFILE Included: Modification time: 27-MAY-25
	SPFILE db_unique_name: PRIM
	
	BS Key  Type LV Size       Device Type Elapsed Time Completion Time
	------- ---- -- ---------- ----------- ------------ ---------------
	2       Full    17.95M     DISK        00:00:00     27-MAY-25
			BP Key: 2   Status: AVAILABLE  Compressed: NO  Tag: TAG20250527T201751
			Piece Name: /data/app/oracle/product/19C/dbhome_3/dbs/c-196814088-20250527-00
	SPFILE Included: Modification time: 27-MAY-25
	SPFILE db_unique_name: PRIM
	Control File Included: Ckp SCN: 3055277      Ckp time: 27-MAY-25

âœ…Command to show tablespace and datafiles file size.

	ðŸ”¹RMAN> report schema;
	
	Report of database schema for database with db_unique_name PRIM
	
	List of Permanent Datafiles
	===========================
	File Size(MB) Tablespace           RB segs Datafile Name
	---- -------- -------------------- ------- ------------------------
	1    910      SYSTEM               YES     /data/app/oracle/oradata/PRIM/system01.dbf
	3    650      SYSAUX               NO      /data/app/oracle/oradata/PRIM/sysaux01.dbf
	4    345      UNDOTBS1             YES     /data/app/oracle/oradata/PRIM/undotbs01.dbf
	5    270      PDB$SEED:SYSTEM      NO      /data/app/oracle/oradata/PRIM/pdbseed/system01.dbf
	6    330      PDB$SEED:SYSAUX      NO      /data/app/oracle/oradata/PRIM/pdbseed/sysaux01.dbf
	7    5        USERS                NO      /data/app/oracle/oradata/PRIM/users01.dbf
	8    100      PDB$SEED:UNDOTBS1    NO      /data/app/oracle/oradata/PRIM/pdbseed/undotbs01.dbf
	9    370      PDBPRIM:SYSTEM       NO      /data/app/oracle/oradata/PRIM/pdbprim/system01.dbf
	10   370      PDBPRIM:SYSAUX       NO      /data/app/oracle/oradata/PRIM/pdbprim/sysaux01.dbf
	11   1075     PDBPRIM:UNDOTBS1     NO      /data/app/oracle/oradata/PRIM/pdbprim/undotbs01.dbf
	12   10       PDBPRIM:USERS        NO      /data/app/oracle/oradata/PRIM/pdbprim/users01.dbf
	13   270      PDBPRIM2:SYSTEM      NO      /data/app/oracle/oradata/PRIM/PDBPRIM2/system01.dbf
	14   340      PDBPRIM2:SYSAUX      NO      /data/app/oracle/oradata/PRIM/PDBPRIM2/sysaux01.dbf
	15   100      PDBPRIM2:UNDOTBS1    NO      /data/app/oracle/oradata/PRIM/PDBPRIM2/undotbs01.dbf
	16   5        PDBPRIM2:USERS       NO      /data/app/oracle/oradata/PRIM/PDBPRIM2/users01.dbf
	17   5120     PDBPRIM:USERS        NO      /data/app/oracle/oradata/PRIM/pdbprim/users02.dbf
	18   10       PDBPRIM:BIGTBS1      NO      /data/app/oracle/oradata/PRIM/pdbprim/bigtbs01.dbf
	19   10       PDBPRIM:NEW_TBS      NO      /data/app/oracle/oradata/PRIM/pdbprim/newtbsfile01.dbf
	20   10       PDBPRIM:NEW_TBS      NO      /data/app/oracle/oradata/PRIM/pdbprim/newtbsfile02
	
	List of Temporary Files
	=======================
	File Size(MB) Tablespace           Maxsize(MB) Tempfile Name
	---- -------- -------------------- ----------- --------------------
	1    32       TEMP                 32767       /data/app/oracle/oradata/PRIM/temp01.dbf
	2    36       PDB$SEED:TEMP        32767       /data/app/oracle/oradata/PRIM/pdbseed/temp012025-04-26_20-53-08-652-PM.dbf
	3    111      PDBPRIM:TEMP         32767       /data/app/oracle/oradata/PRIM/pdbprim/temp01.dbf
	4    36       PDBPRIM2:TEMP        32767       /data/app/oracle/oradata/PRIM/PDBPRIM2/temp012025-04-26_20-53-08-652-PM.dbf
	5    10       TEMP                 10          /data/app/oracle/oradata/PRIM/pdbprim/temp02.dbf



âœ…While taking backup of Spfile, Controlfile, Datafile, Archive log file etc the DB should be in Archive log mode.
	ðŸ”¸How to put DB in Archive log mode?
=>	1) First we need to set archive log destination (path) which has sufficient space.
	2) This is an offline activity so we need to shutdown DB down inorder to put DB in Archive log mode.
	3) Put DB in mount state to perform some activities.
	4) Put DB in Archivelog mode.
	5) DB start.


âœ…To check archive log status.

	ðŸ”¹ðŸ”¹SQL> archive log list;
	Database log mode              No Archive Mode
	Automatic archival             Disabled
	Archive destination            /data/app/oracle/product/19C/dbhome_3/dbs/arch
	Oldest online log sequence     24
	Current log sequence           26

ðŸ”¸Now the location to take backup of sqlplus is "/data/app/oracle/product/19C/dbhome_3/dbs/arch" bydefault. So to change it we need to create it first.

	ðŸ”¹ðŸ”¹SQL> !mkdir -p /data/archive           =====> {âš ï¸Note:- using "!" we can type linux commands from sql itself}
	
	ðŸ”¹ðŸ”¹SQL> alter system set log_archive_dest_1='location=/data/archive' scope=both;
	
	System altered.
	
	Now check again
	
	ðŸ”¹ðŸ”¹SQL> alter system set log_archive_dest_1='location=/data/archive' scope=both;
	
	System altered.
	
	ðŸ”¹ðŸ”¹SQL> archive log list;
	Database log mode              No Archive Mode
	Automatic archival             Disabled
	Archive destination            /data/archive   =====>path is changed.
	Oldest online log sequence     24
	Current log sequence           26

ðŸ”¸Now shutdown DB and again start DB in mount state.

	ðŸ”¹ðŸ”¹SQL> shutdown immediate
	ðŸ”¹ðŸ”¹SQL> startup mount
	
ðŸ”¸Now put Db in archivelog mode and start DB.
	ðŸ”¹ðŸ”¹SQL> alter database archivelog;
	
	Database altered.
	
	ðŸ”¹ðŸ”¹SQL> alter database open;
	
	Database altered.
	
	ðŸ”¹ðŸ”¹SQL> archive log list;
	Database log mode              Archive Mode       ==========>in archive log mode now.
	Automatic archival             Enabled
	Archive destination            /data/archive
	Oldest online log sequence     24
	Next log sequence to archive   26
	Current log sequence           26


âœ…To take backup of control, spfile, archived redo log file together using a script.

	ðŸ”¸Level 0 Backup - Backup of spfile,control file ,database and archivelog


  ðŸ”¹RUN
	{
	  ALLOCATE CHANNEL ch11 TYPE DISK MAXPIECESIZE 10G;
	  ALLOCATE CHANNEL ch12 TYPE DISK MAXPIECESIZE 10G;
	  ALLOCATE CHANNEL ch13 TYPE DISK MAXPIECESIZE 10G;
	  BACKUP
	  FORMAT '/data/backup/RMAN_BACKUP/%d_D_%T_%u_s%s_p%p'
	  INCREMENTAL LEVEL 0 DATABASE
	  CURRENT CONTROLFILE
	  FORMAT '/data/backup/RMAN_BACKUP/%d_C_%T_%u'
	  SPFILE
	  FORMAT '/data/backup/RMAN_BACKUP/%d_S_%T_%u'
	  PLUS ARCHIVELOG
	  FORMAT '/data/backup/RMAN_BACKUP/%d_A_%T_%u_s%s_p%p';
	  RELEASE CHANNEL ch11;
	  RELEASE CHANNEL ch12;
	  RELEASE CHANNEL ch13;
	}



âœ… Differential Incremental Backup
	ðŸ”¹What it does: Backs up all blocks that have changed since the last incremental backup of the same or lower level.
	=> RMAN> BACKUP INCREMENTAL LEVEL 1 DIFFERENTIAL DATABASE;
	
	Example:
	
		Level 0 on Sunday (full backup)
		
		Level 1 differential on Monday: backs up changes since Sunday
		
		Level 1 differential on Tuesday: backs up changes since Monday
		
		Backup size: Smaller than cumulative (if done frequently)
		
		Restore time: Slower â€“ multiple backups may need to be applied during recovery.

âœ… Cumulative Incremental Backup
	ðŸ”¹What it does: Backs up all blocks that have changed since the last Level 0 backup, regardless of any other incremental backups taken since.
	=> RMAN> BACKUP INCREMENTAL LEVEL 1 CUMULATIVE DATABASE;
	
	Example:
	
		Level 0 on Sunday (full backup)
		
		Level 1 cumulative on Monday: backs up changes since Sunday
		
		Level 1 cumulative on Tuesday: still backs up all changes since Sunday
		
		Backup size: Grows larger over time until the next Level 0
		
		Restore time: Faster â€“ only the Level 0 and the latest Level 1 cumulative are needed
		
âœ… Expired Backup

	When RMAN tries to access a backup file (e.g., during a restore or CROSSCHECK operation) and the file is not found at the recorded location (because it was deleted 
	manually or the storage is unavailable), RMAN marks that backup as EXPIRED.
	
	ðŸ”¹RMAN> crosscheck backup;

	allocated channel: ORA_DISK_1
	channel ORA_DISK_1: SID=225 device type=DISK
	crosschecked backup piece: found to be 'AVAILABLE'
	backup piece handle=/data/backup/spfile_033qhn28 RECID=3 STAMP=1202248776
	crosschecked backup piece: found to be 'AVAILABLE'
	backup piece handle=/data/app/oracle/product/19C/dbhome_3/dbs/c-196814088-20250527-01 RECID=4 STAMP=1202248777
	crosschecked backup piece: found to be 'EXPIRED'
	backup piece handle=/data/backup/RMAN_BACKUP/PRIM_A_20250530_053qofc1_s5_p1 RECID=5 STAMP=1202470273
	crosschecked backup piece: found to be 'EXPIRED'
	backup piece handle=/data/backup/RMAN_BACKUP/PRIM_D_20250530_063qofc3_s6_p1 RECID=6 STAMP=1202470275
	
	ðŸ”¸Now, since the control file has expired backup entry because we have deleted the backup manually. So to remove the expired backup.
	
	ðŸ”¹RMAN> delete expired backup;
	
	ðŸ”¹RMAN> crosscheck backup;

	allocated channel: ORA_DISK_1
	channel ORA_DISK_1: SID=225 device type=DISK
	crosschecked backup piece: found to be 'AVAILABLE'
	backup piece handle=/data/backup/spfile_033qhn28 RECID=3 STAMP=1202248776
	crosschecked backup piece: found to be 'AVAILABLE'
	backup piece handle=/data/app/oracle/product/19C/dbhome_3/dbs/c-196814088-20250527-01 RECID=4 STAMP=1202248777

	ðŸ”¸Now it will show only the available backup since we have deleted the expired backup and the control file is updated.
	
	ðŸ”¹Recommended way to delete backup is
	=> 	RMAN> delete backup;


âœ… Obsolete Backup

	An obsolete backup is a backup that is no longer needed for recovery, based on your retention policy. RMAN marks it as obsolete, so you can safely delete it to free up space.
	
	ðŸ”¸ RMAN retention policy (RECOVERY WINDOW or REDUNDANCY)
	
	1. Recovery Window (e.g., 7 days):
		ðŸ”¹RMAN> CONFIGURE RETENTION POLICY TO RECOVERY WINDOW OF 7 DAYS;
	RMAN keeps all backups needed to recover to any point in the last 7 days. Anything older becomes obsolete.
	
	2. Redundancy (e.g., 1 backup copies):
		ðŸ”¹RMAN> CONFIGURE RETENTION POLICY TO REDUNDANCY 1;
	RMAN keeps only the most recent backup. Older ones are obsolete.
	
	ðŸ”¹ How to See Obsolete Backups
		RMAN> REPORT OBSOLETE;
		
	ðŸ”¹ How to Delete Obsolete Backups
		RMAN> DELETE OBSOLETE;
		
	ðŸ”¹ To check policies.
		RMAN> show all;
		
-------------------------------------------------------------------------SOFTWARE LEVEL BACKUP------------------------------------------------------------------------------------

ðŸ’¾ How is tar used in software-level backups?

	A software-level backup means you're backing up the files and folders of an application, such as:
	
	Oracle installation folders
	
	Configuration files (like init.ora, .bash_profile, listener.ora)
	
	Log files
	
	Scripts
	
	Static data files (not live DB files)

ðŸ” You do not backup the live database files (like .dbf) this way â€” that needs RMAN.




BACKUP ARCHIVELOG ALL FORMAT '/backup/archivelogs/arch_%d_%T_%s.log';
BACKUP CURRENT CONTROLFILE FORMAT '/backup/controlfile/ctrl_%d_%T_%s.bkp';
BACKUP SPFILE FORMAT '/backup/spfile/spfile_%d_%T_%s.bkp';
BACKUP TABLESPACE users;
BACKUP DATABASE;
BACKUP DATAFILE '/u01/oradata/ORCL/users01.dbf', '/u01/oradata/ORCL/system01.dbf';
BACKUP DATABASE PLUS ARCHIVELOG INCLUDE CURRENT CONTROLFILE FORMAT '/backup/full/full_%d_%T_%s.bkp';
â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–



ðŸ“ŒRESTORATION (RMAN)
---------------------

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
âœ…To take RMAN BACKUP Of DB, DROP DB and then RESTORE DB using RMAN.
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

=========================================================================================================
1) Delete old backup.
=========================================================================================================
2) Take new level 0 incremental cumulative DB backup using below script in path /rman/backup.
	  ðŸ”¹RUN
			{
			ALLOCATE CHANNEL ch11 TYPE DISK MAXPIECESIZE 10G;
			ALLOCATE CHANNEL ch12 TYPE DISK MAXPIECESIZE 10G;
			ALLOCATE CHANNEL ch13 TYPE DISK MAXPIECESIZE 10G;
			BACKUP
			FORMAT '/data/rman/%d_D_%T_%u_s%s_p%p'
			INCREMENTAL LEVEL 0 CUMULATIVE DATABASE
			CURRENT CONTROLFILE
			FORMAT '/data/rman/%d_C_%T_%u'
			SPFILE
			FORMAT '/data/rman/%d_S_%T_%u'
			PLUS ARCHIVELOG
			FORMAT '/data/rman/%d_A_%T_%u_s%s_p%p';
			RELEASE CHANNEL ch11;
			RELEASE CHANNEL ch12;
			RELEASE CHANNEL ch13;
			}
=========================================================================================================
3) Now shutdown DB and start in restrict mode(no user can log in during that period).
	ðŸ”¹ðŸ”¹SQL> startup mount restrict;
=========================================================================================================
4) Now Drop DB
	ðŸ”¹ðŸ”¹SQL> drop database;

	  Database dropped.
=========================================================================================================
5) Now since we have drop the DB we wont have any spfile, control file or archived redo log file. But in order to retrieve all datafiles we need control file, and to retrieve
   control file we need spfile. 

	[oracle@node1 ~]$ cd $ORACLE_HOME
	[oracle@node1 dbhome_3]$ cd dbs
	[oracle@node1 dbs]$ ls -lrt
	total 18420
	-rw-r--r--. 1 oracle oinstall     3079 May 14  2015 init.ora
	-rw-r-----. 1 oracle oinstall       24 Apr 26 20:47 lkPRIM
	-rw-r-----. 1 oracle oinstall     2048 Apr 26 20:49 orapwprim
	-rw-r--r--. 1 oracle oinstall     1042 Apr 30 23:57 initprim.ora
	-rw-r-----. 1 oracle oinstall 18841600 Jun  6 13:31 c-196814088-20250606-01
	-rw-rw----. 1 oracle oinstall     1544 Jun  6 13:50 hc_prim.dat
	[oracle@node1 dbs]$

	ðŸ”¸So we need to start the db in nomount state for which we require spfile but since we know that if the spfile is missing we can use the pfile to start the database in 
	  nomount state, but if pfile is also missing we can create a dummy pfile.txt and put this one parameter "*.db_name='prim'" to start the database in nomount state.
=========================================================================================================
6) Now in our case the pfile(initprim.ora) is present so we can restore the spfile in no mount state

	ðŸ”¹ðŸ”¹SQL> startup nomount pfile='initprim.ora';
=========================================================================================================
7) Now exit sql and open rman and restore spfile from path /data/rman

	[oracle@node1 rman]$ ll
	total 4003580
	-rw-r-----. 1 oracle oinstall  82843136 Jun  6 13:30 PRIM_A_20250606_1b3rb502_s43_p1
	-rw-r-----. 1 oracle oinstall   2086400 Jun  6 13:30 PRIM_A_20250606_1c3rb502_s44_p1
	-rw-r-----. 1 oracle oinstall     10240 Jun  6 13:30 PRIM_A_20250606_1d3rb502_s45_p1
	-rw-r-----. 1 oracle oinstall      8192 Jun  6 13:31 PRIM_A_20250606_1q3rb50v_s58_p1
	-rw-r-----. 1 oracle oinstall  18808832 Jun  6 13:31 PRIM_C_20250606_1o3rb50t        ==================> controlfile
	-rw-r-----. 1 oracle oinstall 937549824 Jun  6 13:30 PRIM_D_20250606_1e3rb503_s46_p1
	-rw-r-----. 1 oracle oinstall 833789952 Jun  6 13:30 PRIM_D_20250606_1f3rb503_s47_p1
	-rw-r-----. 1 oracle oinstall  13107200 Jun  6 13:30 PRIM_D_20250606_1g3rb503_s48_p1
	-rw-r-----. 1 oracle oinstall 634298368 Jun  6 13:31 PRIM_D_20250606_1h3rb50j_s49_p1
	-rw-r-----. 1 oracle oinstall 499171328 Jun  6 13:31 PRIM_D_20250606_1i3rb50j_s50_p1
	-rw-r-----. 1 oracle oinstall 266715136 Jun  6 13:31 PRIM_D_20250606_1j3rb50j_s51_p1
	-rw-r-----. 1 oracle oinstall 262995968 Jun  6 13:31 PRIM_D_20250606_1k3rb50q_s52_p1
	-rw-r-----. 1 oracle oinstall 229457920 Jun  6 13:31 PRIM_D_20250606_1l3rb50r_s53_p1
	-rw-r-----. 1 oracle oinstall 228622336 Jun  6 13:31 PRIM_D_20250606_1m3rb50r_s54_p1
	-rw-r-----. 1 oracle oinstall  90079232 Jun  6 13:31 PRIM_D_20250606_1n3rb50t_s55_p1
	-rw-r-----. 1 oracle oinstall    114688 Jun  6 13:31 PRIM_S_20250606_1p3rb50u         =================> spfile
	
	ðŸ”¹RMAN> restore spfile from '/data/rman/PRIM_S_20250606_1p3rb50u';
	
	[oracle@node1 dbs]$ ll
	total 18424
	-rw-r-----. 1 oracle oinstall 18841600 Jun  6 13:31 c-196814088-20250606-01
	-rw-rw----. 1 oracle oinstall     1544 Jun  6 14:03 hc_prim.dat
	-rw-r--r--. 1 oracle oinstall     3079 May 14  2015 init.ora
	-rw-r--r--. 1 oracle oinstall     1042 Apr 30 23:57 initprim.ora
	-rw-r-----. 1 oracle oinstall       24 Apr 26 20:47 lkPRIM
	-rw-r-----. 1 oracle oinstall     2048 Apr 26 20:49 orapwprim
	-rw-r-----. 1 oracle oinstall     3584 Jun  6 14:07 spfileprim.ora =====================> spfile is backedup
	[oracle@node1 dbs]$
=========================================================================================================
8) Now since the DB is started using the pfile so we need to shutdown it and start in nomount state using spfile.
	ðŸ”¹ðŸ”¹SQL> startup nomount;
=========================================================================================================
9) Now exit sql and open rman and restore controlfile from path /data/rman
	ðŸ”¹RMAN> restore controlfile from '/data/rman/PRIM_C_20250606_1o3rb50t';
	
	[oracle@node1 ~]$ cd /data/app/oracle/oradata/PRIM
	[oracle@node1 PRIM]$ ll
	total 54864
	-rw-r-----. 1 oracle oinstall 18726912 Jun  6 14:12 control01.ctl ==
	-rw-r-----. 1 oracle oinstall 18726912 Jun  6 14:12 control02.ctl =============> controlfile is backedup.
	-rw-r-----. 1 oracle oinstall 18726912 Jun  6 14:12 control03.ctl ==
	drwxr-x---. 2 oracle oinstall        6 Jun  6 13:50 pdbprim
	drwxr-x---. 2 oracle oinstall        6 Jun  6 13:50 PDBPRIM2
	drwxr-x---. 2 oracle oinstall        6 Jun  6 13:50 pdbseed
=========================================================================================================
10) Now since we have the controlfiles we can start the DB in mount state using controlfile.
	ðŸ”¹ðŸ”¹SQL> alter database mount;

	Database altered.
=========================================================================================================
11) Now before restoring datafile we need to catalog the path where data files are backedup so the controlfile will know about it.
	ðŸ”¹RMAN> catalog start with '/data/rman/';
=========================================================================================================
12) To Restore datafiles
	ðŸ”¹RMAN> restore database;
=========================================================================================================
13) To Restore archive redo log files.
	ðŸ”¹RMAN> recover database;
	ðŸ”¹RMAN> alter database open resetlogs; ========> to reset log sequence from 1.

	Statement processed

	ðŸ”¹RMAN> exit
=========================================================================================================



++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
âœ…To take LEVEL 1 BACKUP Of DB and do Point in time RECOVERY for data update after LEVEL 1 using archive redo logs and DROP DB using dbca and then RESTORE DB using RMAN.
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


=========================================================================================================
1) Insert new records in u1.t1 to take level 1 backup.
	ðŸ”¹ðŸ”¹SQL> select count(*) from u1.t1;
	
	COUNT(*)
	----------
			24
			
			Now take LEVEL 0 backup
	
	ðŸ”¹ðŸ”¹SQL> insert into u1.t1 select * from u1.t1;
	
	24 rows created.
	
	ðŸ”¹ðŸ”¹SQL> select count(*) from u1.t1;
	
	COUNT(*)
	----------
			48
	
	ðŸ”¹ðŸ”¹SQL> commit;
	
	Commit complete.
=========================================================================================================
2) Now run level 1 backup script 
	ðŸ”¹RUN
		{
		ALLOCATE CHANNEL ch11 TYPE DISK MAXPIECESIZE 10G;
		ALLOCATE CHANNEL ch12 TYPE DISK MAXPIECESIZE 10G;
		ALLOCATE CHANNEL ch13 TYPE DISK MAXPIECESIZE 10G;
		BACKUP
		FORMAT '/data/rman/%d_LEVEL1_D_%T_%u_s%s_p%p'
		INCREMENTAL LEVEL 1 DATABASE
		CURRENT CONTROLFILE
		FORMAT '/data/rman/%d_LEVEL1_C_%T_%u'
		SPFILE
		FORMAT '/data/rman/%d_LEVEL1_S_%T_%u'
		PLUS ARCHIVELOG
		FORMAT '/data/rman/%d_LEVEL1_A_%T_%u_s%s_p%p';
		RELEASE CHANNEL ch11;
		RELEASE CHANNEL ch12;
		RELEASE CHANNEL ch13;
		}
		
	ðŸ”¸Now the LEVEL 1 backup is present in /data/rman
	
	[oracle@node1 rman]$ ll
	total 5417556
	-rw-r-----. 1 oracle oinstall   82843136 Jun  6 23:13 PRIM_LEVEL0_A_20250606_2t3rc74q_s93_p1
	-rw-r-----. 1 oracle oinstall   44328448 Jun  6 23:13 PRIM_LEVEL0_A_20250606_2u3rc74q_s94_p1
	-rw-r-----. 1 oracle oinstall   12155904 Jun  6 23:13 PRIM_LEVEL0_A_20250606_2v3rc74q_s95_p1
	-rw-r-----. 1 oracle oinstall    2099712 Jun  6 23:13 PRIM_LEVEL0_A_20250606_303rc74r_s96_p1
	-rw-r-----. 1 oracle oinstall      20480 Jun  6 23:13 PRIM_LEVEL0_A_20250606_313rc74r_s97_p1
	-rw-r-----. 1 oracle oinstall      19456 Jun  6 23:13 PRIM_LEVEL0_A_20250606_3e3rc75k_s110_p1
	-rw-r-----. 1 oracle oinstall   18808832 Jun  6 23:13 PRIM_LEVEL0_C_20250606_3c3rc75h
	-rw-r-----. 1 oracle oinstall  937549824 Jun  6 23:13 PRIM_LEVEL0_D_20250606_323rc74t_s98_p1
	-rw-r-----. 1 oracle oinstall  865083392 Jun  6 23:13 PRIM_LEVEL0_D_20250606_333rc74t_s99_p1
	-rw-r-----. 1 oracle oinstall 1116512256 Jun  6 23:13 PRIM_LEVEL0_D_20250606_343rc74t_s100_p1
	-rw-r-----. 1 oracle oinstall  635199488 Jun  6 23:13 PRIM_LEVEL0_D_20250606_353rc754_s101_p1
	-rw-r-----. 1 oracle oinstall  501825536 Jun  6 23:13 PRIM_LEVEL0_D_20250606_363rc754_s102_p1
	-rw-r-----. 1 oracle oinstall  356556800 Jun  6 23:13 PRIM_LEVEL0_D_20250606_373rc755_s103_p1
	-rw-r-----. 1 oracle oinstall  262995968 Jun  6 23:13 PRIM_LEVEL0_D_20250606_383rc756_s104_p1
	-rw-r-----. 1 oracle oinstall  229875712 Jun  6 23:13 PRIM_LEVEL0_D_20250606_393rc75e_s105_p1
	-rw-r-----. 1 oracle oinstall  228622336 Jun  6 23:13 PRIM_LEVEL0_D_20250606_3a3rc75e_s106_p1
	-rw-r-----. 1 oracle oinstall   90079232 Jun  6 23:13 PRIM_LEVEL0_D_20250606_3b3rc75e_s107_p1
	-rw-r-----. 1 oracle oinstall     114688 Jun  6 23:13 PRIM_LEVEL0_S_20250606_3d3rc75h
	-rw-r-----. 1 oracle oinstall   82843136 Jun  6 23:15 PRIM_LEVEL1_A_20250606_3g3rc795_s112_p1
	-rw-r-----. 1 oracle oinstall   45173248 Jun  6 23:15 PRIM_LEVEL1_A_20250606_3h3rc795_s113_p1
	-rw-r-----. 1 oracle oinstall   12173824 Jun  6 23:15 PRIM_LEVEL1_A_20250606_3i3rc795_s114_p1
	-rw-r-----. 1 oracle oinstall    2099712 Jun  6 23:15 PRIM_LEVEL1_A_20250606_3j3rc796_s115_p1
	-rw-r-----. 1 oracle oinstall       8192 Jun  6 23:15 PRIM_LEVEL1_A_20250606_403rc79f_s128_p1
	-rw-r-----. 1 oracle oinstall   18808832 Jun  6 23:15 PRIM_LEVEL1_C_20250606_3u3rc79d
	-rw-r-----. 1 oracle oinstall      73728 Jun  6 23:15 PRIM_LEVEL1_D_20250606_3k3rc798_s116_p1
	-rw-r-----. 1 oracle oinstall     942080 Jun  6 23:15 PRIM_LEVEL1_D_20250606_3l3rc798_s117_p1
	-rw-r-----. 1 oracle oinstall     270336 Jun  6 23:15 PRIM_LEVEL1_D_20250606_3m3rc798_s118_p1
	-rw-r-----. 1 oracle oinstall     262144 Jun  6 23:15 PRIM_LEVEL1_D_20250606_3n3rc79b_s119_p1
	-rw-r-----. 1 oracle oinstall      98304 Jun  6 23:15 PRIM_LEVEL1_D_20250606_3o3rc79b_s120_p1
	-rw-r-----. 1 oracle oinstall     114688 Jun  6 23:15 PRIM_LEVEL1_S_20250606_3v3rc79d
=========================================================================================================
3) Now inserting more 48 records in u1.t1 and switching logfile by CDB to move the redo logs in archived redo logs.

	ðŸ”¹ðŸ”¹SQL> select count(*) from u1.t1;
	
	COUNT(*)
	----------
			96
	
	ðŸ”¹ðŸ”¹SQL> commit;
	
	Commit complete.
			
	ðŸ”¹ðŸ”¹SQL> alter session set container=CDB$ROOT;
	
	Session altered.
	
	ðŸ”¹ðŸ”¹SQL> alter system switch logfile;
	
	System altered.
	
	Now shutdown DB and start in restrict mode(no user can log in during that period).
	ðŸ”¹ðŸ”¹SQL> startup mount restrict;
=========================================================================================================
4) Now dropping the DB using dbca

	{âš ï¸Note :- when we drop db using dbca all the physical files are dropped along with their path(folder) so we need to copy the paths first before dropping and 
			   create the same before restoration.}
	mkdir -p /data/app/oracle/oradata/PRIM                   /control01.ctl
	mkdir -p /data/app/oracle/oradata/PRIM/PDBPRIM2          /system01.dbf
	mkdir -p /data/app/oracle/oradata/PRIM/pdbprim           /system01.dbf
	mkdir -p /data/app/oracle/oradata/PRIM/pdbseed           /system01.dbf
=========================================================================================================	
5)Now since the DB is dropped we will create dummy pfile and follow the restore process.
	
	ðŸ”¹ðŸ”¹SQL> startup nomount pfile='/data/app/oracle/product/19C/dbhome_3/dbs/initprim.ora';
	
	ðŸ”¹RMAN> restore spfile from '/data/rman/PRIM_LEVEL1_S_20250606_2r3rc0d1';
	
	Create new pfile.
	ðŸ”¹ðŸ”¹SQL> create pfile from spfile;
	
	File created.
	
	Now since the the audit log dump path is not created in spfile so we need to create one.
	
	ðŸ”¹[oracle@node1 ~]$ mkdir -p /data/app/oracle/admin/prim/adump
	
	ðŸ”¹ðŸ”¹SQL> startup nomount;
	
	ðŸ”¹RMAN> restore controlfile from '/data/rman/PRIM_LEVEL1_C_20250606_2q3rc0d1';
	
	ðŸ”¹ðŸ”¹SQL> alter database mount;
	
	Database altered.
	
	ðŸ”¹RMAN> catalog start with '/data/rman/';
	
	ðŸ”¹RMAN> restore database;
	
	ðŸ”¹RMAN> recover database;
	
	ðŸ”¹RMAN> alter database open resetlogs; (To reset the archive log sequencing from 1 again)
	
	Statement processed
	
	ðŸ”¹RMAN> exit
	
ðŸ”¸Now since we have done logfile switching by CDB to move the redo logs in archived redo logs so we got our 96 count which is called Point in time recovery.
	
	ðŸ”¹ðŸ”¹SQL> select count(*) from u1.t1;
	
	COUNT(*)
	----------
			96
=========================================================================================================
	


ðŸ” What Are Audit Logs?
	Audit logs record who did what in the database. For example:
	
	Who logged in?
	
	Who created or dropped a table?
	
	Who updated sensitive data?
	
	Stored in /adump directory

	eg) /data/app/oracle/admin/prim/adump
	ðŸ”¹[oracle@node1 adump]$ cat prim_ora_9806_20250609150743411523712338.aud
	Audit file /data/app/oracle/admin/prim/adump/prim_ora_9806_20250609150743411523712338.aud
	Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production
	Version 19.14.0.0.0
	
	Build label:    RDBMS_19.14.0.0.0DBRU_LINUX.X64_211224.3
	ORACLE_HOME:    /data/app/oracle/product/19C/dbhome_3
	System name:    Linux
	Node name:      node1.learnomate.org
	Release:        4.14.35-1902.300.11.el7uek.x86_64
	Version:        #2 SMP Tue Mar 17 17:11:47 PDT 2020
	Machine:        x86_64
	Instance name: prim
	Redo thread mounted by this instance: 1
	Oracle process number: 53
	Unix process pid: 9806, image: oracle@node1.learnomate.org (TNS V1-V3)
	
	Mon Jun  9 15:07:43 2025 +05:30
	LENGTH : '269'
	ACTION :[7] 'CONNECT'
	DATABASE USER:[1] '/'
	PRIVILEGE :[6] 'SYSDBA'
	CLIENT USER:[6] 'oracle'
	CLIENT TERMINAL:[5] 'pts/0'
	STATUS:[1] '0'
	DBID:[9] '196814088'
	SESSIONID:[10] '4294967295'
	USERHOST:[20] 'node1.learnomate.org'
	CLIENT ADDRESS:[0] ''
	ACTION NUMBER:[3] '100'
	
	Mon Jun  9 15:07:43 2025 +05:30
	LENGTH : '267'
	ACTION :[6] 'COMMIT'
	DATABASE USER:[1] '/'
	PRIVILEGE :[6] 'SYSDBA'
	CLIENT USER:[6] 'oracle'
	CLIENT TERMINAL:[5] 'pts/0'
	STATUS:[1] '0'
	DBID:[9] '196814088'
	SESSIONID:[10] '4294967295'
	USERHOST:[20] 'node1.learnomate.org'
	CLIENT ADDRESS:[0] ''
	ACTION NUMBER:[2] '44'
	
	Mon Jun  9 15:07:43 2025 +05:30
	LENGTH : '267'
	ACTION :[6] 'COMMIT'
	DATABASE USER:[1] '/'
	PRIVILEGE :[6] 'SYSDBA'
	CLIENT USER:[6] 'oracle'
	CLIENT TERMINAL:[5] 'pts/0'
	STATUS:[1] '0'
	DBID:[9] '196814088'
	SESSIONID:[10] '4294967295'
	USERHOST:[20] 'node1.learnomate.org'
	CLIENT ADDRESS:[0] ''
	ACTION NUMBER:[2] '44'
	
	Mon Jun  9 15:10:28 2025 +05:30
	LENGTH : '407'
	ACTION :[145] 'SELECT SYS_CONTEXT('USERENV','CDB_NAME'),    SYS_CONTEXT('USERENV','CON_NAME'),    SYS_CONTEXT('USERENV','IS_APPLICATION_ROOT')    FROM SYS.DUAL'
	DATABASE USER:[1] '/'
	PRIVILEGE :[6] 'SYSDBA'
	CLIENT USER:[6] 'oracle'
	CLIENT TERMINAL:[5] 'pts/0'
	STATUS:[1] '0'
	DBID:[9] '196814088'
	SESSIONID:[10] '4294967295'
	USERHOST:[20] 'node1.learnomate.org'
	CLIENT ADDRESS:[0] ''
	ACTION NUMBER:[1] '3'
	
	Mon Jun  9 15:16:24 2025 +05:30
	LENGTH : '289'
	ACTION :[27] 'ALTER DATABASE CLOSE NORMAL'
	DATABASE USER:[1] '/'
	PRIVILEGE :[6] 'SYSDBA'
	CLIENT USER:[6] 'oracle'
	CLIENT TERMINAL:[5] 'pts/0'
	STATUS:[1] '0'
	DBID:[9] '196814088'
	SESSIONID:[10] '4294967295'
	USERHOST:[20] 'node1.learnomate.org'
	CLIENT ADDRESS:[0] ''
	ACTION NUMBER:[2] '35'
	
	Mon Jun  9 15:16:24 2025 +05:30
	LENGTH : '276'
	ACTION :[23] 'ALTER DATABASE DISMOUNT'
	DATABASE USER:[1] '/'
	PRIVILEGE :[6] 'SYSDBA'
	CLIENT USER:[6] 'oracle'
	CLIENT TERMINAL:[5] 'pts/0'
	STATUS:[1] '0'
	DBID:[0] ''
	SESSIONID:[10] '4294967295'
	USERHOST:[20] 'node1.learnomate.org'
	CLIENT ADDRESS:[0] ''
	ACTION NUMBER:[2] '35'
	
	Mon Jun  9 15:16:24 2025 +05:30
	LENGTH : '272'
	ACTION :[18] 'SHUTDOWN IMMEDIATE'
	DATABASE USER:[1] '/'
	PRIVILEGE :[6] 'SYSDBA'
	CLIENT USER:[6] 'oracle'
	CLIENT TERMINAL:[5] 'pts/0'
	STATUS:[1] '0'
	DBID:[0] ''
	SESSIONID:[10] '4294967295'
	USERHOST:[20] 'node1.learnomate.org'
	CLIENT ADDRESS:[0] ''
	ACTION NUMBER:[3] '139'


ðŸ§  Trace Logs:
Think of trace logs like a black box in an airplane. When something goes wrong in Oracle, trace logs record the exact actions and errors that happened behind the 
scenes â€” super useful for finding out what went wrong and why.
â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–



ðŸ“ŒPATCHING
------------
Patching refers to the process of applying software updates to Oracle components which are provided by oracle support quarterly. These patches fix bugs, improve performance, 
and address security vulnerabilities. Patching is a offline activity.

âœ…TYPES:--

1) Patch Set Update (PSU) - Cumulative patches that include High priority + Security patches.

2) Critical Patch Update (CPU) - Security-specific patches released quarterly.

3) One-off Patch - Fixes a specific bug. Usually requested through Oracle Support.

ðŸ”¸ OPatch is the utility used to perform patching. When you download patch we get one readme.html file which has the information related to patching prerequisites and how to 
	apply.

ðŸ”¸ Prerequisites for Patching:-
	â—ˆ Upgrade the opatch version as per the requirement of patching.
	â—ˆ Avoid conflict of patches (Overlaps with an existing patch already applied).
	â—ˆ Enough system space to apply patching.
	â—ˆ Need to shutdown DB and other services.
	â—ˆ We can apply patch.
	{âš ï¸Note :- Check Invalid object count before and after patching it should be same}
	
ðŸ”¸ Command to check opatch version:-
	ðŸ”¹ [oracle@node1 ~]$ $ORACLE_HOME/OPatch/opatch version
	OPatch Version: 12.2.0.1.17

	OPatch succeeded.
	
âœ… Steps for Patching.

1) Download patch from oracle support.

	ðŸ”¸ p6880880_122010_Linux-x86-64.zip  ==> Fixed reference number that Oracle uses on its support site to always point to the latest version of a particular tool or patch.
	------------------------------------	 So every time Oracle releases a new OPatch version, they update the files under patch number 6880880.
		â—ˆ This is the OPatch Utility itself.
		â—ˆ Patch Number: 6880880 (Permanent patch number for OPatch)
		â—ˆ Purpose: Updates the OPatch tool inside your $ORACLE_HOME/OPatch directory.
		â—ˆ Use it when: You need to make sure you have the latest OPatch before applying other patches.
		
	ðŸ”¸ p33509923_190000_Linux-x86-64.zip
	-------------------------------------
		â—ˆ This is an actual Oracle Database / Grid Infrastructure patch.
		â—ˆ Patch Number: 33509923
		â—ˆ Purpose: Updates your Oracle Grid Infrastructure and/or Database Home to include new features, security fixes, and bug fixes.
		â—ˆ Use it when: Update Oracle GI/DB
		
2) Create directory on linux. ==> mkdir -p  /data/patches
3) Upload the patches in /data/patches and unzip them.
4) Now open patch 33509923(CPU) and read the readme.html and check the OPatch utility version before applying. There are many sub patches inside this patch for 
   oracle home and grid home.
	Sub patches ===>
	Patch Number					Description								Applicable Homes
	a)33515361 			Database Release Update 19.14.0.0.220118			Only Oracle home
	b)33529556			OCW Release Update 19.14.0.0.220118			Both Oracle home and Grid home.
	
5) Now the version required to apply this patch is 12.2.0.1.28 or greater and our version is 12.2.0.1.17 so we need to upgrade.
6) We can check the latest OPatch Utility version for p6880880 inside a version.txt file inside the folder in windows (path: p6880880_122010_Linux-x86-64\OPatch\version.txt)
   i.e OPATCH_VERSION:12.2.0.1.29
   
7) Now to upgrade the our opatch version we need to replace the OPatch folder in our linux server with the OPatch folder of the p6880880_122010_Linux-x86-64.zip.
8) Rename our OPatch folder as old.
	ðŸ”¹ [oracle@node1 ~]$ mv $ORACLE_HOME/OPatch $ORACLE_HOME/OPatch_old
9) Now put the OPatch folder(which we get after unzipping p6880880_122010_Linux-x86-64.zip) from /data/patches to $ORACLE_HOME
	ðŸ”¹ cp -R OPatch $ORACLE_HOME
10) Now if we check the opatch version.
	ðŸ”¹[oracle@node1 OPatch]$ 		
	  OPatch Version: 12.2.0.1.29
	  
	  OPatch succeeded.
	  
11) Now check the prerequisites from readme.html

	â—ˆ check invalid object count:- (It should be zero before and after applying patch)
		ðŸ”¹SQL> select count(*) from dba_objects where status='INVALID';
		
		COUNT(*)
		----------
				0
	{âš ï¸Note :- if not proper:- run script	cd $ORACLE_HOME/rdbms/admin
											sqlplus /nolog
											ðŸ”¹SQL> CONNECT / AS SYSDBA
											ðŸ”¹SQL> @utlrp.sql
	
	â—ˆ check conflicts:- (run this commands one by one for both subpatches to check any conflicts if it comes "passed" and "OPatch succeeded" then no conflict.)
		ðŸ”¹ $ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /data/patches/33509923/33515361
		ðŸ”¹ $ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /data/patches/33509923/33529556
	{âš ï¸Note :- if not proper:- $ORACLE_HOME/OPatch/opatch rollback -id <PATCH_NUMBER>}
	
	â—ˆ check system space:- 
		1) Create temporary file ==> vi /tmp/patch_list_dbhome.txt to Check many patches at once. And insert the following content:
			/data/patches/33509923/33515361
			/data/patches/33509923/33529556
		2) now run command (if it comes "passed" and "OPatch succeeded" then no space issue.)
			ðŸ”¹ $ORACLE_HOME/OPatch/opatch prereq CheckSystemSpace -phBaseFile /tmp/patch_list_dbhome.txt
	{âš ï¸Note :- if not proper:- Clear space}
	
12) To apply software level patch:-

	1) For 33515361 go to that path
	/data/patches/33509923
	ðŸ”¹ [oracle@node1 33509923]$ ls -lrt
	total 136
	drwxr-x---. 4 oracle oinstall     48 Jan 13  2022 33575402
	drwxr-x---. 5 oracle oinstall     62 Jan 13  2022 33534448
	drwxr-x---. 2 oracle oinstall   4096 Jan 13  2022 automation
	drwxr-x---. 5 oracle oinstall     81 Jan 13  2022 33515361
	-rw-r--r--. 1 oracle oinstall      0 Jan 13  2022 README.txt
	drwxr-x---. 5 oracle oinstall     62 Jan 13  2022 33529556
	drwxr-x---. 4 oracle oinstall     48 Jan 13  2022 33239955
	-rw-rw-r--. 1 oracle oinstall   5824 Jan 13  2022 bundle.xml
	-rw-r--r--. 1 oracle oinstall 123797 Jan 20  2022 README.html
	
	cd 33515361
	/data/patches/33509923/33515361
	
	ðŸ”¹ [oracle@node1 33515361]$ $ORACLE_HOME/OPatch/opatch apply
	Patch 33515361 successfully applied.
	Sub-set patch [29517242] has become inactive due to the application of a super-set patch [33515361].
	Please refer to Doc ID 2161861.1 for any possible further required actions.
	Log file location: /data/app/oracle/product/19C/dbhome_3/cfgtoollogs/opatch/opatch2025-06-08_23-53-54PM_1.log
	
	OPatch succeeded.


	2) For 33529556 go to that path
	cd /data/patches/33509923/33529556
	
	ðŸ”¹ [oracle@node1 33529556]$ $ORACLE_HOME/OPatch/opatch apply
	Patch 33529556 successfully applied.
	Sub-set patch [29585399] has become inactive due to the application of a super-set patch [33529556].
	Please refer to Doc ID 2161861.1 for any possible further required actions.
	Log file location: /data/app/oracle/product/19C/dbhome_3/cfgtoollogs/opatch/opatch2025-06-09_00-01-51AM_1.log
	
	OPatch succeeded.
	
13) To apply DB level patch:-
	{âš ï¸Note :- For DB level patch start CDB and PDB both}
	Go to $ORACLE_HOME/OPatch and run the datapatch script.
	 ðŸ”¹[oracle@node1 OPatch]$ cd $ORACLE_HOME/OPatch
	 ðŸ”¹[oracle@node1 OPatch]$ nohup ./datapatch & (run in background)
	Now "nohup.out" output log file is created in same path.
	
	ðŸ”¹ [oracle@node1 OPatch]$ jobs
	[1]+  Running                 nohup ./datapatch &
	ðŸ”¹ [oracle@node1 OPatch]$ jobs
	[1]+  Done                    nohup ./datapatch


âœ… Frequently Used OPatch Commands

| **Purpose**            | **Command**                                             | **Notes**                                  |
| ---------------------- | ------------------------------------------------------- | ------------------------------------------ |
| Check applied patches  | `opatch lsinventory`                                    | Lists all installed patches                |
| Check OPatch version   | `opatch version`                                        | Shows current OPatch utility version       |
| Apply a patch          | `opatch apply`                                          | Run from inside the patch directory        |
| Rollback a patch       | `opatch rollback -id <patch_number>`                    | Removes the specified patch                |
| Check patch conflicts  | `opatch prereq CheckConflictAgainstOHWithDetail -ph ./` | Run from the patch folder                  |
| Apply multiple patches | `opatch napply -skip_subset -skip_duplicate`            | Used for bundles with multiple sub-patches |
| Validate Oracle Home   | `opatch util validate`                                  | Checks Oracle Home for issues              |
â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–



ðŸ“ŒUPGRADATION
---------------
Upgradation in Oracle Database means moving from an older version of Oracle Database (e.g., 12c, 18c, or 19c) to a newer version (e.g., 21c or later). The goal is to take 
advantage of new features, enhanced performance, bug fixes, and better security.
{âš ï¸Note :- Note this is software level upgradation and not DB level i.e 12c software to 19c software.}

âœ…COMPATIBILTY CHECKS:-

1) OS LEVEL:- An OS-level compatibility check ensures that your operating system (Linux, Windows, etc.) and its configuration are certified, supported, and capable of running 
			  the target Oracle Database version (like 19c or 21c).
âž¡ï¸		  
| Oracle DB Version | Supported OS (Example)                         |
| ----------------- | ---------------------------------------------- |
| 19c               | RHEL/CentOS/OL 7 & 8, Windows Server 2016/2019 |
| 21c               | OL 8+, RHEL 8+, Windows 2019/2022              |

 
2) DB LEVEL:- A DB-level compatibility check is like a health check for your current Oracle Database before upgrading it to a newer version (like from 12c to 19c or 21c).
			  Make sure your source version is directly upgradable to the target version.
âž¡ï¸			  
| Upgrade To | Supported From                    |
| ---------- | --------------------------------- |
| 19c        | 11.2.0.4, 12.1.0.2, 12.2.0.1, 18c |
| 21c        | 12.2.0.1, 18c, 19c                |


3) APP lEVEL:- Making sure your business application (like ERP, CRM, custom app, etc.) will work properly after the Oracle Database upgrade (e.g., 12c â†’ 19c). All these apps 
			  (ERP, CRM, custom) store or fetch data from the Oracle Database.
			  
âž¡ï¸ When you upgrade the database, you must make sure:

ðŸ”¹These apps still work

ðŸ”¹Their queries and reports donâ€™t break

ðŸ”¹They can still connect to the new version safely


âœ… Types of Upgrade Methods:-

	1. Manual Upgrade (Using SQL Scripts)
	
		ðŸ”¹ You run preupgrade.jar which creates =>logfile, preupgrade_fixups.sql, postupgrade_fixups.sql then use catctl.pl and catupgrd.sql to manually upgrade.
	
		ðŸ”¹ Suitable for experienced DBAs.
	
	2. DBUA (Database Upgrade Assistant)
	
		ðŸ”¹ GUI-based tool provided by Oracle.
	
		ðŸ”¹ Simplifies upgrade process.
	
		ðŸ”¹ Good for non-critical or dev/test environments.
		


-------------------------------------------------------------------------ðŸ“Œ12c DB + Software Installation-----------------------------------------------------------------------------------------

ðŸ‘‰1) Create new Oracle Linux server.
ðŸ‘‰2) Login from Root user.
	ðŸ”¹ yum install oracle-database-server-12cR2-preinstall -y  ===>Packages installation 12c
ðŸ‘‰3) Now oracle user will be automatically downloaded.
ðŸ‘‰4) Set bash profile by oracle user for 12c.
ðŸ‘‰5) Create staging directory from root user where the software will be uploaded.(But in case of 19c we always upload our software in oracle_home).
	ðŸ”¹ [oracle@node2 ~]$ mkdir -p /u01/staging
ðŸ‘‰6) Create oracle_home and change group and give permissions
	ðŸ”¹ [root@node2 ~]# mkdir -p /u01/app/oracle/product/12.2.0/dbhome_1
	ðŸ”¹ [root@node2 ~]# chown -R oracle:oinstall /u01
	ðŸ”¹ [root@node2 ~]# chmod -R 755 /u01
ðŸ‘‰7) upload software to /u01/staging and change group again if not proper and then unzip

	ðŸ”¹ [oracle@node2 staging]$ ll
	total 3372752
	-rw-rw-r--. 1 oracle oracle 3453696911 Jun 15 21:56 linuxx64_12201_database.zip
	
	ðŸ”¹ [root@node2 ~]# chown -R oracle:oinstall /u01
	ðŸ”¹ [root@node2 ~]# chmod -R 755 /u01
	ðŸ”¹ [oracle@node2 staging]$ ll
	total 3372752
	-rwxr-xr-x. 1 oracle oinstall 3453696911 Jun 15 21:56 linuxx64_12201_database.zip
	ðŸ”¹ [oracle@node2 staging]$ unzip linuxx64_12201_database.zip

ðŸ‘‰8) run installer
	ðŸ”¹ [oracle@node2 staging]$ ls -lrt
	total 3372756
	drwxr-xr-x. 7 oracle oracle         4096 Jan 26  2017 database
	-rwxr-xr-x. 1 oracle oinstall 3453696911 Jun 15 21:56 linuxx64_12201_database.zip
	ðŸ”¹ [oracle@node2 staging]$ cd database
	ðŸ”¹ [oracle@node2 database]$ ./runInstaller
	
ðŸ‘‰9) From root user do entry of node and ip in /etc/hosts
	ðŸ”¹ [root@node2 ~]# vi /etc/hosts
	ðŸ”¹ [root@node2 ~]# cat /etc/hosts
	127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
	::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
	192.168.10.100  node2   node2.learnomate.org  <=================== Do this entry.
	
ðŸ‘‰9) Now in "Recovery Options" section select archive log mode create directory in oracle user to store all archive logs
	ðŸ”¹ [oracle@node2 ~]$ mkdir -p /u01/archive

ðŸ‘‰10) Type "oracle" password for all users. and start installation.

ðŸ‘‰11)Run below scripts with root user when the dialogue box appears.
	ðŸ”¹ /u01/app/oraInventory/orainstRoot.sh
	ðŸ”¹ /u01/app/oracle/product/12.2.0/dbhome_1/root.sh
	
close gui dialogue box after successful installation.

-------------------------------------------------------------------------ðŸ“Œ19c Software only Installation-----------------------------------------------------------------------------------------

	
ðŸ‘‰12) Now create 19c path in oracle user 
	ðŸ”¹ [oracle@node2 ~]$ mkdir -p  /u01/app/oracle/product/19.0.0/dbhome_1

ðŸ‘‰13) Login from Root user.
	ðŸ”¹ [root@node2 ~]# yum install -y oracle-database-preinstall-19c	===>Packages installation 19c

ðŸ‘‰14) Now put 19c software in /u01/app/oracle/product/19.0.0/dbhome_1 and unzip
	ðŸ”¹ [oracle@node2 dbhome_1]$ unzip LINUX.X64_193000_db_home.zip

ðŸ‘‰15) runInstaller
	ðŸ”¹ [oracle@node2 dbhome_1]$ ./runInstaller

	Now similarly a 19c gui will open now select "Set Up Software Only" in Database installation options.
	=>Set Up Software Only
	=>single instance
	=>root script execution select checkbox and put root password then root scripts will run automatically.
	
	Now the oracle 19c software only is installed.
	
-------------------------------------------------------------------------ðŸ“ŒUpgradation-----------------------------------------------------------------------------------------

ðŸ‘‰16) open sql and check invalid object count it should be same before and after upgradation.

	ðŸ”¹ ðŸ”¹SQL> select count(*) from dba_objects where status='INVALID';
	
	COUNT(*)
	----------
			0

ðŸ‘‰17) Now startup CDB & PDB and run "pre upgrade.jar"(checks the readiness of your current database for upgrade and gives detailed recommendations.)
	ðŸ”¹ /u01/app/oracle/product/12.2.0/dbhome_1/jdk/bin/java -jar /u01/app/oracle/product/19.0.0/dbhome_1/rdbms/admin/preupgrade.jar FILE DIR /home/oracle/PRIM/preupgrade.
	
ðŸ‘‰18) Now run preupgrade_fixups.sql in sql
	ðŸ”¹ ðŸ”¹SQL> @/home/oracle/PRIM/preupgrade./preupgrade_fixups.sql
	
ðŸ‘‰19) Now put DB in archive log mode.

ðŸ‘‰20) Create Flashback Guaranteed Restore Point

=> A Guaranteed Restore Point is a powerful Oracle feature that allows you to safely rewind your database back to a known good state â€” even after major changes like patching,
   schema changes, or upgrades.
   
	ðŸ”¹ ðŸ”¹SQL> !mkdir -p /u01/app/oracle/fast_recovery_area 
	
	ðŸ”¹ ðŸ”¹SQL> alter system set db_recovery_file_dest_size=10G;
	
	System altered.
	
	ðŸ”¹ ðŸ”¹SQL> alter system set db_recovery_file_dest='/u01/app/oracle/fast_recovery_area';
	
	System altered.
	
	Now create the guarantee restore point.
	
	ðŸ”¹ ðŸ”¹SQL> create restore point pre_upgrade guarantee flashback database;

	Restore point created.
	
	ðŸ”¹ ðŸ”¹SQL> col name for a20
	col GUARANTEE_FLASHBACK_DATABASE for a10
	col TIME for a60
	set lines 190
	select NAME,GUARANTEE_FLASHBACK_DATABASE,TIME from V$restore_point;
	
		NAME                 GUARANTEE_ TIME
	-------------------- ---------- ------------------------------------------------------------
	PRE_UPGRADE          YES        15-JUN-25 11.59.29.000000000 PM

ðŸ‘‰21) Now shutdown database.

ðŸ‘‰22) Now we want to start DB by 19c but since we dont have spfile we will copy the 12c spfile to /u01/app/oracle/product/19.0.0/dbhome_1/dbs/
	ðŸ”¹ [oracle@node2 dbs]$ cp spfileprim.ora /u01/app/oracle/product/19.0.0/dbhome_1/dbs

ðŸ‘‰23) Startup DB in Upgrade mode from 19c home
=> Set environment variables

	ðŸ”¹ [oracle@node2 dbs]$ export ORACLE_SID=prim;
	ðŸ”¹ [oracle@node2 dbs]$ export ORACLE_HOME=/u01/app/oracle/product/19.0.0/dbhome_1
	ðŸ”¹ [oracle@node2 dbs]$ PATH=/u01/app/oracle/product/19.0.0/dbhome_1/bin:$PATH; export PATH
	ðŸ”¹ [oracle@node2 dbs]$ which sqlplus
	ðŸ”¹ /u01/app/oracle/product/19.0.0/dbhome_1/bin/sqlplus
	
	ðŸ”¹ ðŸ”¹SQL> startup upgrade;
	
ðŸ‘‰24) Run db upgrade.

	ðŸ”¹ [oracle@node2 dbs]$ mkdir -p /home/oracle/whileupgrade
	ðŸ”¹ [oracle@node2 dbs]$ cd /u01/app/oracle/product/19.0.0/dbhome_1/rdbms/admin
	ðŸ”¹ [oracle@node2 admin]$ nohup /u01/app/oracle/product/19.0.0/dbhome_1/perl/bin/perl catctl.pl -l /home/oracle/whileupgrade -n 4 catupgrd.sql &
	ðŸ”¹ [oracle@node2 admin]$ pwd
	ðŸ”¹ /u01/app/oracle/product/19.0.0/dbhome_1/rdbms/admin
	ðŸ”¹ [oracle@node2 admin]$ tail -f nohup.out ====> monitor the upgradation log
	ðŸ”¹ [oracle@node2 admin]$ jobs
	    [1]+  Running                 nohup /u01/app/oracle/product/19.0.0/dbhome_1/perl/bin/perl catctl.pl -l /home/oracle/whileupgrade -n 4 catupgrd.sql &
	ðŸ”¹ [oracle@node2 admin]$ jobs
	    [1]+  Done                    nohup /u01/app/oracle/product/19.0.0/dbhome_1/perl/bin/perl catctl.pl -l /home/oracle/whileupgrade -n 4 catupgrd.sql &



-------------------------------------------------------------------------ðŸ“ŒPOST Upgradation-----------------------------------------------------------------------------------------

ðŸ‘‰25) Set bash_profile to 19c
	# User specific environment and startup programs
	
	PATH=$PATH:$HOME/.local/bin:$HOME/bin
	export ORACLE_BASE=/u01/app/oracle/
	export ORACLE_SID=prim
	export ORACLE_HOME=/u01/app/oracle/product/19.0.0/dbhome_1    <===================== 19c
	export LD_LIBRARY_PATH=\$ORACLE_HOME/lib:/lib:/usr/lib
	export CLASSPATH=\$ORACLE_HOME/jlib:\$ORACLE_HOME/rdbms/jlib
	PATH=$PATH:$HOME/.local/bin:$ORACLE_HOME/bin
	export PATH

	Now open duplicate session so that changes are reflected and open sqlplus
	
		Last login: Mon Jun 16 19:30:30 2025 from 192.168.0.100
	[oracle@node2 ~]$ sqlplus / as sysdba
	
	SQL*Plus: Release 19.0.0.0.0 - Production on Mon Jun 16 19:35:07 2025   <=================== 19c
	Version 19.3.0.0.0
	
	Copyright (c) 1982, 2019, Oracle.  All rights reserved.
	
	Connected to an idle instance.
	
	ðŸ”¹SQL>

	ðŸ”¹ ðŸ”¹SQL> select name,open_mode,cdb,version,status from v$database,v$instance;
	
	NAME      OPEN_MODE            CDB VERSION           STATUS
	--------- -------------------- --- ----------------- ------------
	PRIM      READ WRITE           YES 19.0.0.0.0        OPEN
	
ðŸ‘‰26) Check the invalid object count it should be zero. If not then run below script.

	ðŸ”¹ ðŸ”¹SQL>@/u01/app/oracle/product/19.0.0/dbhome_1/rdbms/admin/utlrp.sql
	
ðŸ‘‰27) Now run post upgrade script.

	ðŸ”¹ ðŸ”¹SQL> @/home/oracle/PRIM/preupgrade./postupgrade_fixups.sql

ðŸ‘‰28) Check Timezone of DB 

	ðŸ”¹ ðŸ”¹SQL> COLUMN version FORMAT 99999;
	SELECT version FROM v$timezone_file;
	ðŸ”¹SQL>
	VERSION
	-------
		26
	
ðŸ‘‰29) Run two scripts to change the timezone of DB
	ðŸ”¹ ðŸ”¹SQL> @/u01/app/oracle/product/19.0.0/dbhome_1/rdbms/admin/utltz_upg_check.sql
	ðŸ”¹ ðŸ”¹SQL> @/u01/app/oracle/product/19.0.0/dbhome_1/rdbms/admin/utltz_upg_apply.sql
	ðŸ”¹ ðŸ”¹SQL> COLUMN version FORMAT 99999;
	ðŸ”¹ SELECT version FROM v$timezone_file;
	ðŸ”¹SQL>
	VERSION
	-------
		32


-------------------------------------------------------------------------ðŸ Upgradation Successful--------------------------------------------------------------------------------
â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–




ðŸ“ŒAUTOMATIC STORAGE MANAGEMENT(ASM) [aka Volume Manager]
------------------------------------
ASM simplifies and optimizes the storage of Oracle database files (like datafiles, control files, redo logs) by managing them across multiple disks.
Think of it as a smart storage layer that handles:

| Feature                           | Description                                                          |
| --------------------------------- | -------------------------------------------------------------------- |
| Striping  - RBAL Process          | Spreads data evenly across disks to improve performance.             |
| Mirroring                         | Protects against disk failures (normal/high redundancy).             |
| Simplified Storage Management     | No need for file systems or logical volumes â€” ASM handles it all.    |
| Scalability                       | Easily add/remove disks online without downtime.                     |
| Automatic Rebalancing             | Automatically redistributes data when storage configuration changes. |
| Supports CDB/PDB architecture     | Fully compatible with multitenant databases in 19c.                  |
| Redundancy						| Redundancy is the configuration level or policy you choose that 	   |
|									| determines how much mirroring ASM performs.						   |

ðŸ”¸ Now after installing ASM we will have two softwares in system 19c DB software & ASM software.

ðŸ”¸ So there will be two HOME's ORACLE_HOME & GRID_HOME and two users oracle & grid respectively.

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     ASM Architecture       â”‚       â”‚   Non-ASM (Traditional)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                                â”‚
              â–¼                                â–¼
         OS (OEL 7.9)                     OS (OEL 7.9)
              â”‚                                â”‚
              â–¼                                â–¼
      ASM Software (GRID)             OS File System (ext4/XFS)
              â”‚                                â”‚
              â–¼                                â–¼
      ASM File System (DGs)               DB Software (ORACLE_HOME)
              â”‚                                â”‚
              â–¼                                â–¼
     DB Software (ORACLE_HOME)             Database Instance
              â”‚                                â”‚
              â–¼                                â–¼
       Database Instance                 Database Files (datafiles,
   (+ASM mounts ASM Diskgroups)         redo logs, controlfiles etc.)
              â”‚
              â–¼
   Database Files in ASM Diskgroup
      (+DATA, +FRA, etc.)


| ASM Architecture                                              | Nonâ€‘ASM Architecture                              |
| ------------------------------------------------------------- | ------------------------------------------------- |
| Uses **ASM software** and **+ASM instance**                   | Uses **OS filesystem** (ext4/XFS)                 |
| Database files stored in **ASM Diskgroups** (`+DATA`, `+FRA`) | Files stored in regular paths like `/u01/oradata` |
| Grid Infrastructure (GI) must be installed                    | Only DB software is required                      |
| More scalable and suitable for RAC                            | Simpler for standalone DBs                        |

		
ðŸ§© Example:
	ðŸ”¸ You create 3 raw disks: /dev/sdb, /dev/sdc, /dev/sdd
	
	ðŸ”¸ ASM instance creates a diskgroup +DATA using these 3 disks.
	
	ðŸ”¸ Oracle database stores files like +DATA/ORCL/DATAFILE/system.123.456789 in that diskgroup.
	
âœ… NON ASM SCENARIO:-

A user fires a query. The Oracle database instance processes it â€” parsing, verifying, and executing it. If needed, the instance fetches the required data from 
database files (via the OS filesystem in Non-ASM), and then returns the result back to the user.

âœ… ASM SCENARIO:- 

A user fires a SQL query. The Oracle database instance receives the query, parses, verifies, and executes it.
If data is needed, the DB instance communicates with the +ASM instance, which manages the ASM disk groups (like +DATA, +FRA).
The ASM instance handles the I/O and retrieves the required data files from the ASM disks.
The database instance then processes the data and returns the result to the user.


ðŸ”¹ RBAL Process (Rebalance Process):-
----------------------------------------
RBAL stands for ReBalance ALlocation.

It is an ASM background process that coordinates disk rebalancing when:

A disk is added or removed from a disk group.

It tells other processes to move data evenly across disks.


ðŸ”¹ ASM Power Limit:-
--------------------------
Controls how fast rebalancing happens.

Set using the asm_power_limit parameter (range 1â€“1024).

Higher value = faster rebalance, but more CPU usage.
SQL> ALTER SYSTEM SET asm_power_limit = 8 SCOPE=BOTH;



ðŸ”¹ What is Redundancy in ASM?
---------------------------------
In ASM, redundancy controls how Oracle manages data mirroring (i.e., protecting against disk failures):

| Redundancy Level | ASM Mirrors Data? | Who Provides Redundancy? |
| ---------------- | ----------------- | ------------------------ |
| **External**     | âŒ No             | **Storage or OS (RAID)** |
| **Normal**       | âœ… Yes (2 copies) | ASM itself               |
| **High**         | âœ… Yes (3 copies) | ASM itself               |


ðŸ”¹ Files:-
-------------
spfiles are different because each instance has its own memory settings and parameters.

| File Type      | +ASM Instance   |  Database Instance    |
| -------------- | --------------- |  -------------------- |
| SPFILE         | âœ… Has its own  | âœ… Has its own        |
| Datafiles      | âŒ None         | âœ… Yes                |
| Control files  | âŒ None         | âœ… Yes                |
| Redo logs      | âŒ None         | âœ… Yes                |
| Uses ASM disks | âœ… Manages disks| âœ… Stores data in ASM |

------------------------------------------------------------------------------ðŸ“ŒASM SETUP-----------------------------------------------------------------------------------------

ðŸ‘‰1) Install 19c packages ðŸ”¹ => 	
ðŸ‘‰2) Install ASM package  ðŸ”¹ => yum -y install oracleasm*
					      ðŸ”¹ => yum -y install kmod-oracleasm*
ðŸ‘‰3) Add OS groups
	ðŸ”¹=>groupadd -g 54327 asmdba
	    groupadd -g 54328 asmoper
	    groupadd -g 54329 asmadmin
	  
ðŸ‘‰4) Add oracle user to asmdba as secondary group.
	ðŸ”¹ => usermod -a -G asmdba oracle
	
ðŸ‘‰5) Create GRID user
	ðŸ”¹ => useradd -u 54331 -g oinstall -G dba,asmdba,asmoper,asmadmin,racdba grid
	
ðŸ‘‰6) Create oracle and grid users password as "oracle" & "grid" respectively.
	ðŸ”¹ => passwd oracle, passwd grid
	
ðŸ‘‰7) Create ORACLE_HOME & GRID_HOME
	ðŸ”¹ => mkdir -p /u02/app/oracle
	ðŸ”¹ => mkdir -p /u02/app/oracle/product/19.3.0/db_home
	ðŸ”¹ => chown -R oracle:oinstall /u02/app/oracle
	
	ðŸ”¹ => mkdir -p /u01/app/grid/product/19.3.0/grid_home
	ðŸ”¹ => chown -R grid:oinstall /u01/app/grid
	ðŸ”¹ => chmod -R 775 /u01
	
ðŸ‘‰8) CONFIGURE ASM

	=> oracleasm configure -i
	
	O/P:-
	------
	Default user to own the driver interface []: grid
	Default group to own the driver interface []: oinstall
	Start Oracle ASM library driver on boot (y/n) [n]: y
	Scan for Oracle ASM disks on boot (y/n) [y]: y
	Writing Oracle ASM library driver configuration: done
	
ðŸ‘‰9) Load / initiate Oracle ASM
		=> oracleasm init
		
ðŸ‘‰10) Now add disk
	=> ðŸ”¹ power off machine -> settings -> storage -> add disk -> create 4 disks -> 2 10GB & 2 5GB disks.
	
ðŸ‘‰11) Turn on machine login by root and check disk
	=> ðŸ”¹ [root@node2 oracle]# fdisk -l
	
ðŸ‘‰12) Format all disks

		Before format disk names:- /dev/sdb /dev/sdc /dev/sdd 
		Format command:- fdisk /dev/sdb fdisk /dev/sdc fdisk /dev/sdd 
		Prompt sequence:- Hit m,n,p,enter,enter,enter,w.
		After format disk names:- /dev/sdb1 /dev/sdc1 /dev/sdd1 

ðŸ‘‰13) Create separate ASM Disk for each partition

	ðŸ”¹ oracleasm createdisk CRS1 /dev/sdb1
	ðŸ”¹ oracleasm createdisk DATA1 /dev/sdc1
	ðŸ”¹ oracleasm createdisk FRA1 /dev/sdd1
	
	ðŸ”¹ [root@node2 oracle]# oracleasm listdisks
	 DISK1
	 DISK2
	 DISK3
	 DISK4

	ðŸ”¹ [root@node2 dev]# ls -lrt /dev/oracleasm/disks
	 total 0
	 brw-rw----. 1 grid oinstall 8, 49 Jun 20 15:23 DISK3
	 brw-rw----. 1 grid oinstall 8, 33 Jun 20 15:23 DISK2
	 brw-rw----. 1 grid oinstall 8, 17 Jun 20 15:23 DISK1
	 brw-rw----. 1 grid oinstall 8, 65 Jun 20 15:23 DISK4

ðŸ‘‰14) Now to make ASM DISKS we need software so for that login with grid user create bash profile.

	  ðŸ”¹export ORACLE_BASE=/u01/app/grid
		export ORACLE_HOME=/u01/app/grid/product/19.3.0/grid_home
		export ORACLE_SID=+ASM
		export LD_LIBRARY_PATH=\$ORACLE_HOME/lib:/lib:/usr/lib
		export CLASSPATH=\$ORACLE_HOME/jlib:\$ORACLE_HOME/rdbms/jlib
		PATH=$PATH:$HOME/.local/bin:$ORACLE_HOME/bin
		export PATH
		umask 022
	
ðŸ‘‰15) Download oracle grid software put it in GRID_HOME and unzip.

ðŸ‘‰16) Download one rpm package.
	ðŸ”¹ [grid@node2 grid_home]$ cd cv/rpm
	ðŸ”¹ [grid@node2 rpm]$ ls -lrt
	ðŸ”¹ total 12
	ðŸ”¹ -rw-r--r--. 1 grid oinstall 11412 Mar 13  2019 cvuqdisk-1.0.10-1.rpm

	Install with root user
	
	[root@node2 rpm]# rpm -ivh cvuqdisk-1.0.10-1.rpm
	Preparing...                          ################################# [100%]
	Using default group oinstall to install package
	Updating / installing...
	1:cvuqdisk-1.0.10-1                ################################# [100%]

ðŸ‘‰17) Login with Grid go to GRID_HOME and run grid setup script which will launch a GUI for setup.

	ðŸ”¹ [grid@node2 ~]$ cd /u01/app/grid/product/19.3.0/grid_home
	ðŸ”¹ [grid@node2 grid_home]$ ls -lrt *grid*
	ðŸ”¹ -rwxr-x---. 1 grid oinstall       3294 Mar  8  2017 gridSetup.sh
	ðŸ”¹ [grid@node2 grid_home]$ ./gridSetup.sh
	ðŸ”¹ Launching Oracle Grid Infrastructure Setup Wizard...

ðŸ‘‰18) From root user do entry of node and ip in /etc/hosts
	ðŸ”¹ [root@node2 ~]# vi /etc/hosts
	ðŸ”¹ [root@node2 ~]# cat /etc/hosts
	127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
	::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
	192.168.56.71  node1   node1.learnomate.org  <=================== Do this entry.
	
ðŸ‘‰19) Now after successful installation of grid software.

ðŸ‘‰20) Now run asmca for diskgroup creation.

ðŸ‘‰21) Login with oracle and create bash profile.
	  ðŸ”¹export ORACLE_BASE=/u02/app/oracle
		export ORACLE_HOME=/u02/app/oracle/product/19.3.0/db_home
		export ORACLE_SID=prim
		export LD_LIBRARY_PATH=\$ORACLE_HOME/lib:/lib:/usr/lib
		export CLASSPATH=\$ORACLE_HOME/jlib:\$ORACLE_HOME/rdbms/jlib
		PATH=$PATH:$HOME/.local/bin:$ORACLE_HOME/bin

ðŸ‘‰22) Create oracle directories

	ðŸ”¹ mkdir -p /u02/app/oracle
	ðŸ”¹ mkdir -p /u02/app/oracle/product/19.3.0/db_home
	ðŸ”¹ chown -R oracle:oinstall /u02
	
ðŸ‘‰23) Upload 19c db in ORACLE_HOME and unzip it after that ./runinstaller and select software only.

ðŸ‘‰24) Now call dbca and install DB.


âœ… Now since we have successfully installed ASM we will open sqlplus in oracle user and check spfile, control file and data files location.

	ðŸ”¸ SQL> show parameter spfile;
	
	NAME                                 TYPE        VALUE
	------------------------------------ ----------- ------------------------------
	spfile                               string      +DATA/PRIM/PARAMETERFILE/spfil
                                                 e.265.1206026185

	ðŸ”¸ SQL> select name from v$controlfile;
	
	NAME
	--------------------------------------------------------------------------------
	+DATA/PRIM/CONTROLFILE/current.260.1206025937
	
	
	ðŸ”¸ SQL> select file_name from dba_data_files;
	
	FILE_NAME
	--------------------------------------------------------------------------------
	+DATA/PRIM/DATAFILE/users.259.1206025871
	+DATA/PRIM/DATAFILE/undotbs1.258.1206025869
	+DATA/PRIM/DATAFILE/system.256.1206025821
	+DATA/PRIM/DATAFILE/sysaux.257.1206025855


	ðŸ”¸ Now if we want to access this location of datafile login with grid user.
	   use below utility.
		ðŸ”¹ [grid@node1 grid_home]$ asmcmd -p
		ðŸ”¹ ASMCMD [+] >
		ðŸ”¹ ASMCMD [+] >
		ðŸ”¹ ASMCMD [+] > cd DATA/PRIM/
		ðŸ”¹ ASMCMD [+DATA/PRIM] > ls
			CONTROLFILE/
			DATAFILE/
			ONLINELOG/
			PARAMETERFILE/
			TEMPFILE/
		ðŸ”¹ ASMCMD [+DATA/PRIM] > cd PARAMETERFILE/
		ðŸ”¹ ASMCMD [+DATA/PRIM/PARAMETERFILE] > ls
			spfile.265.1206026185
		
	ðŸ”¸ To copy spfile or any file from ASM filesystem to normal file system.
		ðŸ”¹ ASMCMD [+DATA/PRIM/PARAMETERFILE] > cp spfile.265.1206026185 /home/grid
		   copying +DATA/PRIM/PARAMETERFILE/spfile.265.1206026185 -> /home/grid/spfile.265.1206026185
		   
	ðŸ”¸ To check disks present and their details.(metadata table:- v$asm_diskgroup)
		ðŸ”¹ASMCMD [+DATA/PRIM] > lsdg
		State    Type    Rebal  Sector  Logical_Sector  Block       AU  Total_MB  Free_MB  Req_mir_free_MB  Usable_file_MB  Offline_disks  Voting_files  Name
		MOUNTED  EXTERN  N         512             512   4096  4194304     10236    10136                0           10136              0             N  CRS/
		MOUNTED  EXTERN  N         512             512   4096  4194304     10236     7680                0            7680              0             N  DATA/
		MOUNTED  EXTERN  N         512             512   4096  4194304     10236    10148                0           10148              0             N  FRA/

	ðŸ”¸ To change the archive log destination as +FRA diskgroup.
		SQL> archive log list;
		Database log mode              No Archive Mode
		Automatic archival             Disabled
		Archive destination            /u02/app/oracle/product/19.3.0/db_home/dbs/arch
		Oldest online log sequence     3
		Current log sequence           5
		SQL>
		
		SQL> ALTER SYSTEM SET log_archive_dest_1='LOCATION=+FRA' SCOPE=BOTH;
		
		System altered.
		
		SQL> archive log list;
		Database log mode              No Archive Mode
		Automatic archival             Disabled
		Archive destination            +FRA
		Oldest online log sequence     3
		Current log sequence           5

	ðŸ”¸ To add datafile to tablespace we just need to write the command, ASM Oracle mangage file will automatically keep name of that file.
		ðŸ”¹ SQL> alter tablespace USERS add datafile '+DATA' size 10m;

			Tablespace altered.

		ðŸ”¹ SQL> select file_name from dba_data_files;

				FILE_NAME
				--------------------------------------------------------------------------------
				+DATA/PRIM/DATAFILE/users.259.1206025871
				+DATA/PRIM/DATAFILE/undotbs1.258.1206025869
				+DATA/PRIM/DATAFILE/system.256.1206025821
				+DATA/PRIM/DATAFILE/sysaux.257.1206025855
				+DATA/PRIM/DATAFILE/users.266.1206029015                             <=================== New File

	ðŸ”¸ To check ASM spfile location and create pfile login sql as sysasm

		ðŸ”¹ [grid@node1 grid_home]$ sqlplus / as sysasm

		ðŸ”¹ SQL> show parameter spfile;

		NAME                                 TYPE        VALUE
		------------------------------------ ----------- ------------------------------
		spfile                               string      +CRS/ASM/ASMPARAMETERFILE/registry.253.1206022649
		
		ðŸ”¹ SQL> create pfile from spfile;

			File created.
			SQL> exit

			[grid@node1 grid_home]$ cd $ORACLE_HOME/dbs


		ðŸ”¹ [grid@node1 dbs]$ ls -lrt
			total 16
			-rwxrwxr-x. 1 grid oinstall 3079 May 14  2015 init.ora
			-rw-rw----. 1 grid oinstall 1544 Jul  9 14:17 hc_+ASM.dat
			-rw-rw----. 1 grid oinstall 3955 Jul  9 14:17 ab_+ASM.dat
			-rw-r--r--. 1 grid oinstall  240 Jul  9 16:08 init+ASM.ora 

		{âš ï¸Note:- First shutdown DB and then ASM, While starting First Start ASM and then DB.}


	ðŸ”¸ If we want to do normal backup of spfile using RMAN

		ðŸ”¹ RMAN> backup spfile;

	ðŸ”¸ If we want to take backup of spfile in +FRA diskgroup.

		ðŸ”¹ RMAN> backup spfile format '+FRA/spfile_%u';

		ðŸ”¹ [grid@node1 ~]$ asmcmd -p
			ASMCMD [+] >
			ASMCMD [+] > cd FRA
			ASMCMD [+FRA] > ls
				PRIM/
				spfile_033u5o67
â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–

	

ðŸ“ŒDATAGUARD
---------------
Oracle Data Guard in Oracle 19c is a disaster recovery and high availability solution that ensures data protection and availability by creating and managing one or more 
standby copies of a production (primary) database.
																	   														   
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------																	   
										                         ++++++ORACLE DATAGUARD ARCHITECTURE++++++							   
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
						P R I M A R Y 	S I T E						   |						   				S T A N D B Y	S I T E
																	   |
																	   |
+----------------------------+       +------------+        +-----+     |     +-----+                                     +-----+        +------------------+
|PRIMARY DATABASE TRANSACTION| ----> | REDO BUFFER|  ----- | LNS | --------- | RFS | ---------|                          | MRP |------> | STANDBY DATABASE |
+----------------------------+       +------------+        +-----+     |     +-----+          |                          +-----+        +------------------+
										   |                          t|       ||             |                             |             |              |
										   V                          e|       ||             |                             |             |              |
								     +------------+                   n|       ||             |                             |             |              |
									 |    LGWR    |                    |       ||             |                             |             |              |
									 +------------+                   e|       ||             |                             |             |              |
									       |                          l|       ||             |                             |        +---------+     +--------+
										   V                          c|       ||             V                             |        | REPORTS |     | BACKUP |
								  +------------------+                a|       ||    +-------------------+ (Real-time Apply)|        +---------+     +--------+
								  | ONLINE REDO LOGS |                r|       ||    | STANDBY REDO LOGS |----------------->|
								  +------------------+                o|       ||    +-------------------+                  |
								           |                           |       ||             |                             |
										   V                           |       ||             V                             |
									 +------------+     Gap Resolution |       ||       +------------+                      |
									 |    ARC0    | ------>-------<------------||       |    ARC0    |                      |
									 +------------+                    |        |       +------------+                      |
									       |                           |        |             |                             |
										   V                           |        |             V                             |
							    +---------------------+                |        |  +---------------------+                  |
								| ARCHIVED REDO LOGS  |                |        |--| ARCHIVED REDO LOGS  |------------------|
								+---------------------+                |           +---------------------+
								                                       |
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------																	   

ðŸŸ¥ Primary Site
------------------
ðŸ”¸ Primary Database Transaction: User-initiated DML/DDL operations that modify data.

ðŸ”¸ Redo Buffer: Temporarily stores redo information in memory (SGA).

ðŸ”¸ LGWR (Log Writer): Writes redo from buffer to online redo logs.

ðŸ”¸ ONLINE REDO LOGS: Disk-based logs storing real-time redo data.

ðŸ”¸ ARC0 (Archiver Process): Archives full online redo logs to archive logs.

ðŸ”¸ ARCHIVED REDO LOGS: Historical redo log files stored for recovery.

ðŸ”¸ LNSn (Log Network Service): Sends redo data in real-time to standby via Oracle Net.


ðŸŸ© Transport (Network Layer)
-------------------------------

ðŸ”¸ Oracle Net: Facilitates redo transmission between primary and standby databases.


ðŸŸ¦ Standby Site
------------------

ðŸ”¸ RFS (Remote File Server): Receives redo data from LNSn and writes to standby redo logs.

ðŸ”¸ STANDBY REDO LOGS: Temporary redo logs on standby for real-time apply.

ðŸ”¸ ARC0 (on Standby): Archives standby redo logs to local archived redo logs.

ðŸ”¸ ARCHIVED REDO LOGS (on Standby): Retained redo logs for recovery or gap resolution.

ðŸ”¸ MRP (Managed Recovery Process): Applies redo to maintain synchronization with primary.

ðŸ”¸ STANDBY DATABASE: Synchronized copy of primary, ready for failover or read-only access.

ðŸ”¸ REPORTS: Run read-only queries (if standby is in read-only or snapshot mode).

ðŸ”¸ BACKUP: Create backups without impacting the production database.



âœ… TYPES :-
=================

++++++++++++++++++++
1. Physical Standby+
++++++++++++++++++++

ðŸ”¸ Exact block-for-block copy of the primary database.

ðŸ”¸ Uses Redo Apply to keep in sync.

ðŸ”¸ Supports real-time apply and failover.

ðŸ”¸ Can be opened read-only for reporting (Active Data Guard).


âœ… SETUP STEPS :-
=================

âž¡ï¸1. startup primary DB.

	ðŸ”¹ SQL> alter system set log_archive_dest_1='location=/data/archive' scope=both;

âž¡ï¸2. change archive log destination and shutdown DB and startup mount.

	ðŸ”¹ SQL> startup mount

	ðŸ”¹ SQL> alter database archivelog;

	   Database altered.

	ðŸ”¹ SQL> alter database open;

	   Database altered.

âž¡ï¸3. Add below entries in /etc/hosts of both node 1 & 2.

	ðŸ”¹ vi /etc/hosts
	
	  192.168.56.50 node1.learnomate.org node1
	  192.168.56.60 node2.learnomate.org node2

âž¡ï¸4. Disable the firewall of both primary and standby machine.

	ðŸ”¹ [root@node1 ~]# systemctl stop firewalld
	ðŸ”¹ [root@node1 ~]# systemctl disable firewalld
	
	Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service.
	Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.
	
	ðŸ”¹ [root@node2 ~]# systemctl stop firewalld
	ðŸ”¹ [root@node2 ~]# systemctl disable firewalld
	
	Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service.
	Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.


âž¡ï¸5. create standby redo logs for switchovers on STANDBY & PRIMARY.

	ðŸ”¹ SQL> alter database add standby logfile '/data/app/oracle/oradata/STAND/redo04.log' size 200m;
	ðŸ”¹ SQL> alter database add standby logfile '/data/app/oracle/oradata/STAND/redo05.log' size 200m;
	ðŸ”¹ SQL> alter database add standby logfile '/data/app/oracle/oradata/STAND/redo06.log' size 200m;
	ðŸ”¹ SQL> alter database add standby logfile '/data/app/oracle/oradata/STAND/redo07.log' size 200m;
	
	ðŸ”¹ SQL> alter database add standby logfile '/data/app/oracle/oradata/PRIM/redo04.log' size 200m;
	ðŸ”¹ SQL> alter database add standby logfile '/data/app/oracle/oradata/PRIM/redo05.log' size 200m;	   <===================|
	ðŸ”¹ SQL> alter database add standby logfile '/data/app/oracle/oradata/PRIM/redo06.log' size 200m;                           |
	ðŸ”¹ SQL> alter database add standby logfile '/data/app/oracle/oradata/PRIM/redo07.log' size 200m;                           |
																												               |
âž¡ï¸6. To check created standby logs on primary.                                                                                 |
																												               |
	ðŸ”¹ SQL> SELECT group#, type, member FROM v$logfile WHERE type = 'STANDBY' order by group#;                                 |
	 																												           |
	GROUP# TYPE                                                                                                                |
	---------- -------                                                                                                         |
	MEMBER                                                                                                                     |
	--------------------------------------------------------------------------------                                           |
			4 STANDBY                                                                                                          |
	/data/app/oracle/oradata/PRIM/redo04.log                                                                                   |
																													           |
			5 STANDBY                                                                                                          |
	/data/app/oracle/oradata/PRIM/redo05.log                                                                                   |
																													           |
			6 STANDBY                                                                                                          |
	/data/app/oracle/oradata/PRIM/redo06.log                                                                                   |
																													           |
		7 STANDBY                                                                                                              |
	/data/app/oracle/oradata/PRIM/redo07.log                                                                                   |
																												               |
âž¡ï¸7. To check online redo log file size                                                                                        |
																												               |
	ðŸ”¹ SQL> select GROUP#,THREAD#,SEQUENCE#,bytes/1024/1024,MEMBERS,STATUS from v$log;                                         |
																												               |
		GROUP#    THREAD#  SEQUENCE# BYTES/1024/1024    MEMBERS STATUS                                                         |
	---------- ---------- ---------- --------------- ---------- ----------------        <================ Here we have 3 online redo logs each of size 200 MB so the  
			1          1          4             200          1 INACTIVE                                  standby redo logs size should also be 200 MB only.
			2          1          5             200          1 INACTIVE                         {âš ï¸Note:- the no of standby redo log = no of online redo log + 1
			3          1          6             200          1 CURRENT                          thats why we created a standby redo logs on primary. Because when high
																							  high data traffic arrives at online redo logs ==> standby redo logs ==> 
																							 if still more traffic ==> data passed to extra standby log.}

âž¡ï¸8. Check DB_NAME & DB_UNIQUE_NAME

	ðŸ”¹ SQL> show parameter db_name NAME
	
	NAME                                 TYPE        VALUE
	------------------------------------ ----------- ------------------------------
	db_name                              string      prim
	SQL>
	ðŸ”¹ SQL> show parameter db_unique_name

	NAME                                 TYPE        VALUE
	------------------------------------ ----------- ------------------------------
	db_unique_name                       string      prim

âž¡ï¸9. set remote archivelog destination for standby

	ðŸ”¹ SQL> alter system set log_archive_dest_2= 'service=stand async noaffirm reopen=15  valid_for=(all_logfiles,primary_role) db_unique_name=stand';
																							 

âž¡ï¸10. The STANDBY_FILE_MANAGEMENT parameter must be set AUTO (Automatic syncing of files on standby server)	

	ðŸ”¹ SQL> ALTER SYSTEM SET STANDBY_FILE_MANAGEMENT=AUTO;

	System altered.


âž¡ï¸11. Listener configuration on PRIMARY.

	# listener.ora Network Configuration File: /u02/app/oracle/product/19.3.0/db_home/network/admin/tnsnames.ora
	# Generated by Oracle configuration tools.
	
	
	SID_LIST_LISTENER =
	(SID_LIST =
		(SID_DESC =
			(GLOBAL_DBNAME = prim)
			(ORACLE_HOME = /u02/app/oracle/product/19.3.0/db_home)
			(SID_NAME = prim)
		)
		(SID_DESC =
		(GLOBAL_DBNAME = stand)
		(ORACLE_HOME = /u02/app/oracle/product/19.3.0/db_home)
		(SID_NAME = stand)
		)
	)

	LISTENER =
		(DESCRIPTION_LIST =
			(DESCRIPTION =
			(ADDRESS = (PROTOCOL = TCP) (HOST = node1.learnomate.org)(PORT = 1521))
			(ADDRESS = (PROTOCOL = ICP) (KEY = EXTPROC1521))
			)
		)


âž¡ï¸12. TNS FIle configuration on PRIMARY.

	PRIM =
	(DESCRIPTION =
		(ADDRESS = (PROTOCOL = TCP)(HOST = node1.learnomate.org)(PORT = 1521))
		(CONNECT_DATA =
		(SERVER = DEDICATED)
		(SERVICE_NAME = prim)
		)
	)
	STAND =
	(DESCRIPTION =
		(ADDRESS = (PROTOCOL = TCP)(HOST = node2.learnomate.org)(PORT = 1521))
		(CONNECT_DATA =
		(SERVER = DEDICATED)
		(SERVICE_NAME = stand)
		)
	)														 
  
 
âž¡ï¸13. Set the log_archive_config parameter( This tells that how many nodes are there in our DATAGUARD)

	ðŸ”¹ SQL> alter system set log_archive_config='dg_config=(prim,stand)';

	System altered.

âž¡ï¸14. set remote_login_passwordfile exclusive. (To create seperate password file for STANDBY)

	ðŸ”¹ SQL> alter system set remote_login_passwordfile='EXCLUSIVE' scope=spfile;

	System altered.

âž¡ï¸15. Update the fal_server and fal_client(For switch over/ fail over activity)

	ðŸ”¹ SQL> alter system set fal_server='stand';

	System altered.

	ðŸ”¹ SQL> alter system set fal_client='prim';

	System altered.


âž¡ï¸16. SCP password file, listener.ora and tnsnames.ora to standby server. and edit the listener.ora and tnsname.ora as node 2

	ðŸ”¹ [oracle@node1 dbs]$ scp orapwprim oracle@node2:$ORACLE_HOME/dbs/orapwstand
	ðŸ”¹ [oracle@node1 admin]$ scp listener.ora oracle@node2:$ORACLE_HOME/network/admin/
	ðŸ”¹ [oracle@node1 admin]$ scp tnsnames.ora oracle@node2:$ORACLE_HOME/network/admin/

	IN listener.ora
	----------------
	
	LISTENER =
		(DESCRIPTION_LIST =                      |
			(DESCRIPTION =                       V
			(ADDRESS = (PROTOCOL = TCP) (HOST = node2.learnomate.org)(PORT = 1521))
			(ADDRESS = (PROTOCOL = ICP) (KEY = EXTPROC1521))
			)
		)
	
	IN tnsname.ora
	----------------
										   |
	LISTENER_PRIM =                        V
	(ADDRESS = (PROTOCOL = TCP)(HOST = node2.learnomate.org)(PORT = 1521))


âž¡ï¸17. Standby Configuration Create directory on standby for CDB and PDB datafile also.

	ðŸ”¹ [root@node2 ~]# mkdir -p /data/app/oracle/oradata/STAND/pdbprim
	ðŸ”¹ [root@node2 ~]# mkdir -p /data/app/oracle/oradata/STAND/pdbseed
	ðŸ”¹ [root@node2 ~]# mkdir -p /data/app/oracle/admin/stand/adump
	ðŸ”¹ [root@node2 ~]# mkdir -p /data/app/oracle/fast_recovery_area/stand/

âž¡ï¸18. Create initstand.ora (pfile) in STANDBY server

	ðŸ”¹ [oracle@node2 dbs]$ vi initstand.ora   (REFER LOGS.txt)

âž¡ï¸19. startup database STAND in nomount using pfile.

	ðŸ”¹SQL> startup nomount pfile='initstand.ora';

âž¡ï¸20. Start listener in both servers.

âž¡ï¸21. connect with rman with target & auxiliary instance using the following command.

	ðŸ”¹[oracle@node2 dbs]$ rman target sys/oracle@prim auxiliary sys/oracle@stand

âž¡ï¸22. Run the following duplicate command, that command will start copying all database on the standby server.

	ðŸ”¹RMAN> Duplicate target database for standby from active database dorecover nofilenamecheck;

âž¡ï¸23. Dataguard important Queries Check the database status on primary and standby

	ðŸ”¹SQL> select status,instance_name,database_role,protection_mode from v$database,v$instance;
	
	STATUS       INSTANCE_NAME    DATABASE_ROLE    PROTECTION_MODE
	------------ ---------------- ---------------- --------------------
	OPEN         prim             PRIMARY          MAXIMUM PERFORMANCE
	
	ðŸ”¹SQL> select status,instance_name,database_role,protection_mode from v$database,v$instance;
	
	STATUS       INSTANCE_NAME    DATABASE_ROLE    PROTECTION_MODE
	------------ ---------------- ---------------- --------------------
	MOUNTED      stand            PHYSICAL STANDBY MAXIMUM PERFORMANCE


âž¡ï¸24. On node2 startup nomount.
	ðŸ”¹[oracle@node2 ~]$ sqlplus / as sysdba
	ðŸ”¹SQL> startup nomount
	ðŸ”¹SQL> ALTER DATABASE MOUNT STANDBY DATABASE;
	Database altered.
	SQL>

âž¡ï¸25. now check the DB status on node1 and node2.
	ðŸ”¹SQL> select name, open_mode, database_role from v$database;
	
	NAME      OPEN_MODE            DATABASE_ROLE
	--------- -------------------- ----------------
	PRIM      READ WRITE           PRIMARY
	
	ðŸ”¹SQL> select name, open_mode, database_role from v$database;
	
	NAME      OPEN_MODE            DATABASE_ROLE
	--------- -------------------- ----------------
	PRIM      MOUNTED              PHYSICAL STANDBY

âž¡ï¸26. To start the MRP service on standby DB run below command.
	ðŸ”¹SQL> alter database recover managed standby database disconnect from session;          <=============== START MRP

	Database altered.

âž¡ï¸27. Now we can check whether changes made on primary are actually reflecting on standby DB or not.

	On primary
	
	ðŸ”¹SQL> SELECT SEQUENCE#, APPLIED FROM V$ARCHIVED_LOG;
	SEQUENCE# APPLIED
	---------- ---------
			14 YES
			15 YES
			17 YES
			16 YES
			6 YES
			18 NO
			19 NO
			20 NO
			21 NO
			21 NO
			22 NO           <==================== Same sequence number
	
	
	32 rows selected.
	
	ðŸ”¹SQL> alter system switch logfile;
	
	System altered.
	
	ðŸ”¹SQL> SELECT SEQUENCE#, APPLIED FROM V$ARCHIVED_LOG;
	
	On standby
	
	SEQUENCE# APPLIED
	---------- ---------
			14 YES
			15 YES
			17 YES
			16 YES
			6 YES
			18 NO
			19 NO
			20 NO
			21 NO
			21 NO
			22 NO            <==================== Same sequence number That means Changes are reflecting.
			
			

==========================================================================âœ… ACTIVE DATAGUARD MODE ===============================================================================

âœ… Now since we cannot read any data from standby database so to make it read only mode because it is in mount stage so we have to put primary database in (Active Dataguard Mode).

âž¡ï¸1. Cancel the running MRP process on STANDBY

	ðŸ”¹SQL> alter database recover managed standby database cancel;
	Database altered.
	
âž¡ï¸2. Open STANDBY DATABASE	

	ðŸ”¹SQL> alter database open;
	Database altered.
	
âž¡ï¸3. Now again start MRP to view the changes on STANDBY.

	ðŸ”¹SQL> alter database recover managed standby database disconnect from session;
	Database altered.
	
âž¡ï¸4. To check whether changes done to primary are reflecting on standby or not.

	On Primary creating a table and inserting values.
	
		ðŸ”¹SQL> CREATE TABLE guys (
		id   NUMBER,
		name VARCHAR2(100));
		
		ðŸ”¹SQL> INSERT INTO guys (id, name) VALUES (1, 'Alice');
		ðŸ”¹SQL> INSERT INTO guys (id, name) VALUES (2, 'Bob');
		
		ðŸ”¹SQL> commit;
		
		ðŸ”¹SQL> select * from guys;
		
			ID NAME
	---------- ----------------------------------------------------------------------------------------------------
			1 Alice
			2 Bob


âž¡ï¸5. Now on standby check the changes

	ðŸ”¹SQL> select * from guys;
		
			ID NAME
	---------- ----------------------------------------------------------------------------------------------------
			1 Alice
			2 Bob
	



+++++++++++++++++++++++++++++
2. Snapshot Standby Database+
+++++++++++++++++++++++++++++

ðŸ”¸ Description: A physical standby database temporarily converted into a read/write database for testing.

ðŸ”¸ Data Sync: Redo logs are received but not applied until the snapshot is converted back to a physical standby.

ðŸ”¸ Use Case: Ideal for testing changes in a production-like environment without affecting replication.


âœ… SETUP STEPS :-
=================

âž¡ 1. Cancel the existing Recovery Process i.e MRP

	ðŸ”¹ SQL> alter database recover managed standby database cancel;
 
Database altered.

âž¡ 2. Shutdown database to enable flashback and start again in mount stage.

	ðŸ”¹ SQL> shu immediate;
	ðŸ”¹ SQL> startup mount;

âž¡ 3. Check if recovery area is already set with required size.

	ðŸ”¹ SQL> show parameter recover;

	NAME                                 TYPE        VALUE
	------------------------------------ ----------- ------------------------------
	db_recovery_file_dest                string      /data/app/oracle/fast_recovery <====|
													_area/                              ====> Before creating guarantee restore point these 2 parameters must be set properly.
	db_recovery_file_dest_size           big integer 4800M                          <====|
	db_unrecoverable_scn_tracking        boolean     TRUE
	recovery_parallelism                 integer     0
	remote_recovery_file_dest            string


âž¡ 4. Now the below command will convert it to snapshot standby

	ðŸ”¹ SQL> alter database convert to snapshot standby;
 
Database altered.

	ðŸ”¹ SQL> alter database open;
 
Database altered.

	ðŸ”¹ SQL> select name,open_mode from v$database;
 
	NAME      OPEN_MODE
	--------- --------------------
	PRIM      READ WRITE

==========================================================================âœ… SNAPSHOT STANDBY USE CASE ===========================================================================


âœ… Now since snapshot standby is generally used for testing purpose we will see the use case.

ðŸ”¸ Consider primary db is up and running.

ðŸ”¸ We opened standby db in mount stage.

	ðŸ”¹ SQL> startup mount;
	
ðŸ”¸ Convert standby db to physical standby / active dataguard mode.

	ðŸ”¹ SQL> alter database convert to physical standby.
	ðŸ”¹ SQL> alter database open;
	ðŸ”¹ SQL> select name,open_mode from v$database;
 
	NAME      OPEN_MODE
	--------- --------------------
	PRIM      READ ONLY

ðŸ”¸ Now Create a table emp on primary db.

	ðŸ”¹ SQL> create table emp (name char(10));
	ðŸ”¹ SQL> insert into emp values ('primary');
	ðŸ”¹ SQL> insert into emp values ('primary');
	ðŸ”¹ SQL> commit;
	
	ðŸ”¹SQL> select * from emp;
	
	NAME
	---------
	primary
	primary
	
ðŸ”¸ Now go to standby db and start mrp so that the logs are applied to standby db.

	ðŸ”¹ SQL> alter database recover managed standby database disconnect from session;
	ðŸ”¹ SQL> select * from emp;
	
	NAME
	---------
	primary
	primary

ðŸ”¸ Now kill mrp and to convert physical standby into snapshot standby for testing purpose.
	ðŸ”¹ SQL>	 ALTER DATABASE RECOVER MANAGED STANDBY DATABASE CANCEL;
	ðŸ”¹ SQL> shu immediate;
	ðŸ”¹ SQL> startup mount;
	ðŸ”¹ SQL> alter database convert to snapshot standby.
	ðŸ”¹ SQL> alter database open;
	ðŸ”¹ SQL> select name,open_mode from v$database;
	
	NAME      OPEN_MODE
	--------- --------------------
	PRIM      READ WRITE
	
	ðŸ”¹ SQL> select * from emp;
	
	NAME
	---------
	primary
	primary

ðŸ”¸ Now for testing the application team inserts some record inside emp table of stanby db.

	ðŸ”¹ SQL> insert into emp values ('testing');
    ðŸ”¹ SQL> insert into emp values ('testing');
    ðŸ”¹ SQL> commit;
	
	ðŸ”¹ SQL> select * from emp;
	
	NAME
	---------
	primary
	primary
	testing
	testing
	
ðŸ”¸ Now if we insert new records in emp from primary the changes wont go to standby because it is in snapshot standby mode where MRP is not started.

	ðŸ”¹ SQL> insert into emp values ('after snap');
	ðŸ”¹ SQL> insert into emp values ('after snap');
	ðŸ”¹ SQL> commit;

	ðŸ”¹ SQL> select * from emp;
	
	NAME
	---------
	primary
	primary
	after snap
	after snap
	
ðŸ”¸ Now since the testing is done now we can put the snapshot standby to physical standby again.

	ðŸ”¹ SQL> shu immediate;
	ðŸ”¹ SQL> startup mount;
	ðŸ”¹ SQL> alter database convert to physical standby.
	ðŸ”¹ SQL> alter database open;                           <=========Active Dataguard Mode
	
ðŸ”¸ Now to apply "after snap" new records from primary db we have to start MRP on physical standby.

	ðŸ”¹ SQL> alter database recover managed standby database disconnect from session;
	ðŸ”¹ SQL> select * from emp;
	
	NAME
	---------
	primary
	primary
	after snap
	after snap
	
	Now all the testing records are gone.
	
	
	
ðŸ§© Physical Standby Creation â€“ Comparison

| Step                               | **Using RMAN Backup (Traditional Method)**                                                 | **Using RMAN Active Duplicate (Modern Method)**                                                |
| ---------------------------------- | ------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------- |
| **1. Prerequisites**               | Primary must be in ARCHIVELOG + FORCE LOGGING mode.                                        | Same â€” ARCHIVELOG + FORCE LOGGING required.                                                    |
| **2. Network Setup**               | Not mandatory (you just copy files manually).                                              | Mandatory â€” tnsnames and listener must be configured for both primary & standby.               |
| **3. Backup**                      | Take full RMAN backup of datafiles + archivelogs.                                          | No backup needed â€” datafiles copied directly over network.                                     |
| **4. Standby Controlfile**         | Create using:<br>`ALTER DATABASE CREATE STANDBY CONTROLFILE AS '/tmp/standby.ctl';`        | RMAN automatically creates standby controlfile.                                                |
| **5. Copy Files**                  | Manually copy backups and controlfile to standby server.                                   | No manual copy â€” RMAN duplicates directly.                                                     |
| **6. Standby Initialization File** | Create `init.ora` manually with all DG parameters.                                         | Same â€” you create minimal `init.ora` before starting NOMOUNT.                                  |
| **7. Start Standby**               | `STARTUP NOMOUNT;`                                                                         | `STARTUP NOMOUNT;`                                                                             |
| **8. Restore Database**            | Run RMAN commands:<br>`RESTORE CONTROLFILE;`<br>`RESTORE DATABASE;`<br>`RECOVER DATABASE;` | Run single command:<br>`DUPLICATE TARGET DATABASE FOR STANDBY FROM ACTIVE DATABASE DORECOVER;` |
| **9. Managed Recovery**            | Start manually:<br>`ALTER DATABASE RECOVER MANAGED STANDBY DATABASE DISCONNECT;`           | RMAN starts recovery automatically (if `DORECOVER` used).                                      |
| **10. Complexity**                 | More manual â€” suitable when network is slow or restricted.                                 | Easier & faster â€” preferred method in most environments.                                       |
| **11. File Copy Method**           | Using RMAN backupsets or OS copy.                                                          | Through Oracle Net (network connection).                                                       |
| **12. Performance**                | Depends on disk copy speed.                                                                | Depends on network throughput.                                                                 |

	
===================================================================âœ…Switchover in Oracle 19C Dataguard==========================================================================


ðŸ”„ PREREQUISITES:-
===================
ðŸ”¸ Data Guard is configured and running correctly.

ðŸ”¸ Archive log shipping and Redo Apply are working.

ðŸ”¸ Both databases are in SYNC.

ðŸ”¸ You have a full backup.

âž¡ 1. Check Switchover Status on Primary
  +++++++++++++++++++++++++++++++++++++++
	Login to the primary database:
	
	ðŸ”¹SQL> SELECT SWITCHOVER_STATUS FROM V$DATABASE;
	
	Possible values:
	-----------------

	a. TO STANDBY: Ready for switchover.
	
	b. SESSIONS ACTIVE: Disconnect users.
	
	c. NOT ALLOWED: Some issue exists.

	Ensure the result is TO STANDBY. If not:
                    ============  
	Close user sessions.
	Ensure log shipping and apply are working.

âž¡ 2. Perform Switchover on Primary (Making PRIMARY as new STANDBY)
  ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
	ðŸ”¹SQL> ALTER DATABASE COMMIT TO SWITCHOVER TO STANDBY WITH SESSION SHUTDOWN;
	
	Then shutdown and mount the database:
	
	ðŸ”¹SQL> SHUTDOWN IMMEDIATE;
	ðŸ”¹SQL> STARTUP MOUNT;
	ðŸ”¹SQL> select name, open_mode, database_role from v$database;
	
		NAME      OPEN_MODE            DATABASE_ROLE
		--------- -------------------- ----------------
		PRIM      MOUNTED              PHYSICAL STANDBY

	ðŸ”¹SQL> alter database recover managed standby database disconnect from session;

âž¡ 3. Perform Switchover on Standby (Making STANDBY as new PRIMARY)
  ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
	Connect to the standby database:

	ðŸ”¹SQL> SELECT SWITCHOVER_STATUS FROM V$DATABASE;

	Ensure the result is TO PRIMARY.

	ðŸ”¹SQL> ALTER DATABASE COMMIT TO SWITCHOVER TO PRIMARY WITH SESSION SHUTDOWN;
	ðŸ”¹SQL> SHUTDOWN IMMEDIATE;
	ðŸ”¹SQL> STARTUP;
	
	ðŸ”¹SQL> select name, open_mode, database_role from v$database;
	
		NAME      OPEN_MODE            DATABASE_ROLE
		--------- -------------------- ----------------
		PRIM      READ WRITE           PRIMARY						   
â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–




ðŸ“ŒPERFORMANCE TUNING
---------------------
Optimizing and tuning Oracle databases is essential for ensuring efficient and reliable performance. This article will walk you through key techniques and tools to 
enhance your databaseâ€™s performance, using real-world scenarios for better understanding.

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ ðŸŸ¥ Sample example execution plan ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

ðŸ”¹ Step 1: Create the Table
-------------------------------
DROP TABLE employees_demo PURGE;

CREATE TABLE employees_demo (
  emp_id     NUMBER PRIMARY KEY,
  emp_name   VARCHAR2(100),
  department VARCHAR2(50),
  salary     NUMBER
);

ðŸ”¹ Step 2: Insert Sample Data
--------------------------------
BEGIN
  FOR i IN 1..1000 LOOP
    INSERT INTO employees_demo (emp_id, emp_name, department, salary)
    VALUES (
      i,
      'Employee_' || i,
      CASE
        WHEN MOD(i, 3) = 0 THEN 'IT'
        WHEN MOD(i, 3) = 1 THEN 'HR'
        ELSE 'Finance'
      END,
      3000 + MOD(i, 5000)
    );
  END LOOP;
  COMMIT;
END;
/

ðŸ”¹ Step 3: Run a Sample Query (this is what weâ€™ll analyze)
-------------------------------------------------------------
-- SAMPLE QUERY:
SELECT emp_name, salary
FROM employees_demo
WHERE department = 'IT';


ðŸ”¹ Step 4: Generate and View the Execution Plan
-----------------------------------------------
SET LINESIZE 200
SET PAGESIZE 1000
SET TRIMSPOOL ON
SET TRIMOUT ON
SET TAB OFF

EXPLAIN PLAN FOR
SELECT emp_name, salary
FROM employees_demo
WHERE department = 'IT';

===>  Explained.

SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY);

PLAN_TABLE_OUTPUT
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Plan hash value: 1271012197

------------------------------------------------------------------------------------
| Id  | Operation         | Name           | Rows  | Bytes | Cost (%CPU)| Time     |
------------------------------------------------------------------------------------
|   0 | SELECT STATEMENT  |                |   333 | 30636 |     3   (0)| 00:00:01 |
|*  1 |  TABLE ACCESS FULL| EMPLOYEES_DEMO |   333 | 30636 |     3   (0)| 00:00:01 |
------------------------------------------------------------------------------------

Predicate Information (identified by operation id):
---------------------------------------------------

   1 - filter("DEPARTMENT"='IT')

Note
-----
   - dynamic statistics used: dynamic sampling (level=2)


========> Observed that it is taking more time to fetch the query as it is using "TABLE ACCESS FULL" scan operation to search. So now we can take suggestion from 
"SQL Tuning Advisor".


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ ðŸŸ© SQL Tuning Advisor ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


âž¡ 1. Letâ€™s run a sample query

	SQL> SELECT emp_name, salary FROM employees_demo WHERE department = 'IT';

	ðŸ”¸ we will get some output for it.

âž¡ 2. Now you might want to know the SQL ID of the above command. 

	SQL> select prev_sql_id from v$session where sid=sys_context('userenv','sid');
	
	PREV_SQL_ID
	-------------
	7tsgp76vwvgm0


âž¡ 3. You can check if the sql id returned above is correct by checking the SQL TEXT associated with the sql id

	SQL> select sql_id, sql_text from v$sqltext where sql_id in ('7tsgp76vwvgm0');
	
	SQL_ID        SQL_TEXT
	------------- ---------------------------------------------------------------- 
	7tsgp76vwvgm0 SELECT emp_name, salary FROM employees_demo WHERE department = 'IT'


âž¡ 4. Run the SQL Advisor Manually

	DECLARE
		l_sql_tune_task_id VARCHAR2(100);
	BEGIN
		l_sql_tune_task_id := DBMS_SQLTUNE.create_tuning_task (
			sql_id => '7tsgp76vwvgm0',
			scope => DBMS_SQLTUNE.scope_comprehensive,
			time_limit => 500,
			task_name => '7tsgp76vwvgm0_tuning_task11',
			description => 'Tuning task1 for statement 7tsgp76vwvgm0'
		);
		DBMS_OUTPUT.put_line('l_sql_tune_task_id: ' || l_sql_tune_task_id);
	END;
	/
	
	-- Execute the SQL Tuning Task
	EXEC DBMS_SQLTUNE.execute_tuning_task(task_name => '7tsgp76vwvgm0_tuning_task11');
	
	-- Retrieve and Display the Tuning Report
	SET LONG 65536
	SET LONGCHUNKSIZE 65536
	SET LINESIZE 100
	SELECT DBMS_SQLTUNE.report_tuning_task('7tsgp76vwvgm0_tuning_task11') FROM dual;


	ðŸ”¸ we get this output

		DBMS_SQLTUNE.REPORT_TUNING_TASK('7TSGP76VWVGM0_TUNING_TASK11')
		----------------------------------------------------------------------------------------------------
		GENERAL INFORMATION SECTION
		-------------------------------------------------------------------------------
		Tuning Task Name   : 7tsgp76vwvgm0_tuning_task11
		Tuning Task Owner  : SYS
		Workload Type      : Single SQL Statement
		Scope              : COMPREHENSIVE
		Time Limit(seconds): 500
		Completion Status  : COMPLETED
		Started at         : 07/25/2025 19:49:37
		Completed at       : 07/25/2025 19:49:38
		
		-------------------------------------------------------------------------------
		Schema Name: SYS
		SQL ID     : 7tsgp76vwvgm0
		SQL Text   : SELECT emp_name, salary
					FROM employees_demo
					WHERE department = 'IT'
		
		-------------------------------------------------------------------------------
		FINDINGS SECTION (1 finding)
		-------------------------------------------------------------------------------
		
		1- Statistics Finding
		---------------------
		Table "SYS"."EMPLOYEES_DEMO" was not analyzed.
		
		Recommendation
		--------------
		- Consider collecting optimizer statistics for this table.
			execute dbms_stats.gather_table_stats(ownname => 'SYS', tabname =>
					'EMPLOYEES_DEMO', estimate_percent =>
					DBMS_STATS.AUTO_SAMPLE_SIZE, method_opt => 'FOR ALL COLUMNS SIZE       <====== Observed that SQL Tuning Advisor Suggesting us to 
					AUTO');																		   gather stats for this sql query and table;
		
		Rationale
		---------
			The optimizer requires up-to-date statistics for the table in order to
			select a good execution plan.
		
		-------------------------------------------------------------------------------
		EXPLAIN PLANS SECTION
		-------------------------------------------------------------------------------
		
		1- Original
		-----------
		Plan hash value: 1271012197
		
		------------------------------------------------------------------------------------
		| Id  | Operation         | Name           | Rows  | Bytes | Cost (%CPU)| Time     |
		------------------------------------------------------------------------------------
		|   0 | SELECT STATEMENT  |                |   333 | 30636 |     3   (0)| 00:00:01 |
		|*  1 |  TABLE ACCESS FULL| EMPLOYEES_DEMO |   333 | 30636 |     3   (0)| 00:00:01 |
		------------------------------------------------------------------------------------
		
		Predicate Information (identified by operation id):
		---------------------------------------------------
		
		1 - filter("DEPARTMENT"='IT')
		
		-------------------------------------------------------------------------------
		
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ ðŸŸ¦ Gather Stats ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


âž¡ 1. Run this query suggested by SQL Tuning Advisor.

	SQL> execute dbms_stats.gather_table_stats(ownname => 'SYS', tabname => 'EMPLOYEES_DEMO', estimate_percent => DBMS_STATS.AUTO_SAMPLE_SIZE, method_opt => 
	'FOR ALL COLUMNS SIZE AUTO');
	
	PL/SQL procedure successfully completed.
	
	ðŸ”¸ now check whether the statistics has known about this table or not (i.e check the last analysed date)
	
	SQL> select table_name, to_char(last_analyzed, 'DD-MON-YYYY HH24:MI:SS') from dba_tables where owner='SYS' AND TABLE_NAME = 'EMPLOYEES_DEMO';
	
	TABLE_NAME      TO_CHAR(LAST_ANALYZED,'DD-MON
	--------------- -----------------------------
	EMPLOYEES_DEMO  25-JUL-2025 19:56:28                   <============= Now the statistics has known everything till date about the table.

check objects whose gather statistics is stale

SQL> select owner, index_name, table_name, last_analyzed, stale_stats from dba_ind_statistics where owner='SYS' and stale_stats='YES';


OWNER                INDEX_NAME                          TABLE_NAME                     LAST_ANAL STA
-------------------- ----------------------------------- ------------------------------ --------- ---
SYS                  I_UNDO1                             UNDO$                          03-AUG-25 YES
SYS                  I_UNDO2                             UNDO$                          03-AUG-25 YES
SYS                  I_IND1                              IND$                           03-AUG-25 YES
SYS                  I_H_OBJ#_COL#                       HISTGRM$                       03-AUG-25 YES
SYS                  I_PARTOBJ$                          PARTOBJ$                       03-AUG-25 YES
SYS                  I_CONTAINER1                        CONTAINER$                     03-AUG-25 YES
SYS                  I_CONTAINER2                        CONTAINER$                     03-AUG-25 YES
SYS                  I_CONTAINER3                        CONTAINER$                     03-AUG-25 YES
SYS                  SMON_SCN_TIME_SCN_IDX               SMON_SCN_TIME                  03-AUG-25 YES
SYS                  SMON_SCN_TIME_TIM_IDX               SMON_SCN_TIME                  03-AUG-25 YES
SYS                  I_STATS_TARGET1                     STATS_TARGET$                  03-AUG-25 YES
SYS                  I_STATS_TARGET2                     STATS_TARGET$                  03-AUG-25 YES
SYS                  I_COL_USAGE$                        COL_USAGE$                     03-AUG-25 YES
SYS                  PK_COL_GROUP_USAGE$                 COL_GROUP_USAGE$               03-AUG-25 YES
SYS                  I_MON_MODS_ALL$_OBJ                 MON_MODS_ALL$                  03-AUG-25 YES
SYS                  I_WRI$_OPTSTAT_IND_OBJ#_ST          WRI$_OPTSTAT_IND_HISTORY       03-AUG-25 YES


ðŸŽ¯ Scenario: Employee Management System (Oracle 19c)
You have a table: EMPLOYEES


CREATE TABLE employees (
    emp_id        NUMBER PRIMARY KEY,
    name          VARCHAR2(100),
    department_id NUMBER,
    salary        NUMBER,
    hire_date     DATE
);
ðŸ§± Step 1: Index Creation
âœ… Oracle Automatically Creates:

-- This creates a primary key, so Oracle creates an index on emp_id
ALTER TABLE employees ADD CONSTRAINT emp_pk PRIMARY KEY (emp_id);
âœ… DBA Manually Creates:
Suppose many queries use department_id in the WHERE clause:


-- Manual index to speed up lookups by department
CREATE INDEX idx_emp_dept ON employees(department_id);


ðŸ” Step 2: Frequent DML Changes
The employees table is very active:

New hires (INSERTs)

Promotions/Transfers (UPDATEs)

Departures (DELETEs)

This causes:

Index fragmentation

Outdated optimizer statistics


ðŸ§¹ Step 3: Index Rebuild (After Heavy Changes)
You notice queries are slowing down.
You check fragmentation (via DBA_INDEXES) and see high BLEVEL and clustering factor.

âœ… You decide to rebuild the index:


-- Rebuild the index to remove fragmentation
ALTER INDEX idx_emp_dept REBUILD;
Or online (without locking the table):

ALTER INDEX idx_emp_dept REBUILD ONLINE;


ðŸ“Š Step 4: Gather Statistics (After Rebuild or Data Changes)
After heavy DML or index rebuild, Oracleâ€™s optimizer needs fresh stats.

âœ… You gather statistics on the table and its indexes:


BEGIN
  DBMS_STATS.GATHER_TABLE_STATS(
    ownname  => 'HR',
    tabname  => 'EMPLOYEES',
    cascade  => TRUE -- also gathers stats on indexes
  );
END;
/
This helps Oracle:

Estimate rows

Choose the best query plan

Decide whether to use an index or full table scan

ðŸ“Œ Step 5: Summary of the Process
Step	Action	Why We Do It
1	Create indexes	To speed up queries (on PKs or WHERE columns)
2	Perform DML (INSERT/UPDATE/DELETE)	Regular business operations
3	Rebuild indexes	To fix fragmentation after heavy DML
4	Gather statistics	So Oracle optimizer has accurate data
5	Faster queries	Oracle makes smarter decisions with fresh stats

ðŸ”Ž Bonus: A Common Query Before vs After

-- Common query that benefits from the index
SELECT name FROM employees WHERE department_id = 10;
ðŸ¢ Before index rebuild & stats: May do full table scan.

ðŸš€ After rebuild & stats: Uses index on department_id, much faster!
â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–


ðŸ“ŒOEM(ORACLE ENTERPRISE MANAGER)
---------------------------------
It is a web-based management tool provided by Oracle to monitor and administer Oracle environments â€” databases, listeners, hosts, ASM, etc.
If any database or server level issue then email is sent by OEM and also the OEM is integrated with the sevicenow so a ticket is generated via oem on service now to us.


                 +---------------------+
                 |     OEM Console     |
                 |  (Web-based GUI)    |
                 +---------------------+
                            â¬†ï¸
                            â¬†ï¸
	            |----------------------------------------------------------------|				
	            |				        SEPERATE NODE FOR OEM					 |
                | +---------------------+		+------------------------------+ |
                | |   Oracle Management | ====>	|  OEM Repository Database     | |
                | |Server (OMS) Software| ====>	|  (Stores monitoring & config)| |
                | +---------------------+		+------------------------------+ |
	            |----------------------------------------------------------------|
                            â¬†ï¸
        +-------------------+-------------------+
        â¬†ï¸                                       â¬†ï¸
        â¬†ï¸                                       â¬†ï¸
+---------------------+                +---------------------+
|   Management Agent  |                |   Management Agent  |
| (Installed on Host) |                | (Installed on Host) |
+---------------------+                +---------------------+
        â¬†ï¸                                       â¬†ï¸
        â¬†ï¸                                       â¬†ï¸
+---------------------+                +---------------------+
|  Target Database /  |                |  Target Database /  |
|    Host Systems     |                |    Host Systems     |
+---------------------+                +---------------------+


ðŸ”¹ Explanation

OEM Console â€“ Web interface to monitor and manage targets.

OMS (Oracle Management Server) â€“ Core server processing monitoring and management tasks.

Management Agents â€“ Installed on each host to collect data from databases or hosts.

Target Databases / Hosts â€“ The actual systems you monitor (Oracle DB, ASM, RAC, etc.).

Repository Database â€“ Stores historical performance data, alerts, and configuration info.


âž¡ï¸ To start OEM

ðŸ”¸ Check Listener status.
	=> [oracle@oem ~]# lsnrctl start
ðŸ”¸ Login to oem server with oracle user.
	=> [oracle@oem ~]# sqlplus / as sysdba
	
ðŸ”¸ First start the repository DB.
	=> startup
	=> alter pluggable database all open; (if the repository DB is a PDB)
	
ðŸ”¸ Then start the OMS software.
	=> $OMS_HOME/bin/emctl start oms
	

Database Alert Log Location:
------------------------------
/u01/app/oraclebase/diag/rdbms/prim/prim1/trace/alert_prim1.log

Database Size:
----------------
SQL> SELECT ROUND(SUM(bytes)/1024/1024/1024,2) AS total_db_size_gb
FROM (
  SELECT bytes FROM v$datafile
  UNION ALL
  SELECT bytes FROM v$tempfile
  UNION ALL
  SELECT g.bytes FROM v$log g
);
TOTAL_DB_SIZE_GB
----------------
            4.17
â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–


ðŸ“ŒSRVCTL(Server Control Utility)
-----------
=> To start and stop database using srvctl command.

1. To check database status=>

	ðŸ”¹ [oracle@node1 ~]$ srvctl status database -d prim
	Instance prim1 is running on node node1
	Instance prim2 is running on node node2

2. To down database and all instance together=>

	ðŸ”¹[oracle@node1 ~]$ srvctl stop database -d prim

3. To start particular database instance=>

	ðŸ”¹[oracle@node2 ~]$ srvctl start instance -i prim1 -d prim
	ðŸ”¹[oracle@node1 ~]$ srvctl start instance -i prim2 -d prim

4. To start database and all instance together=>

	ðŸ”¹[oracle@node1 ~]$ srvctl start database -d prim
	
5. To start asm instance=>
	ðŸ”¹[oracle@node1 ~]$ srvctl start asm -n node1

6. To check status of Listener

	ðŸ”¹[oracle@node1 ~]$ srvctl status listener -l LISTENER
Listener LISTENER is enabled
Listener LISTENER is running on node(s): node2,node1

7. To start Listener=>
	ðŸ”¹[oracle@node1 ~]$ srvctl start listener -l LISTENER

8. To stop Listener=>
	ðŸ”¹[oracle@node1 ~]$ srvctl stop listener -l LISTENER

9. To put database in mount mode=>

	ðŸ”¹[oracle@node1 ~]$ srvctl stop database -d prim
	ðŸ”¹[oracle@node1 ~]$ srvctl status database -d prim
Instance prim1 is not running on node node1
Instance prim2 is not running on node node2
	ðŸ”¹[oracle@node1 ~]$ srvctl start database -d prim -o mount
	
SQL> select name, open_mode from v$database;

NAME      OPEN_MODE
--------- --------------------
PRIM      MOUNTED

Similarly, to put in nomount or open state first shutdown and then:

	ðŸ”¹[oracle@node1 ~]$ srvctl start database -d prim -o nomount
	ðŸ”¹[oracle@node1 ~]$ srvctl start database -d prim -o open


ðŸ“ŒCRSCTL(Cluster Ready Services Control Utility)
-----------
=> To start and stop cluster services using crvctl.

1. To stop particular node cluster services
	ðŸ”¹[root@node2 ~]# crsctl stop crs -f	(-f -> forcefully)
	To Start
	ðŸ”¹[root@node2 ~]# crsctl start crs

2. To stop entire RAC cluster 
	ðŸ”¹[root@node2 ~]# crsctl stop cluster -all	(-all -> Both node1, node2 and all services inside it).
	To Start
	ðŸ”¹[root@node2 ~]# crsctl start cluster

3. To check status of Clusterware resources
	ðŸ”¹[root@node2 ~]# crsctl stat res -t	(-t -> Tabular form)
	
4. To check the health of Clusterware services

	ðŸ”¹[root@node1 ~]# crsctl check crs
CRS-4638: Oracle High Availability Services is online
CRS-4537: Cluster Ready Services is online
CRS-4529: Cluster Synchronization Services is online
CRS-4533: Event Manager is online
â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–



ðŸ“ŒSCAN & RAC LISTENER
-----------------------

Request from app server
|
-> It will look for hostname in tnsnames.ora(client side) and get hostname as rac-scan
Now to convert/resolve this rac-scan into IP address DNS server or HOST file(/etc/hosts) will resolve rac-scan name into 1 of 3 ip address present in DNS server in Round Robin.
Further three SCAN_LISTENERS will be created for these three ip address.
SCAN_LISTENERS will use that ip and do load balancing and send request to LOCAL_LISTENER of any respective Nodes. 
{âš ï¸Note:- If node 1 is down then all connections will be diverted automatically to other nodes.}
{âš ï¸Note:- If we want to connect to particular node then provide the hostname as node1 in tnsnames.ora(client side)}
{âš ï¸Note:- If we want to connect to pluggable DB then provide the service name as pdbprim in tnsnames.ora(client side)}

                                                  -------------
												  |ROUND ROBIN|
												  -------------
													   â†»					
		------------------	----------------	|---------------|
		| APP SERVER REQ |	| tnsnames.ora |    | DNS SERVER    |		
        ------------------  ----------------    |---------------|                       LOAD BALANCING ADVISOR
				â¬‡â¬‡ï¸				 â¬‡â¬‡ï¸                    â¬‡â¬‡ï¸                                         â¬‡â¬‡ï¸		
				
			----------		------------        -----------------		                        		    ------------------
			| user 1 |---->	| RAC_SCAN | =====> | SCAN IP       |		|-----------------|     |---|       | LOCAL_LISTENER |
			----------      ------------        | 192.168.56.91 |-----> | SCAN_LISTENER 1 |     | L |       |     NODE 1     |
												|               |       |-----------------|     |   |       ------------------			
												|---------------|                               | B |       			
			----------		------------        |               |                               |   |       ------------------
			| user 2 |----> | RAC_SCAN | =====> | SCAN IP       |		|-----------------|     | A |       | LOCAL_LISTENER |
			----------      ------------        | 192.168.56.92 |-----> | SCAN_LISTENER 2 |     |   |       |     NODE 2     |
												|               |       |-----------------|     |   |       ------------------			
												|---------------|                               |   |       			
			----------		------------        |               |                               |   |       ------------------
			| user 3 |----> | RAC_SCAN | =====> | SCAN IP       |		|-----------------|     |   |       | LOCAL_LISTENER |
			----------      ------------        | 192.168.56.93 |-----> | SCAN_LISTENER 3 |     |   |       |     NODE 3     |
												|               |       |-----------------|     | L |       ------------------ 			
                                                |---------------|                               |   |                   
																								| B |       ------------------			
																								|   |       | LOCAL_LISTENER |
																								| A |       |     NODE 4     |
																								|---|       ------------------
			                                                                                                
â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–



ðŸ“ŒRMAN_RAC
-----------

1. Put database in archive logmode.
2. The RMAN backup taken on RAC environment should be stored inside common storage of both nodes i.e a common diskgroup.
3. Set common archive log destination.
	SQL> alter system set log_archive_dest_1='location=+FRA' scope=both;
4. Create a diskgroup +FRA using asmcmd.

âœ…BYDEFAULT DIFFERENTIAL

RUN
	{
	  ALLOCATE CHANNEL ch11 TYPE DISK MAXPIECESIZE 10G;
	  ALLOCATE CHANNEL ch12 TYPE DISK MAXPIECESIZE 10G;
	  ALLOCATE CHANNEL ch13 TYPE DISK MAXPIECESIZE 10G;
	  BACKUP
	  FORMAT '/u01/rman/%d_D_%T_%u_s%s_p%p'
	  INCREMENTAL LEVEL 1 DATABASE
	  CURRENT CONTROLFILE
	  FORMAT '/u01/rman/%d_C_%T_%u'
	  SPFILE
	  FORMAT '/u01/rman/%d_S_%T_%u'
	  PLUS ARCHIVELOG
	  FORMAT '/u01/rman/%d_A_%T_%u_s%s_p%p';
	  RELEASE CHANNEL ch11;
	  RELEASE CHANNEL ch12;
	  RELEASE CHANNEL ch13;
	}

âœ… TO MAKE CUMULATIVE

RUN
	{
	  ALLOCATE CHANNEL ch11 TYPE DISK MAXPIECESIZE 10G;
	  ALLOCATE CHANNEL ch12 TYPE DISK MAXPIECESIZE 10G;
	  ALLOCATE CHANNEL ch13 TYPE DISK MAXPIECESIZE 10G;
	  BACKUP
	  FORMAT '/u01/rman/%d_D_%T_%u_s%s_p%p'
	  INCREMENTAL LEVEL 1 CUMULATIVE DATABASE
	  CURRENT CONTROLFILE
	  FORMAT '/u01/rman/%d_C_%T_%u'
	  SPFILE
	  FORMAT '/u01/rman/%d_S_%T_%u'
	  PLUS ARCHIVELOG
	  FORMAT '/u01/rman/%d_A_%T_%u_s%s_p%p';
	  RELEASE CHANNEL ch11;
	  RELEASE CHANNEL ch12;
	  RELEASE CHANNEL ch13;
	}
	
âœ… Now to store the RMAN backup on shared location and splitting the channel on both nodes.

RUN
	{
	  ALLOCATE CHANNEL c1 TYPE DISK CONNECT 'sys/oracle@prim1';
	  ALLOCATE CHANNEL c2 TYPE DISK CONNECT 'sys/oracle@prim1';
	  ALLOCATE CHANNEL c3 TYPE DISK CONNECT 'sys/oracle@prim2';
	  ALLOCATE CHANNEL c4 TYPE DISK CONNECT 'sys/oracle@prim2';
	  BACKUP
	  FORMAT '+DATA/PRIM/RMAN/FULL_%d_D_%T_%u_s%s_p%p'
	  INCREMENTAL LEVEL 0 DATABASE
	  CURRENT CONTROLFILE
	  FORMAT '+DATA/PRIM/RMAN/FULL_%d_C_%T_%u'
	  SPFILE
	  FORMAT '+DATA/PRIM/RMAN/FULL_%d_S_%T_%u'
	  PLUS ARCHIVELOG
	  FORMAT '+DATA/PRIM/RMAN/FULL_%d_A_%T_%u_s%s_p%p';
	  RELEASE CHANNEL c1;
	  RELEASE CHANNEL c2;
	  RELEASE CHANNEL c3;
	  RELEASE CHANNEL c4;
	}
RUN {
	ALLOCATE CHANNEL c1 TYPE DISK CONNECT 'sys/oracle@prim1';
	BACKUP CURRENT CONTROLFILE FORMAT '+DATA/PRIM/RMAN/FULL_%d_C_%T_%U';
	RELEASE CHANNEL c1;
  }
  
  
ðŸ“ŒRMAN_RESTORATION_RAC
------------------------

ðŸ”¸ First of all, make sure the clusterware is Up and Running.

[grid@node1 ~]# crsctl check crs
[grid@node1 ~]# crsctl status resource -t

ASMCMD [+] > ls -ld +DATA
State    Type    Rebal  Name
MOUNTED  EXTERN  N      DATA/

ðŸ”¸ Make sure that we have a backup set of the database.

[oracle@node1 rman]$ ll
total 2715244
-rw-r-----. 1 oracle asmadmin 126724096 Sep 29 20:05 FULL_PRIM_A_20250929_3m44tnjv_s118_p1
-rw-r-----. 1 oracle asmadmin 117346816 Sep 29 20:05 FULL_PRIM_A_20250929_3n44tnk0_s119_p1
-rw-r-----. 1 oracle asmadmin  22060032 Sep 29 20:05 FULL_PRIM_A_20250929_3o44tnk0_s120_p1
-rw-r-----. 1 oracle asmadmin  13993984 Sep 29 20:05 FULL_PRIM_A_20250929_3p44tnk1_s121_p1
-rw-r-----. 1 oracle asmadmin   9806336 Sep 29 20:05 FULL_PRIM_A_20250929_3q44tnk3_s122_p1
-rw-r-----. 1 oracle asmadmin      6656 Sep 29 20:05 FULL_PRIM_A_20250929_4644tnks_s134_p1
-rw-r-----. 1 oracle asmadmin      4608 Sep 29 20:05 FULL_PRIM_A_20250929_4744tnks_s135_p1
-rw-r-----. 1 oracle asmadmin  20086784 Sep 29 20:05 FULL_PRIM_C_20250929_4444tnkm
-rw-r-----. 1 oracle asmadmin 826540032 Sep 29 20:05 FULL_PRIM_D_20250929_3r44tnk7_s123_p1
-rw-r-----. 1 oracle asmadmin 455729152 Sep 29 20:05 FULL_PRIM_D_20250929_3s44tnk7_s124_p1
-rw-r-----. 1 oracle asmadmin   9076736 Sep 29 20:05 FULL_PRIM_D_20250929_3t44tnk7_s125_p1
-rw-r-----. 1 oracle asmadmin 264290304 Sep 29 20:05 FULL_PRIM_D_20250929_3u44tnk7_s126_p1
-rw-r-----. 1 oracle asmadmin 256163840 Sep 29 20:05 FULL_PRIM_D_20250929_3v44tnkc_s127_p1
-rw-r-----. 1 oracle asmadmin 238002176 Sep 29 20:05 FULL_PRIM_D_20250929_4044tnkf_s128_p1
-rw-r-----. 1 oracle asmadmin 229629952 Sep 29 20:05 FULL_PRIM_D_20250929_4144tnkh_s129_p1
-rw-r-----. 1 oracle asmadmin  99090432 Sep 29 20:05 FULL_PRIM_D_20250929_4244tnkk_s130_p1
-rw-r-----. 1 oracle asmadmin  91717632 Sep 29 20:05 FULL_PRIM_D_20250929_4344tnkl_s131_p1
-rw-r-----. 1 oracle asmadmin    114688 Sep 29 20:05 FULL_PRIM_S_20250929_4544tnkm


ðŸ”¸ Now restore the spfile to temp location

RMAN> restore spfile to '/tmp/spfileprim.ora' from '/u01/rman/FULL_PRIM_S_20250929_4544tnkm';

ðŸ”¸ Shutdown database
SQL> shu immediate;
SQL> exit

Create pfile from spfile
RMAN> create pfile from spfile='/tmp/spfileprim.ora';

ðŸ”¸ It will be created at oraclehome dbs location.
[oracle@node1 dbs]$ ls initprim.ora
initprim.ora

ðŸ”¸ start database in nomount with the pfile.
[oracle@node1 dbs]$ sqlplus / as sysdba
SQL> startup nomount pfile='initprim.ora';

ðŸ”¸ Now restore control file
RMAN> restore controlfile from '/u01/rman/FULL_PRIM_C_20250929_4444tnkm';

Now the controlfile will automatically get restored in +DATA diskgroup as the location specified in pfile as we started database with pfile.

ðŸ”¸ start database in mount with the controlfile.
SQL> startup mount
SQL> exit

ðŸ”¸ Now create spfile from pfile
RMAN> create spfile='+DATA/PRIM/spfilePRIM.ora' from pfile='/u01/app/oracle/product/19c/dbhome/dbs/initprim.ora';

ðŸ”¸ Now we have to start our database with spfile which is in +DATA diskgroup but when we hit startup the database will start with the spfile present in oracle 
home dbs, so we will rename our pfile 'initprim.ora' to 'initprim.ora_bkp' and create new pfile with parameter spfile='+DATA/PRIM/spfilePRIM.ora' and start
the database with this new file so that it knows the location of the spfile in +DATA diskgroup.

ðŸ”¸ shutdown and start database in mount.
SQL> shu immediate;
SQL> startup mount

ðŸ”¸ Now recover datafile and archive log files, but before that do catalogue start so that rman knows from where to restore the backup.

RMAN> catalogue start with '/u01/rman/';

RMAN> restore database;

RMAN> recover database

ðŸ”¸ Now open database in reset logs.

RMAN> alter database open resetlogs;
RMAN> exit

ðŸ”¸ Now since ebverything is done node 1 so to inform node 2 about this restoration.
ADD DATABASE TO CLUSTER and Add rac Instanses
[oracle@node1 dbs]$ srvctl add database -d prim -o $ORACLE_HOME
[oracle@node1 dbs]$ srvctl add instance -d prim -i prim1 -n node1
[oracle@node1 dbs]$ srvctl add instance -d prim -i prim2 -n node2

[oracle@node1 dbs]$ srvctl config database -d PRIM

ðŸ”¸ Now acknowledge the config file about location of spfile
[oracle@node1 dbs]$ srvctl modify database -d prim -spfile +DATA/PRIM/spfileprim.ora

ðŸ”¸ Now create password file

[oracle@node1 dbs]$ orapwd file='+DATA' dbuniquename='prim' password=oracle
â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–


ðŸ“ŒRAC_PATCH
---------------

[oracle@node1 dbhome]$ $ORACLE_HOME/OPatch/opatch version
OPatch Version: 12.2.0.1.29

Prechecks
Check Patch Conflict

$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/patches/33509923/33515361
 
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/patches/33509923/33529556
 
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/patches/33509923/33534448
 
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/patches/33509923/33239955
 
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/patches/33509923/33575402


Stop clusterware services
$ORACLE_HOME/crs/install/rootcrs.sh -prepatch

Apply the patch on GRID HOME

$ORACLE_HOME/OPatch/opatch apply -oh $ORACLE_HOME -local -silent /u01/patches/33509923/33515361
$ORACLE_HOME/OPatch/opatch apply -oh $ORACLE_HOME -local -silent /u01/patches/33509923/33529556
$ORACLE_HOME/OPatch/opatch apply -oh $ORACLE_HOME -local -silent /u01/patches/33509923/33534448
$ORACLE_HOME/OPatch/opatch apply -oh $ORACLE_HOME -local -silent /u01/patches/33509923/33239955
$ORACLE_HOME/OPatch/opatch apply -oh $ORACLE_HOME -local -silent /u01/patches/33509923/33575402

Apply the patch on ORACLE_HOME

$ORACLE_HOME/OPatch/opatch apply -oh $ORACLE_HOME -local -silent /u01/patches/33509923/33515361
$ORACLE_HOME/OPatch/opatch apply -oh $ORACLE_HOME -local -silent /u01/patches/33509923/33529556


[grid@node1 ~]$ $ORACLE_HOME/OPatch/opatch lspatches
33575402;DBWLM RELEASE UPDATE 19.0.0.0.0 (33575402)
33239955;TOMCAT RELEASE UPDATE 19.0.0.0.0 (33239955)
33534448;ACFS RELEASE UPDATE 19.14.0.0.0 (33534448)
33529556;OCW RELEASE UPDATE 19.14.0.0.0 (33529556)
33515361;Database Release Update : 19.14.0.0.220118 (33515361)


Start the clusterware services on Node 1
$ORACLE_HOME/crs/install/rootcrs.sh -postpatch
â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–



ðŸ“ŒCACHE FUSION
---------------
ðŸ”¸ Without Cache Fusion:

	If Node 1 modifies a data block, and Node 2 needs the same block,

	Node 2 would have to read it from disk â€” which is slow.

ðŸ”¸ What Cache Fusion Does

	Cache Fusion â€œfusesâ€ all buffer caches from the cluster into one logical global cache. Instead of reading from disk:

	Global Cache Service (GCS) and Global Enqueue Service (GES) coordinate:

	GCS knows which node has the current block version.

	Node 1 sends the latest version directly to Node 2 via interconnect(high-speed private network) , not disk directly from one instanceâ€™s memory to another.

	This inter-node block transfer keeps all nodes synchronized and improves performance dramatically.
	
	Global Cache Service (GCS) and Global Enqueue Service (GES) coordinate through the Global Resource Directory (GRD) â€” a distributed in-memory directory that tracks which 
	instance holds each data block and its current state (Shared, Exclusive, or Invalid).

	GCS checks the GRD to know which node currently owns the latest version of the requested block.
	
| Component | Full Form              | Purpose                                                        |
| --------- | ---------------------- | -------------------------------------------------------------- |
| **GCS**   | Global Cache Service   | Manages **data block access and transfer** between instances.  |
| **GES**   | Global Enqueue Service | Manages **locks and enqueues** for all other shared resources. |

ðŸ”¸ Example Scenario:

	Instance 1 has a data block in Exclusive mode.

	Instance 2 wants to read or modify that block.

	Instance 2 asks GES (via LMD) for permission.

	GES checks GRD to see who owns it â†’ finds Instance 1.

	GCS (via LMS) coordinates block transfer from Instance 1 â†’ Instance 2.

	GRD is updated with the new ownership and state.

âœ… Result: Both instances stay consistent without disk I/O.
â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–


ðŸ“ŒVOTING DISK
---------------
Voting Disk is a special file in Oracle RAC that stores the heartbeat information of all cluster nodes and helps determine which nodes are part of the active cluster.

Number of Voting Disks:	Typically 3 voting disks (odd number for majority voting) â€” can be stored in Oracle ASM for redundancy.
Location: Usually stored on shared storage accessible by all nodes (ASM disk group, shared file system, or raw devices).
Function: Each node writes a heartbeat to the voting disk at regular intervals. If a node fails to update its heartbeat, Clusterware marks it as dead and evicts it to 
		  protect data consistency.

ðŸ”¹ Example Scenario

In a 3-node RAC cluster with 3 voting disks:
Each node writes its heartbeat to all 3 disks every few seconds.
If Node 2 stops responding, the other nodes detect the missing heartbeat and vote to evict Node 2 from the cluster.

Two types of heartbeats :-
 1) Network Heartbeat for communication between nodes. CSSD [Cluster Synchronization Services (CSS) daemon]process present on each node to communicate with other node for its 
    presence via heartbeat.
 2) Disc Heartbeat for communication between node and voting disk.

ðŸ”¹ Firstly voting disk was present in +DATA diskgroup itself

ðŸ”¹ QUERY to check number of Voting Disks.

	[grid@node1 ~]$ crsctl query css votedisk
##  STATE    File Universal Id                File Name Disk group
--  -----    -----------------                --------- ---------
 1. ONLINE   71abe2761e014fd2bfb98be537c2126a (/dev/oracleasm/disks/DISK1) [DATA]
Located 1 voting disk(s).

ðŸ”¹ So we create new disks for our new diskgroup +VD

	[root@node2 ~]# fdisk -l

ðŸ”¹ FORMAT THEM

	[root@node2 ~]# fdisk /dev/sdf
	[root@node2 ~]# fdisk /dev/sdg
	[root@node2 ~]# fdisk /dev/sdh

ðŸ”¹ REGISTER THEM

	oracleasm createdisk DISK5 /dev/sdf1
	oracleasm createdisk DISK6 /dev/sdg1
	oracleasm createdisk DISK7 /dev/sdh1

ðŸ”¹ CALL ASMCA and add those disks to +VD DISKGROUP.

ðŸ”¹ Now since previously voting disk was present in +DATA diskgroup now we will replace it with +VD DISKGROUP

	[grid@node2 ~]$ crsctl replace votedisk +VD
Successful addition of voting disk ce12e9840b774ffabfbcf59a5d34a1e8.
Successful addition of voting disk 408a654e235e4f16bf72e91cd131cc12.
Successful addition of voting disk 645ab6d010084f09bf688d5a0ba63c43.
Successful deletion of voting disk 71abe2761e014fd2bfb98be537c2126a.
Successfully replaced voting disk group with +VD.
CRS-4266: Voting file(s) successfully replaced
	[grid@node2 ~]$
	[grid@node2 ~]$ crsctl query css votedisk
##  STATE    File Universal Id                File Name Disk group
--  -----    -----------------                --------- ---------
 1. ONLINE   ce12e9840b774ffabfbcf59a5d34a1e8 (/dev/oracleasm/disks/DISK5) [VD]
 2. ONLINE   408a654e235e4f16bf72e91cd131cc12 (/dev/oracleasm/disks/DISK6) [VD]
 3. ONLINE   645ab6d010084f09bf688d5a0ba63c43 (/dev/oracleasm/disks/DISK7) [VD]
Located 3 voting disk(s).



ðŸ”¹ Multiple Voting Disks

	Oracle recommends 3 or 5 voting disks spread across different storage paths.

	This ensures that even if one disk or one storage fails, the cluster can still function.

ðŸ”¹ Quorum Requirement

	Cluster membership requires a majority of voting disks to be accessible.

	Example: If you have 3 voting disks:

	2 disks must be online to form quorum

	1 disk fails â†’ cluster still works

	2 disks fail â†’ cluster cannot form quorum â†’ nodes evicted

ðŸ”¹ Quorum is the minimum number of voting disks or nodes required for the cluster to function safely.
â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–




ðŸ“ŒOLR (Oracle Local Registry) & OCR (Oracle Cluster Registry)                               
---------------------------------------------------------------

ðŸ§© 1. When the RAC node starts (boot time)
	The first Oracle service to start is OHASD (Oracle High Availability Service Daemon).  
	But at this point, ASM disks (shared storage) are not yet mounted,
	so the node canâ€™t read the OCR (which is on shared storage).
â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸
âš™ï¸ 2. OHASD reads OLR (Local file)

	OLR = Oracle Local Registry
	â†’ itâ€™s a small local file stored on every RAC node.
	It has basic info like:

	ðŸ”¹ Where ASM is installed, How to start ASM, Network info, etc. 

âœ… Using OLR, Oracle can start ASM and basic cluster services.
â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸
ðŸ’¿ 3. ASM starts â†’ shared storage becomes available

	Once ASM is up, now the node can see shared disks.

	These disks contain:

	ðŸ”¹ OCR (Oracle Cluster Registry)

	ðŸ”¹ Voting Disk
â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸	
ðŸ“– 4. Oracle reads OCR

	OCR = Oracle Cluster Registry
	â†’ it has full cluster configuration, like:

	ðŸ”¹ Databases, Listeners, VIPs, Services, (basically everything about your RAC setup).

âœ… OCR is shared by all nodes and keeps the cluster in sync.
â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸	
ðŸš€ 5. Cluster fully starts

	Using OCR, Oracle starts:

	CRSD daemon (Cluster Ready Service Daemon)

Now the RAC cluster is fully up and running ðŸŽ‰
â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸â¬‡â¬‡ï¸	
â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–



ðŸ“ŒADD NODE
---------------

1. Install the linux on new machine, download the prerequisites using yum installer.
2. Do entry in the etc/hosts file of the new node as well as previuos nodes.

127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
#Public
192.168.56.71 node1.learnomate.org node1
192.168.56.72 node2.learnomate.org node2
192.168.56.73 node3.learnomate.org node3 --------- new
#Private
192.168.10.1 node1-priv.learnomate.org node1-priv
192.168.10.2 node2-priv.learnomate.org node2-priv
192.168.10.3 node3-priv.learnomate.org node3-priv --------- new
# Virtual
192.168.56.81 node1-vip.learnomate.org node1-vip
192.168.56.82 node2-vip.learnomate.org node2-vip
192.168.56.83 node2-vip.learnomate.org node3-vip --------- new
#SCAN (in production this should be configured in DNS)
192.168.56.91 node-scan.learnomate.org node-scan
192.168.56.92 node-scan.learnomate.org node-scan
192.168.56.93 node-scan.learnomate.org node-scan

3. Create Directories for oracle and grid and set bash profile. Set oracle and asm instance as prim3 and +ASM3

4. Install all asm packages and configure asm on node3.

5. Now attach the shareable asm disks to node3.

6. Now no need to install again the grid software or the database software automatically the softwares and the files will be shared from node1, node2 to the node3
   via the private ips but for that there should be password less connection for grid and oracle users of other nodes and node3.
   
7. ./sshUserSetup.sh -user grid -hosts â€œnode1 node2 node3â€ -noPromptPassphrase -confirm -advanced --------- run from either node1 or node2 (deinstall folder inside grid home).

8. Run gridSetup.sh from node1 or node2

	=> Add more node to cluster.
	=> Add public and virtual hostname of new node3 for ssh passwordless connectivity with the new node3.
	=> Root.sh will run.
	=> Install finish.
	
9. After node addition, for database software to know about newly added node run below script.

cd $ORACLE_HOME/addnode
 
./addnode.sh "CLUSTER_NEW_NODES={node3}" [from any one node (node 1 or 2) to put DB software on node 3]

	=> select node 3
	=> set ssh connectivity for node 3 (oracle user) run from node 1.
	./sshUserSetup.sh -user oracle -hosts â€œnode1 node2 node3â€ -noPromptPassphrase -confirm -advanced --------- run from either node1 or node2 (deinstall folder inside oracle home).
	=> Root.sh will run.
	=> Install Finish.

10. Add the instance on node using dbca utility (on any existing node)
	cd $ORACLE_HOME/bin
	./dbca 
	
	=> Oracle RAC database instance management
	=> Add an instance
	=> Select the database "prim"
	=> instance name as prim3 on node3
	=> Install Finish.
Instance successfully added.


ðŸ“ŒREMOVE NODE
---------------

1. Remove the instance on node using dbca utility (on any existing node)
	cd $ORACLE_HOME/bin
	./dbca
	
	=> Oracle RAC database instance management
	=> Delete an instance
	=> Select the database "prim"
	=> instance name as prim3 on node3
	=> Delete Finish.
Instance successfully deleted.
	
2. Go to node 3 and run deinstall. (Will delete oracle software and oracle home on node 3)
	[oracle@node3 ~]# cd $ORACLE_HOME/deinstall
	[oracle@node3 ~]# ./deinstall -local
	
	{âš ï¸Note:- Specify the â€œ-localâ€ flag as not to remove more than just the local nodeâ€™s software.}
	
3. Deinstall grid infrastructure home of node3 from any existing node with grid user.
	[grid@node2 ~]# cd $ORACLE_HOME/
	[grid@node2 ~]# ./gridSetup.sh
	
	=> Remove node from the cluster.
	=> select node to remove grid "node 3"
	=> Root.sh will run.
	=> Deinstall Finish.

