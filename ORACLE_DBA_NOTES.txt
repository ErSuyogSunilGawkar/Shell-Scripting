üìåORACLE 19C ARCHITECTURE
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ BLOCK DIAGRAM +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
												   _______________________________________________________
												  |                                                       |
							User Process		  |						  {INSTANCE}		              |
								|				  | _____________________________________________________ |
						        ‚ñº        		  ||                        SGA                          ||
						   Server Process ----->  ||                                                     ||
								[PGA]			  ||  Shared Pool           DB Buffer       Redo Log     ||                           
												  ||  |                       Cache         Buffer Cache ||
								                  ||  |->Library Cache                                   ||                 
												  ||  |                                                  ||    
												  ||  |->Data Dictionary                                 ||                   
												  ||     Cache                                           ||           
												  ||_____________________________________________________||                                                      
												  |                                                       |
												  |                 {BACKGROUND PROCESSES}                |
												  |      |      |       |     |      |      |       |     |
												  |    PMON   SMON    DBWR   LGWR   CKPT   ARCH   OTHERS  |												    
												  |_______________________________________________________|														    
								[PARAMETER FILE]					|			   ‚ñ≤
																	‚ñº              |
								 [PASSWORD FILE]  -----------------------------------------------  ---------	
												 | [Data Files] [Control Files] [Redo Log Files]| |Archived |
												 | [          ] [             ] [              ]| |   Log   |
												 | [          ]        üóÑÔ∏è{DATA BASE}            | |  Files  |
												  -----------------------------------------------  ---------                                                      

1) üìåSGA(System Global Area)
   ++++++++++++++++++++++
	=> Whenever user says he wants to perform any query on DB, at that time he cannot directly access DB, the user query passes via DB Instance to the DB. But for that the 
	DB Instance must have some memory to process that instructions to DB, that memory is called SGA(System Global Area). DB Instance ---2 parts--->1)Memory 2)Background Processes
	Background processes are the processes which help to fetch data from DB to DB instance and displaying them to user, etc.
	
																			 SGA
														--------------------------------------------
														|					  |                    |	
												  Shared Pool           DB Buffer Cache       Redo Log Buffer
												 |           |
											  Library	 Data Dictionary
											   Cache        Cache
											   
	>‚úÖSHARED POOL
	------------
	i)Library Cache:- Whenever a user connects DB and tries to run a query on DB, at that time oracle Optimizer creates different execution plans to execute that query on basis 
	of statistics(which has info of everything), so now whichever plan has low cost(i.e fast speed to execute that query) is selected by oracle to execute that query, this 
	process is called Cost Based Optimization(CBO). Now if user2 comes and tries to run same query then oracle Optimizer will first go to [Library Cache] and check whether any 
	plan is registered against this query or not, if registered than it will refer that plan from Library Cache and implement it, but now output will be more faster.
	
	ii)Data Dictionary Cache:- All our meta data tables(v$database, v$parameter, v$controlfile, dba_user, dba_profiles, dba_sys_privs, dba_tab_privs, dba_tablespace etc) data 
	is present in Data Dictionary Cache to improve performance.
	
	
	>‚úÖDB Buffer Cache
	----------------
	It is temporary memory, whenever a query is fired the optimizer will first look for the output in the temporary memory i.e DB Buffer Cache if not then it will look into
	the DB Data Files fetch the data & copy it inside DB Buffer Cache with help of background process and then show to user(not directly). But after sometime the DB Buffer Cache
	gets full, so now oracle follows an algorithm called as LRU(List Recently Used) to remove the data present in DB Buffer Cache which is present from long time & not used 
	frequently.
	
	
	>‚úÖRedo Log Buffer
	----------------
	If user1 writes one query to update the salary from Rs 1000 to 2000, first the data of Rs 1000 will be copied from the DB Data Files to DB Buffer Cache, now due to update 
	query the salary block of rs 1000 sent by DB Data Files by processes to DB Buffer Cache will be updated to Rs 2000 in temporary memory(DB Buffer Cache) now this 
	updated block is called Dirty Block. Now the previous salary of Rs 1000 will be stored inside UNDO Block. Now whatever query transaction we perform are stored inside 
	Redo Log Buffer. Now if you hit COMMIT to save the transaction, the data will be copied from Redo Log Buffer to Redo Log Files with help of LGWR(Log Writer). Now after
	this the final stage i.e the Dirty Block data of Rs 2000 will be permanently copied to DB Data Files with help of DBWR(Database Writer).
	
	{‚ö†Ô∏èNote 1:- If you hit ROLLBACK instead of COMMIT then the data from UNDO BLOCK will be coppied to Dirty Block and further to DB Data Files with help of DBWR.}
	{‚ö†Ô∏èNote 2:- DB Data Files & Redo Log Files both can store un-committed data but while displaying DB Data Files will only show committed data with help of background 
			  proccess known as CKPT(Check Point) and after sometime the un-committed data gets flushed.}
	
	
	*‚úÖPMON(Process Monitor):- 
	======= 
	Its main role is to monitor and manage server processes and clean up after failed or terminated processes.
	
	*‚úÖCKPT(Checkpoint):- 
	=================
	Oracle stores the SCN (System Change Number) of the most recent committed transactions in the Control File, which is a small binary file that maintains critical 
	database metadata. During database startup, the CKPT (Checkpoint Process) compares the SCN stored in the Control File with the SCN stored in the headers of Data Files.
	If the SCNs match, it means all committed transactions have been successfully written from the Redo Log Buffer into the Data Files, and the database is in a consistent state.
	It can open normally. If the SCNs do not match, it means some committed changes are still in the Redo Logs but not yet reflected in the Data Files. This may happen if the 
	database was shut down abnormally (e.g., crash). In such a case, the database enters the recovery phase. The SMON (System Monitor Process) reads the Redo Logs and applies all
	necessary changes to bring the Data Files up to date with the committed transactions. Once all changes are applied, and SCNs are aligned, the database becomes consistent and 
	is allowed to open normally.
	
	üí° Example:
	Let‚Äôs say you committed some changes at SCN 1050000, and then a checkpoint writes SCN number in CONTROLFILE and DB HEADER and DBWR(Database Writer) writes all your dirty 
	blocks to disk. Now, the datafiles are safe up to SCN 1050000.

	If the DB crashes later:

	üî∏ Oracle starts media recovery from SCN 1050000.

	üî∏ It applies redo logs only for changes after that SCN.

	
	*‚úÖSMON(System Monitor):- 
	=======        
	It is responsible to do instance recovery. It performs tasks like instance recovery at startup, cleaning up temporary segments, and recovering terminated 
	transactions when tablespaces or files are brought back online.
	
	When the database starts after an abnormal shutdown or crash, SMON:

	Reads the SCNs from control files and datafile headers.

	Identifies transactions recorded in the redo logs but not yet applied to datafiles.

	Applies those redo entries to bring the database to a consistent state.

	Once SMON completes recovery, the database can open normally.
			  
	
	+‚úÖARCHIVED LOG FILES:- 
	===================
		All this file archive process is done with help of a background process known as ARCH(ARCHIVER).

		Online Redo Logs: These are the current log files used to record changes made to the database. They are used to ensure data consistency and to allow for 
		                  recovery in case of failures. 
		
		Archived Redo Logs: When an online redo log group is filled, it's copied to an offline destination, creating an archived redo log file. These files are then used for various 
						    purposes, including recovery and point-in-time restoration.
							
		üî∏ A redo log group is a set of one or more redo log members (files) that Oracle treats as a unit.					
 					
		üî∏ When a group is being written, it‚Äôs CURRENT.
		
		üî∏ After a log switch, the just-used group becomes ACTIVE (until its redo information is no longer needed).
		
		üî∏ Once the redo information is no longer needed (all changes are safely written and archived), the group becomes INACTIVE.
			
		ARCHIVELOG Mode: This mode ensures that archived redo log files are created, allowing for more comprehensive recovery options. 
			
		NOARCHIVELOG Mode: In this mode, online redo log groups are simply discarded after being filled, making point-in-time recovery impossible. 
		
		üî∏ Log switching :- is the event when Oracle stops writing to the current active redo log group and starts writing to the next one in a cyclic manner.

		This happens:
		
			When the current redo log group fills up.
		
			When the DBA manually forces a log switch (ALTER SYSTEM SWITCH LOGFILE).
		
			Log switching allows Oracle to cycle through redo log groups continuously.
		
2) üìåPGA(PROGRAM GLOBAL AREA)
   ++++++++++++++++++++++++
   => The Program Global Area (PGA) is a private memory region dedicated to a single session process, containing data and control information for that session.
	  More PGA = faster queries (if properly used), especially for:
		üîπLarge sorts
		üîπComplex joins
		üîπAggregations
   PGA = personal counter (private, fast)

   SGA = shared pantry (used by everyone, for common stuff like caching)



   
3) üìåParameter file:- 
   ++++++++++++++++
   These are text files that contain initialization parameters and their corresponding values, defining the characteristics of the Oracle instance after starting the DB.
   
    1)‚úÖSP File(spfileprim.ora):- Binary file.(SP file gets first preference after DB is started if this file is not there then P file is checked.)
	
    2)‚úÖP File(initprim.ora):- Text file.
		 {‚ö†Ô∏èNote :- If these two files are missing DB won't start.}
				üîπSQL> show parameter spfile;
		
		NAME                                 TYPE        VALUE
		------------------------------------ ----------- ------------------------------
		spfile                               string      /data/app/oracle/product/19C/dbhome_3/dbs/spfileprim.ora
                                                 

	3)‚úÖTo check any parameter from spfile eg) open_cursor
		 
				üîπSQL> show parameters open_cursors;
		
		NAME                                 TYPE        VALUE
		------------------------------------ ----------- ------------------------------
		open_cursors                         integer     300
		
	4)‚úÖTo update any parameter
		 
				üîπSQL> alter system set open_cursors=400 scope=both;
				
				System altered.

			NAME                                 TYPE        VALUE
		------------------------------------ ----------- ------------------------------
		open_cursors                            integer     400
		 
		 
	5)‚úÖThere are 2 types of changes in parameters.
		 
		 i)Dynamic(Immediate)(we can write scope as both & spfile) ii)Static(Needs to Restart DB for changes to get reflected.)(always scope as spfile)
		 
		 If we want to change something from v$parameter and want to know whether it is Dynamic or Static.
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------		 
		 üîπSQL> alter system set open_cursors=400 scope=both;-----------------> Dynamic parameters directly changes done in both memory as well as spfile.
				
				System altered.
		 
		 üîπSQL> select name, ISSYS_MODIFIABLE from v$parameter where name='open_cursors';

		NAME
		--------------------------------------------------------------------------------
		ISSYS_MOD
		---------
		open_cursors
		IMMEDIATE ---------------> this means it is Dynamic no restart required.
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------		
		->Now we try parameter processes
		
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx.üö´If we use scope as both for static file it won't allow and give ORA error as below.xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
		
		üîπSQL> alter system set processes=400 scope=both;
		alter system set processes=400 scope=both
						*
		ERROR at line 1:
		ORA-02095: specified initialization parameter cannot be modified
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------		
		so we try changing scope from (both) to (spfile);
		
		üîπSQL> alter system set processes=400 scope=spfile;------------------> Static parameters where only changes to spfile allowed, after restart changes visible to memory.
		
		System altered.
		
		üîπSQL> select name, ISSYS_MODIFIABLE from v$parameter where name='processes';

		NAME
		--------------------------------------------------------------------------------
		ISSYS_MOD
		---------
		processes
		FALSE---------------> this means we need to restart the DB to reflect the changes.
		
	6) After doing changes to spfile we need to copy changes in pfile after doing DB Shutdown go to /data/app/oracle/product/19C/dbhome_3/dbs/initprim.ora cat in this file
	   initprim.ora and check, if changes not done then 
	   Go to SQL ---> 
	   üîπSQL> create pfile from spfile;

			File created.
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
4) üìåPassword File :-
   ++++++++++++++++++

	i) It's a special file that stores hashed passwords for administrative users (like SYSDBA or SYSOPER).

	ii) It allows remote and local authentication of users who need privileged access to the database, even when the database is down or operating in restricted modes.

	iii) Normal user passwords are stored securely inside the database in hashed form, within system tables.

Password file is only for privileged users authentication (SYSDBA/SYSOPER), especially before the database is open.


5) üìåSCOPE:- used while alterring the parameters from spfile.
   ++++++++++
   3 Types:-
	i)spfile
	ii)memory(for that particular session)
	iii)both
		
		

6) üìåCONTROL FILE:- 
    ++++++++++++++++
	When DB is installed this file is automatically installed. It has information like DB-name, Data File location, System Change Number (SCN) of committed transactions, etc.
	(.ctl extension)
	üîπSQL> select name from v$controlfile;
	
	NAME
	--------------------------------------------------------------------------------
	/data/app/oracle/oradata/PRIM/control01.ctl
	/data/app/oracle/oradata/PRIM/control02.ctl


spfile has location of --> Control File has location of --> Data file & Online Redo Log File.

=> To check DB FILES.

	üîπSQL> select file_name from dba_data_files;
	
	FILE_NAME
	--------------------------------------------------------------------------------
	/data/app/oracle/oradata/PRIM/system01.dbf
	/data/app/oracle/oradata/PRIM/sysaux01.dbf
	/data/app/oracle/oradata/PRIM/undotbs01.dbf
	/data/app/oracle/oradata/PRIM/users01.dbf
	
	a) Control File Multiplexing:- In this case we create an extra control file for backup but on different location since all control files contain same data inside them 
								   to create new file we just have to copy the existing file into new control file. But before that we have to edit spfile and add location of
								   3rd spfile inside it.
								   {‚ö†Ô∏èNote:- After creating path inside spfile, shutdown DB and only after that we can create new Control File}
								   
	1. ALTER SYSTEM SET CONTROL_FILES='/data/app/oracle/oradata/PRIM/control01.ctl','/data/app/oracle/oradata/PRIM/control02.ctl','/data/app/oracle/oradata/PRIM/control03.ctl' SCOPE=spfile;
	2. shutdown immediate.
	3. cp /data/app/oracle/oradata/PRIM/control01.ctl /data/app/oracle/oradata/PRIM/control03.ctl
	4. üîπSQL> select name from v$controlfile;

		NAME
		--------------------------------------------------------------------------------
		/data/app/oracle/oradata/PRIM/control01.ctl
		/data/app/oracle/oradata/PRIM/control02.ctl
		/data/app/oracle/oradata/PRIM/control03.ctl


	The control file contains:
	Records of:
		üîπBackup sets (datafile, control file, SPFILE, archived logs)
		üîπBackup pieces (physical files on disk/tape)
		üîπBackup history		
		üîπArchived redo logs
		üîπDatafile and tablespace info		
		üîπRestore points		
		üîπCheckpoints and SCNs


üìåComplete Example with User Processes, Server Processes, and Background Processes
	Scenario: 10 users connect to the database

	| Component                | Number/Size                           | Description                                                                                 |
	| ------------------------ | ------------------------------------- | ------------------------------------------------------------------------------------------- |
	| **User Processes**       | 10 (on client machines)               | Client-side processes sending requests to the DB.                                           |
	| **Server Processes**     | 10 (one per user session)             | Oracle server processes running SQL for each user.                                          |
	| **PGA**                  | 10 PGAs (one per server proc)         | Private memory for each server process (sorts, session state, etc.).                        |
	| **SGA**                  | 1 (shared among all server processes) | Shared memory area on DB server containing buffer cache, shared pool, redo log buffer, etc. |
	| **Background Processes** | Fixed number (e.g., LGWR, DBWR, SMON) | Oracle system processes running in background for DB management tasks.                      |
	
	How they interact:
	
	| Step                    | Explanation                                                                                     |
	| ----------------------- | ----------------------------------------------------------------------------------------------- |
	| 1. User Process         | Sends a SQL query from client machine.                                                          |
	| 2. Server Process       | Receives and executes the query. Uses its **PGA** for session memory (sorts, joins).            |
	| 3. Server Process       | Reads data from **SGA** (shared pool, buffer cache) or from disk if needed.                     |
	| 4. Background Processes | Manage writing dirty blocks to disk (DBWR), writing redo logs (LGWR), and other internal tasks. |
	| 5. Server Process       | Sends results back to User Process.



______________________________________________________________________________üìåSTARTUP SEQUENCE OF DB___________________________________________________________________________________________________

1) startup command.
2) After startup command DB needs spfile to start DB.
3) Then DB goes in (nomount state)(If DB is in "nomount state" then only DB Instance is started DB is not started.)
4) Now as soon as spfile gets location of Control File inside it, DB goes in (mount state).
5) Now as soon as Control File gets location of Data file & Online Redo Log File the DB goes in (open state) i,e read,write mode so all users now can to DB and perform DDL,DML operation on it.

=> Inside of startup command
1) startup nomount; (spfile)
2) alter database mount;
	üîπSQL> select name,open_mode from v$database;
	
	NAME      OPEN_MODE
	--------- --------------------
	PRIM      MOUNTED

3) alter database open;
	üîπSQL> select name,open_mode from v$database;
	
	NAME      OPEN_MODE
	--------- --------------------
	PRIM      READ WRITE
‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ

üìåMULTITENANT ARCHITECTURE

It is also known as CDB & PDB Architecture, introduced since 12c and compulsory from 21c.
Non CDB's don't have containers inside them, need to install another 19c or any version if two DB's are required.

Inside our DB "PRIM" there is a container called CDB(Container Database) known as "CDB$ROOT". Now inside this container there are Pluggable DB's known as PDB(Pluggable Database).
The version of this DB's is same as the DB version we downloaded i.e 19c. The applications will connected to their respective PDB's.

Advantages:-
------------
1) We can assign combine memory to the CDB itself so the PDB's inside it can share that memory(increases resource utilization).
2) For upgradation we just need to update the CDB itself, the PDB's inside it will be automatically upgraded.
3) Patching only to the CDB the PDB's inside it will be automatically patched.
4) Common Background processes for all the PDB's inside the CDB.
5) Easily Unplug and Plug the PDB's.
6) Licensing Cost is less compared to Non CDB.

Disadvantages:-
---------------
1) If container(CDB) is down then the PDB's will also be down.
______________________________
|            PRIM             |        
|  _________________________  |
| |           CDB           | |
| |                         | |
| | [PDB 1]        [PDB 2]  | |
| |_________________________| | 
|_____________________________|  
__________________________________________________________________________________________________________________________________________________________________________________
    ++++++++
----+ CDB:-+--üìå-------------------------------------------------------------------------------------------------------------------------------------------------------------------
    ++++++++

To check we are in which container.
	üîπSQL> show con_name;
	
	Firstly, we are bydefault in CDB. 
	
	CON_NAME
	------------------------------
	CDB$ROOT
__________________________________________________________________________________________________________________________________________________________________________________

    ++++++++
----+ PDB:-+--üìå--------------------------------------------------------------------------------------------------------------------------------------------------------------------
    ++++++++

	üîπSQL> show pdbs;

    CON_ID CON_NAME                       OPEN MODE  RESTRICTED
---------- ------------------------------ ---------- ----------
         2 PDB$SEED                       READ ONLY  NO
         3 PDBPRIM                        MOUNTED


In this "PDB$SEED" is automatically downloaded always in Read only mode, and "PDBPRIM" we have downloaded.

Now to go inside PDB.

	üîπSQL> alter session set container=PDBPRIM;
	üîπSQL> show con_name;
	
	CON_NAME
	------------------------------
	PDBPRIM

Now we are inside PDB (PDBPRIM).

now since we are inside PDB if we hit startup command we start PDB (PDBPRIM).
	üîπSQL> startup
	Pluggable Database opened.

	üîπSQL> show pdbs;
	
		CON_ID CON_NAME                       OPEN MODE  RESTRICTED
	---------- ------------------------------ ---------- ----------
			3 PDBPRIM                        READ WRITE NO
		 
Now we are in read/write mode we can run all operations.
now since we are inside PDB if we hit shutdown command we will close PDB (PDBPRIM).
üîπSQL> shutdown immediate
Pluggable Database closed.

	üîπSQL> alter session set container=CDB$ROOT; ---------------------->go back to CDB.
	
	Session altered.

Now we can add one more PDB by calling dbca in ORACLE_HOME path.
‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ


üìåUSER MANAGEMENT DBA

There are two types of user in container DB's.
{The metadata table to find info for all the users is "dba_users".}

1)Common User:- This user is present in the container(CDB) as well as all the PDB's inside it.
                eg:- "sys" user =>but this user is system generated user.
                If we want to make our own common user then the command is type=> create user C##username identified by password.
				
2)Local User:- This user is specific to that PDB itself.
               If we want to make our local user then the command is type=> create user username identified by password.
			   
  {‚ö†Ô∏èNote:- You cannot create a local user inside container CDB}
  

===> ‚úÖCreating common user in CDB

		üîπSQL> show con_name;
		
		CON_NAME
		------------------------------
		CDB$ROOT
		
		üîπSQL> create user C##CDBUSER identified by CDBUSER;
		
		User created.

--> ‚úÖNow checking whether the user is created in PDB.

--> ‚úÖNow create user in PDBPRIM

		üîπSQL> create user u1 identified by u1;
		
		
		
		User created.
		
		üîπSQL> select username from dba_users where username='U1';
		
		USERNAME
		--------------------------------------------------------------------------------
		U1 -----------> Stored in Capital Letters

--> ‚úÖNow give create session permission to u1.

		üîπSQL> show user;
		USER is "SYS"
		üîπSQL>
		üîπSQL> grant create session to u1;
		
		Grant succeeded.

--> ‚úÖTo change the password of user u1 as u11.

		üîπSQL> alter user u1 identified by u11;
		
		User altered.
		
		{‚ö†Ô∏èNote:- All this tasks regarding the permissions and all of other users can be done using "sys" user only}

--> ‚úÖTo check and change account status of the user.

		üîπSQL> select username, account_status from dba_users where username='U1';
		
		USERNAME
		--------------------------------------------------------------------------------
		ACCOUNT_STATUS
		--------------------------------
		U1
		OPEN
		
		üîπSQL> alter user u1 account lock;
		
		User altered.	
		
		üîπSQL> alter user u1 account unlock;
		
		User altered.

--> ‚úÖTo login with user type=> username/password@pdbname (eg:- u1/u1@pdbprim)

--> ‚úÖTo expire password so that the user himself can set new password while logging in.

	1) By sysdba user 
		üîπSQL> alter user u1 password expire;
	
		User altered.
		
	2) By u1 user
	
	[oracle@node1 admin]$ sqlplus u1/u1@pdbprim
	ERROR:
	ORA-28001: the password has expired

	Changing password for u1
	New password:
	Retype new password:
	Password changed


++++‚úÖ Tablespace++++
-------------------
Whenever a user is created we need to assign him 2 tablespaces.

	1)Default -"USERS" Tablespace is created by default while installing DB.         
	2)Temporary - "TEMP" Tablespace is created by default while installing DB.

CREATE USER myuser IDENTIFIED BY MyPassword123 DEFAULT TABLESPACE users TEMPORARY TABLESPACE temp PROFILE app_profile QUOTA 500M ON users;



==>üìåPROFILE
-----------
Consider a DB and it has lots of users in it. Generally the password of all the users is set/reset at same time generally reset after (90 days). So for eg the DB owner applies 
some set of policies to users like 1)the password should expire within 90 days, 2)after three invalid login the user has to try again after 24 hrs, 3)password should be alphanumeric,etc
on group of users, these sets of policies are combinely called as profile. So we have to create a profile and put these policies inside it.

Now if you don't assign any profile to a new user then it will automaticalley get a default profile known as "DEFAULT" profile.
Now the profile will be same for all users inside that group but that the values may differ as per the user.(for eg: the invalid password attempts may be different for diff users)

--> ‚úÖTo check default profile 

go to pdb search user U1
	üîπSQL> select username, profile from dba_users where username='U1';

	USERNAME
	--------------------------------------------------------------------------------
	PROFILE
	--------------------------------------------------------------------------------
	U1
	DEFAULT

--> ‚úÖTo check what inside profile

	üîπSQL> select PROFILE, RESOURCE_NAME, RESOURCE_TYPE, LIMIT from dba_profiles where profile='DEFAULT';

--> ‚úÖTo create new profile

	CREATE PROFILE APP2_PROFILE
	LIMIT
	COMPOSITE_LIMIT UNLIMITED
	SESSIONS_PER_USER UNLIMITED
	CPU_PER_SESSION UNLIMITED
	CPU_PER_CALL UNLIMITED
	LOGICAL_READS_PER_SESSION UNLIMITED
	LOGICAL_READS_PER_CALL UNLIMITED
	IDLE_TIME 90
	CONNECT_TIME UNLIMITED
	PRIVATE_SGA UNLIMITED
	FAILED_LOGIN_ATTEMPTS 10
	PASSWORD_LIFE_TIME 30
	PASSWORD_REUSE_TIME UNLIMITED
	PASSWORD_REUSE_MAX UNLIMITED
	PASSWORD_VERIFY_FUNCTION NULL
	PASSWORD_LOCK_TIME UNLIMITED
	PASSWORD_GRACE_TIME UNLIMITED;


--> ‚úÖTo change user profile (eg: from "DEFAULT to APP_PROFILE")

	üîπSQL> alter user u1 profile app_profile;
	
	USERNAME                                             PROFILE
	------------------------------------------------- -----------------------------------------------------
	U1                                                   APP_PROFILE

--> ‚úÖTo give quota for user on a specific tablespace.

	üîπSQL> ALTER USER u2 QUOTA UNLIMITED ON users;
  or
	üîπSQL> ALTER USER u2 QUOTA 50M ON users;



==>üìåPERMISSIONS & PRIVILEGES
----------------------------
To give permissions use command-> "GRANT" & to remove permissions use command-> "REVOKE"
There are two types of permissions:-

1) System Level
   ------------
   a)Scope:- Entire database 
   b)Who uses it:-	DBAs, developers
   c)Examples:- CREATE USER, DROP ANY TABLE
   d)Security risk:- Higher (can affect entire DB)
   
	üîπSQL> select distinct privilege from dba_sys_privs;

	PRIVILEGE
	----------------------------------------
	INHERIT ANY PRIVILEGES
	CREATE TABLESPACE
	ALTER USER
	CREATE ANY CONTEXT
	SELECT ANY MINING MODEL
	CREATE LOCKDOWN PROFILE
	CREATE TABLE
	CREATE ANY TABLE
	ADMINISTER KEY MANAGEMENT
	DROP ANY TYPE
	ALTER SYSTEM
	DEBUG CONNECT ANY
	DELETE ANY CUBE DIMENSION
	ALTER ANY CUBE BUILD PROCESS
	DROP ANY SYNONYM
	DROP PUBLIC SYNONYM
	.......
	
	üîπSQL> select privilege, grantee from dba_sys_privs where grantee='U1';

	PRIVILEGE                                GR
	---------------------------------------- --
	CREATE SESSION                           U1



2) Object Level
   ------------
	a)Scope:- Specific object (table, view, etc.)
	b)Who uses it:- Application users, data analysts
	c)Examples:- SELECT ON emp, EXECUTE ON proc1
	d)Security risk:- Lower (limited to specific object access)

üîπSQL> select distinct privilege from dba_tab_privs;

	PRIVILEGE
	----------------------------------------
	REFERENCES
	USE
	INSERT
	ALTER
	DEQUEUE
	WRITE
	EXECUTE
	INHERIT PRIVILEGES
	DELETE
	UPDATE
	SELECT
	READ
	INHERIT REMOTE PRIVILEGES
	FLASHBACK

Now sys user can give some permissions to other users to perform queries(i.e sys can give permissions to U2 to perform operations on table T1 created bu U1(OWNER))

	üîπSQL> grant select on u1.t1 to u2;

	Grant succeeded.

	üîπSQL> select grantee,owner,table_name,privilege from dba_tab_privs where grantee='U2';

	GRANTEE                        OWNER                          TABLE_NAME                     PRIVILEGE
	------------------------------ ------------------------------ ------------------------------ ------------------------------
	U2                             U1                             T1                             SELECT
	
	
-->üìåROLE:-
---------
A named group/set of related privileges that can be granted to users or other roles.
They make privilege management simpler and more organized.
Instead of giving same permissions to different users we can give those permissions to role and role will further give them to users.

	üîπSQL> create role app_role;
	
	Role created.
	
	üîπSQL> grant select on u1.t1 to app_role;
	
	Grant succeeded.
	
	üîπSQL> grant create session to app_role;
	
	Grant succeeded.
	
	üîπSQL> grant app_role to u1;
	
	Grant succeeded.
	
	üîπSQL> select role,privilege from role_sys_privs where role='APP_ROLE';
	
	ROLE                                                                                                                             PRIVILEGE
	-------------------------------------------------------------------------------------------------------------------------------- ---------------------------                                                               ---
	APP_ROLE                                                                                                                         CREATE SESSION
	
	
	üîπSQL> select role,owner,table_name,privilege from role_tab_privs where role='APP_ROLE';
	
	ROLE                                                                                                    OWNER                     TABLE_NAME                         PRIVILEGE
	--------------------------------------------------------------------------------------------- ------------------------------ ------------------------------ ------------------------------
	APP_ROLE                                                                                                 U1                            T1                              SELECT

--> Drop Role -> drop role role_name;
‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ


üìåLISTENER

Listener is installed with the server itself, it helps user to connect to DB for the first time, it works as a handshake protocol, listener comes into role only when a new 
request is received. First listener checks whether listener itself is registered with DB or not(process known as registeration), if registered then handshake of user & DB 
is done, later listener is of no use.

There are two files containing the listener name, port, etc.:-
1)tnsnames.ora (present at client side as well as server side $OH/network/admin/tnsnames.ora  while using sqldeveloper contains DB details)     
2)listener.ora (present at server side $OH/network/admin/listener.ora)

======>üìåWe have one utility to start listener known as "lsnrctl" present in ORACLE_HOME/bin
->To start [lsnrctl start] now whenever we start listener it reads a file called "listener.ora" file present at $OH/network/admin. 
->To check status [lsnrctl status]
->To stop [lsnrctl stop]
->To restart[lsnrctl reload]


++> LISTENER REGISTERATION

1) Dynamic Registeration :- Here the name of listener should be "LISTENER" and port "1521". This is default setting.
							It will automatically register we can check after typing-> lsnrctl start.
							here the listener.ora file will have only name of listener and port 1521 no specific database registered.
							
							# listener.ora Network Configuration File: /u01/app/oracle/product/19.3.0/db_home/network/admin/listener.ora
							# Generated by Oracle configuration tools.
							
							LISTENER =
								(DESCRIPTION_LIST =
									(DESCRIPTION =
									(ADDRESS = (PROTOCOL = TCP) (HOST = node1.learnomate.org)(PORT = 1521))
									(ADDRESS = (PROTOCOL = ICP) (KEY = EXTPROC1521))
									)
								)
							
							# tnsnames.ora Network Configuration File: /u01/app/oracle/product/19.3.0/db_home/network/admin/tnsnames.ora
							# Generated by Oracle configuration tools.
							
							LISTENER_PRIM =                                                          #we can give any name in tnsnames.ora as it is at client side.
								(ADDRESS = (PROTOCOL = TCP) (HOST = node1) (PORT = 1521))
							
							PRIM =
                                (DESCRIPTION =
                                	(ADDRESS = (PROTOCOL = TCP)(HOST = node1.learnomate.org)(PORT = 1521))
                                	(CONNECT_DATA =
                                	(SERVER = DEDICATED)
                                	(SERVICE_NAME = prim)
                                	)
							
							
							
2) Static Registeration :- You manually define the instance information in the listener.ora file.
                           Required for Oracle RAC, Dataguard, or special configurations (like when dynamic reg fails).
						   
						   # listener.ora Network Configuration File: /u01/app/oracle/product/19.3.0/db_home/network/admin/listener.ora
						   # Generated by Oracle configuration tools.
						   
						   LISTENER =
						   	(DESCRIPTION_LIST =
						   		(DESCRIPTION =
						   		(ADDRESS = (PROTOCOL = TCP) (HOST = node1.learnomate.org)(PORT = 1521))
						   		(ADDRESS = (PROTOCOL = ICP) (KEY = EXTPROC1521))
						   		)
						   	)
						   
						   SID_LIST_LISTENER =
						     (SID_LIST =
						     	(SID_DESC =
						     		(GLOBAL_DBNAME = prim)
						     		(ORACLE_HOME = /u01/app/oracle/product/19.3.0/db_home)
						     		(SID_NAME = prim)
						     	)
						      )
						   
						   
						   # tnsnames.ora Network Configuration File: /u01/app/oracle/product/19.3.0/db_home/network/admin/tnsnames.ora
						   # Generated by Oracle configuration tools.
						   
						   LISTENER_PRIM =                                                          #we can give any name in tnsnames.ora as it is at client side.
						   	(ADDRESS = (PROTOCOL = TCP) (HOST = node1) (PORT = 1521))
						   
						   PRIM =
						       (DESCRIPTION =
						       	(ADDRESS = (PROTOCOL = TCP)(HOST = node1.learnomate.org)(PORT = 1521))
						       	(CONNECT_DATA =
						       	(SERVER = DEDICATED)
						       	(SERVICE_NAME = prim)
						       	)

[oracle@node1 admin]$ ps -ef | grep tnslsnr
grid      7312     1  0 12:50 ?        00:00:00 /u02/app/grid/product/19c/dbhome/bin/tnslsnr LISTENER -no_crs_notify -inherit
grid      7344     1  0 12:50 ?        00:00:00 /u02/app/grid/product/19c/dbhome/bin/tnslsnr LISTENER_SCAN1 -no_crs_notify -inherit
grid      7385     1  0 12:50 ?        00:00:00 /u02/app/grid/product/19c/dbhome/bin/tnslsnr ASMNET1LSNR_ASM -no_crs_notify -inherit
oracle   11748  8715  0 12:53 pts/0    00:00:00 grep --color=auto tnslsnr
‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ



						  					   
üìåTABLESPACE MANAGEMENT

++>TABLESPACE
--------------
TABLESPACE is collection of DATAFILES. One or more users can be assigned to a single tablespace.
Maximum size that a single DATAFILE inside TABLESPACE can have is 32GB. (Depends on the DB_BLOCK_SIZE = 8KB = 32GB, if 16KB then 64GB)
	üîπüîπSQL> show parameter db_block;

	NAME                                 TYPE        VALUE
	------------------------------------ ----------- ------------------------------
	db_block_buffers                     integer     0
	db_block_checking                    string      FALSE
	db_block_checksum                    string      TYPICAL
	db_block_size                        integer     8192 --------8KB

Maximum no of DATAFILES inside a single tablespace is 1022 FILES.

Whenever a DB is installed 5 tablespaces are automatically installed.

1)SYSTEM :- Stores the data dictionary (metadata) and core system objects(meta data tables).
2)SYSAUX :- Auxiliary tablespace to offload data from SYSTEM tablespace and has(AWR (Automatic Workload Repository), OEM (ORACLE ENTERPRISE MANAGER)).
3)UNDO :- Stores undo data for transactions to allow rollback and read consistency.
4)TEMP :- Used for sorting, temporary tables, and intermediate query operations when PGA gets full.
5)USERS :- Used when you forget to assign any tablespace to a newly created user.

Metadata table name -> "dba_tablespace"

	üîπüîπSQL> select username, default_tablespace from dba_users where username='U2';
	
	USERNAME
	--------------------------------------------------------------------------------
	DEFAULT_TABLESPACE
	------------------------------
	U2
	USERS


--> üìåTo create new TABLESPACE
   --------------------------

	üîπüîπSQL> CREATE TABLESPACE new_tbs DATAFILE '/data/app/oracle/oradata/PRIM/pdbprim/newtbsfile01.dbf' SIZE 100M AUTOEXTEND ON NEXT 10M MAXSIZE 500M EXTENT MANAGEMENT LOCAL
		 SEGMENT SPACE MANAGEMENT AUTO;


--> üìåTo Create a User and Assign the Tablespace
   --------------------------------------------

	üîπüîπSQL> CREATE USER new_user IDENTIFIED BY strong_password DEFAULT TABLESPACE new_tbs TEMPORARY TABLESPACE temp QUOTA UNLIMITED ON new_tbs;


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++üìåSCRIPT FOR TABLESPACE UTILIZATION+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
	set linesize 1234 pages 1234                ======================================================> @table_util.sql
	col tablespace format a24
	col free heading 'Free(Mb)' format 99999999.9
	col total heading 'Total(Mb)' format 999999999.9
	col used heading 'Used(Mb)' format 99999999.9
	col pct_free heading 'Pct|Free' format 99999.9
	col largest heading 'Largest(Mb)' format 99999.9
	compute sum of total on report
	compute sum of free on report
	compute sum of used on report
	break on report
	select substr(a.tablespace_name,1,24) tablespace,
	round(sum(a.total1)/1024/1024, 1) Total,
	round(sum(a.total1)/1024/1024, 1)-round(sum(a.sum1)/1024/1024, 1) used,
	round(sum(a.sum1)/1024/1024, 1) free,
	round(sum(a.sum1)/1024/1024, 1)*100/round(sum(a.total1)/1024/1024, 1) pct_free,
	round(sum(a.maxb)/1024/1024, 1) largest,
	max(a.cnt) fragments
	from
	(select tablespace_name, 0 total1, sum(bytes) sum1,
	max(bytes) MAXB,
	count(bytes) cnt
	from dba_free_space
	group by tablespace_name
	union
	select tablespace_name, sum(bytes) total1, 0, 0, 0 from dba_data_files
	group by tablespace_name
	union
	select tablespace_name, sum(bytes) total1, 0, 0, 0 from dba_temp_files
	group by tablespace_name) a
	group by a.tablespace_name
	/
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
============================================================>üìåTo check and increase Tablespaces size<==============================================================================
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++USERS TABLESPACE++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

‚úÖFirst check whether the the tablespace's auto extension is on or not bydefault it is on to increase it manually we will turn it off.

	TABLESPACE_NAME                 FILE_NAME                                       AUT MAXBYTES/1024/1024/1024
	---------------------- ----------------------------                             --- -----------------------
	USERS                  /data/app/oracle/oradata/PRIM/pdbprim/users01.dbf        YES  31.9999847
	
	üîπüîπSQL> select TABLESPACE_NAME, FILE_NAME,AUTOEXTENSIBLE,MAXBYTES/1024/1024/1024 from dba_Data_files;
	üîπüîπSQL> ALTER DATABASE DATAFILE '/data/app/oracle/oradata/PRIM/pdbprim/users01.dbf' AUTOEXTEND OFF;
	
	TABLESPACE_NAME                 FILE_NAME                                       AUT MAXBYTES/1024/1024/1024
	---------------------- ----------------------------                             --- -----------------------
	USERS                  /data/app/oracle/oradata/PRIM/pdbprim/users01.dbf        NO  31.9999847
	
	
	
	
																	Pct
	TABLESPACE                  Total(Mb)    Used(Mb)    Free(Mb)     Free Largest(Mb)  FRAGMENTS
	------------------------ ------------ ----------- ----------- -------- ----------- ----------
	SYSTEM                          270.0       269.8          .2       .1          .2          1
	SYSAUX                          350.0       330.9        19.1      5.5        19.0          2
	UNDOTBS1                        100.0        97.0         3.0      3.0         3.0          1
	TEMP                             36.0        36.0          .0       .0          .0          0
	USERS                             5.0         1.1         3.9     78.0         3.9          1
							------------ ----------- -----------
	sum                             761.0       734.8        26.2


1) ‚úÖCreate user u2 and assign users tablespace to it;
	 SQL> alter user u2 default tablespace users;
2) ‚úÖCreate table inside sql of u2 and try to insert data into it.
	 SQL> ALTER USER u2 QUOTA UNLIMITED ON users;

	create table testtable2 (id number(10), name varchar(20));
	
		BEGIN
		FOR id IN 1..10000000
		loop
		INSERT INTO testtable2(id,name) VALUES(id,'dba');
		END loop;
		END;
		/
	
Now since "USERS tablespace" has only one datafile which is of 5 MB only and we are trying to insert large amount of data leading to fully usage of tablespace.

	TABLESPACE                  Total(Mb)    Used(Mb)    Free(Mb)     Free Largest(Mb)  FRAGMENTS
	------------------------ ------------ ----------- ----------- -------- ----------- ----------
	SYSTEM                          270.0       269.8          .2       .1          .2          1
	SYSAUX                          350.0       330.9        19.1      5.5        19.0          2
	UNDOTBS1                        100.0        96.8         3.2      3.2         1.0          6
	TEMP                             36.0        36.0          .0       .0          .0          0
	USERS                             5.0         4.1          .9     18.0          .9          1           ======================> full usage.
							------------ ----------- -----------
	sum                             761.0       737.6        23.4


3) ‚úÖCheck number of datafiles present in "USERS tablespace" and its size.

	col file_name for a50;
	select file_name,tablespace_name,bytes/1024/1024,status from dba_data_files where tablespace_name='USERS';
	
	FILE_NAME                                          TABLESPACE_NAME                BYTES/1024/1024 STATUS
	-------------------------------------------------- ------------------------------ --------------- ---------
	/data/app/oracle/oradata/PRIM/pdbprim/users01.dbf  USERS                                        5 AVAILABLE

Now we have two options first to add another data file to tablespace or second to increase the size of existing datafile.
we will try first option add new data file of size 10MB.

	üîπüîπSQL> alter tablespace USERS add datafile '/data/app/oracle/oradata/PRIM/pdbprim/users02.dbf' size 10M;
	
	Tablespace altered.
	
	col file_name for a50;
	select file_name,tablespace_name,bytes/1024/1024,status from dba_data_files where tablespace_name='USERS';
	
		FILE_NAME                                          TABLESPACE_NAME                BYTES/1024/1024 STATUS
	-------------------------------------------------- ------------------------------ --------------- ---------
	/data/app/oracle/oradata/PRIM/pdbprim/users01.dbf  USERS                                        5 AVAILABLE
	/data/app/oracle/oradata/PRIM/pdbprim/users02.dbf  USERS                                       10 AVAILABLE


Now if we check again we will get total space as 15MB and available will be more.
now we will try second option increase size of existing datafile.

	üîπüîπSQL> alter database datafile '/data/app/oracle/oradata/PRIM/pdbprim/users01.dbf' resize 10M;
	
	Database altered.
	
	üîπüîπSQL> col file_name for a50;
	select file_name,tablespace_name,bytes/1024/1024,status from dba_data_files where tablespace_name='USERS';
	üîπüîπSQL>
	FILE_NAME                                          TABLESPACE_NAME                BYTES/1024/1024 STATUS
	-------------------------------------------------- ------------------------------ --------------- ---------
	/data/app/oracle/oradata/PRIM/pdbprim/users01.dbf  USERS                                       10 AVAILABLE
	/data/app/oracle/oradata/PRIM/pdbprim/users02.dbf  USERS                                       10 AVAILABLE

Now if we check again we will get total space as 20MB and available will be more.

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++üìåTEMP TABLESPACE+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


If TEMP table space gets full and we want to add new data file then

first check how many temp files

	üîπüîπSQL> select file#, name, round(bytes/(1024*1024),2) "Temp file SIZE IN MB's" from v$tempfile;

Now create new file

	üîπüîπSQL> alter tablespace TEMP add tempfile '/data/app/oracle/oradata/PRIM/pdbprim/temp02.dbf' SIZE 10M ;

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++



===>üìåBIGFILE DATAFILE

A bigfile datafile is a datafile in a bigfile tablespace, which allows:

Only one datafile per tablespace

That one file to be very large (up to 32 TB, depending on block size)

	üîπüîπSQL> CREATE BIGFILE TABLESPACE BIGTBS1 DATAFILE '/data/app/oracle/oradata/PRIM/pdbprim/bigtbs01.dbf' SIZE 10M AUTOEXTEND ON NEXT 20M MAXSIZE 100G;
	
	CHECK BIGFILE & SMALLFILE TABLESPACE
	
	üîπüîπSQL> select TABLESPACE_NAME, BIGFILE from DBA_TABLESPACES;
	
	TABLESPACE_NAME                BIG
	------------------------------ ---
	SYSTEM                         NO
	SYSAUX                         NO
	UNDOTBS1                       NO
	TEMP                           NO
	USERS                          NO
	BIGTBS1                        YES
‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ


üìåDATAPUMP (EXPDP/IMPDP)

To take backup of logical entities like Schema, Table, Tablespace, DB, etc an utility is used known as EXPDP and if we want to restore the same backup then IMPDP utility is used.

There are two types of entities in a DB.

1) Logical - EXPDP/IMPDP is used for backup & restoration.
eg:- Schema, Table, Tablespace, DB, etc

2) Physical - RMAN is used for backup & restoration.
eg:- Spfile, Controlfile, Datafile, etc

There are two types of Backups.

1) Hot Backup (inconsistent backup):- When DB is Up & running.

2) Cold Backup (consistent backup):- When DB is down.


----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++üìåSCENARIO 1 - export/import from u1.t1 to u1.t1 only+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

++STEPS to take backup of any Table++
-------------------------------------

1) ‚úÖGo to pluggable DB i.e Connect directly to PDBPRIM during expdp.
[oracle@node1 ~]$ export ORACLE_PDB_SID=pdbprim -------->(valid for that session only)
[oracle@node1 ~]$ sqlplus / as sysdba

	üîπSQL> show con_name
	
	CON_NAME
	------------------------------
	PDBPRIM
	
2) ‚úÖCheck the table for which backup should be taken.


	üîπSQL> select count(*) from u1.t1;
	
	COUNT(*)
	----------
			1
			
3) ‚úÖCreate logical directory in sql first where backup will be taken.

	üîπSQL> create directory test_dir as '/data/backup';
	
	Directory created.

4) ‚úÖNow Create the physical directory in duplicate session where backup will be taken.

	[oracle@node1 ~]$ mkdir -p /data/backup
	
5) ‚úÖExit from sql session as we have to take backup from linux session.

6) ‚úÖType the expdp command 

	[oracle@node1 ~]$ expdp tables=u1.t1 directory=test_dir dumpfile=t1.dmp logfile=t1.log

	Export: Release 19.0.0.0.0 - Production on Wed May 21 12:22:40 2025
	Version 19.3.0.0.0
	
	Copyright (c) 1982, 2019, Oracle and/or its affiliates.  All rights reserved.
	
	Username: / as sysdba    =========> type this user to monitor the backup
	Password:                ==========> just hit enter dont hit password
	
	Connected to: Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production
	Starting "SYS"."SYS_EXPORT_TABLE_01":  /******** AS SYSDBA tables=u1.t1 directory=test_dir dumpfile=t1.dmp logfile=t1.log
	Processing object type TABLE_EXPORT/TABLE/TABLE_DATA
	Processing object type TABLE_EXPORT/TABLE/STATISTICS/TABLE_STATISTICS
	Processing object type TABLE_EXPORT/TABLE/STATISTICS/MARKER
	Processing object type TABLE_EXPORT/TABLE/TABLE
	Processing object type TABLE_EXPORT/TABLE/GRANT/OWNER_GRANT/OBJECT_GRANT
	. . exported "U1"."T1"                                   5.093 KB       1 rows
	Master table "SYS"."SYS_EXPORT_TABLE_01" successfully loaded/unloaded
	******************************************************************************
	Dump file set for SYS.SYS_EXPORT_TABLE_01 is:
	/data/backup/t1.dmp
	Job "SYS"."SYS_EXPORT_TABLE_01" successfully completed at Wed May 21 12:23:15 2025 elapsed 0 00:00:18

7) ‚úÖNow the dump file & log files are created in the backup directory that we created.
	[oracle@node1 backup]$ ll
	total 180
	-rw-r-----. 1 oracle oinstall 180224 May 21 12:23 t1.dmp
	-rw-r--r--. 1 oracle oinstall   1086 May 21 12:23 t1.log
	
	Now the dmp and log file consist of all the backup details but we cannot read the .dmp file so if the client asks us we can show the log file to them.



++üìåSTEPS to import(restore) any Table ++
-------------------------------------
 
1) ‚úÖNow first open sql and drop the table u1.t1.

	üîπSQL> show con_name;
	
	CON_NAME
	------------------------------
	PDBPRIM
	üîπSQL> drop table u1.t1;
	
	Table dropped.
	
2) ‚úÖExit sql and Type impdp command on linux same session.

	[oracle@node1 ~]$ impdp directory=test_dir dumpfile=t1.dmp logfile=t1_imp.log

3) ‚úÖImport willl start and get completed and we can find find the table again.

	Import: Release 19.0.0.0.0 - Production on Wed May 21 12:44:02 2025
	Version 19.3.0.0.0

	Copyright (c) 1982, 2019, Oracle and/or its affiliates.  All rights reserved.

	Username: / as sysdba
	Password:

	Connected to: Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production
	Master table "SYS"."SYS_IMPORT_FULL_01" successfully loaded/unloaded
	Starting "SYS"."SYS_IMPORT_FULL_01":  /******** AS SYSDBA directory=test_dir dumpfile=t1.dmp logfile=t1_imp.log
	Processing object type TABLE_EXPORT/TABLE/TABLE
	Processing object type TABLE_EXPORT/TABLE/TABLE_DATA
	. . imported "U1"."T1"                                   5.093 KB       1 rows
	Processing object type TABLE_EXPORT/TABLE/GRANT/OWNER_GRANT/OBJECT_GRANT
	Processing object type TABLE_EXPORT/TABLE/STATISTICS/TABLE_STATISTICS
	Processing object type TABLE_EXPORT/TABLE/STATISTICS/MARKER
	Job "SYS"."SYS_IMPORT_FULL_01" successfully completed at Wed May 21 12:45:51 2025 elapsed 0 00:00:38

	[oracle@node1 ~]$ sqlplus / as sysdba

	SQL*Plus: Release 19.0.0.0.0 - Production on Wed May 21 12:46:01 2025
	Version 19.3.0.0.0

	Copyright (c) 1982, 2019, Oracle.  All rights reserved.


	Connected to:
	Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production
	Version 19.3.0.0.0

	üîπSQL>
	üîπSQL>
	üîπSQL> select * from u1.t1;

			ID
	----------
			10

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++üìåSCENARIO 2 - export/import of schema +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

SCHEMA :-  a schema is essentially a collection of database objects that belong to a specific database user. These objects can include: tables, views, indexes, triggers , etc.
Schema name	Always the same as the user name who owns it.

1) ‚úÖType command.
[oracle@node1 ~]$ expdp schemas=u1 directory=test_dir dumpfile=u1.dmp logfile=u1.log

	Export: Release 19.0.0.0.0 - Production on Wed May 21 13:17:45 2025
	Version 19.3.0.0.0
	
	Copyright (c) 1982, 2019, Oracle and/or its affiliates.  All rights reserved.
	
	Username: / as sysdba
	Password:
	
	Connected to: Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production
	Starting "SYS"."SYS_EXPORT_SCHEMA_01":  /******** AS SYSDBA schemas=u1 directory=test_dir dumpfile=u1.dmp logfile=u1.log
	Processing object type SCHEMA_EXPORT/TABLE/TABLE_DATA
	Processing object type SCHEMA_EXPORT/TABLE/STATISTICS/TABLE_STATISTICS
	Processing object type SCHEMA_EXPORT/STATISTICS/MARKER
	Processing object type SCHEMA_EXPORT/USER
	Processing object type SCHEMA_EXPORT/SYSTEM_GRANT
	Processing object type SCHEMA_EXPORT/ROLE_GRANT
	Processing object type SCHEMA_EXPORT/DEFAULT_ROLE
	Processing object type SCHEMA_EXPORT/PRE_SCHEMA/PROCACT_SCHEMA
	Processing object type SCHEMA_EXPORT/TABLE/TABLE
	Processing object type SCHEMA_EXPORT/TABLE/GRANT/OWNER_GRANT/OBJECT_GRANT
	. . exported "U1"."T2"                                   5.593 KB       6 rows
	. . exported "U1"."T1"                                   5.593 KB       6 rows
	Master table "SYS"."SYS_EXPORT_SCHEMA_01" successfully loaded/unloaded
	******************************************************************************
	Dump file set for SYS.SYS_EXPORT_SCHEMA_01 is:
	/data/backup/u1.dmp
	Job "SYS"."SYS_EXPORT_SCHEMA_01" successfully completed at Wed May 21 13:18:55 2025 elapsed 0 00:00:59

2) ‚úÖTo check schema size

	run script => üîπSQL> @schema_size_check.sql

	OWNER           ???SIZE_IN_GB???
	--------------- ----------------
	AUDSYS                  .0013125
	CTXSYS                  .0026875
	DBSNMP                  .0001875
	DVSYS                   .0045625
	GSMADMIN_INTERN             .001
	AL
	
	LBACSYS                 .0003125
	MDSYS                    .122875
	OJVMSYS                  .000375
	ORDDATA                 .0013125
	ORDSYS                   .000375
	SYS                     .4069375
	SYSTEM                  .0013125
	U1                      .0001875
	U2                          .003
	U3                      .0000625
	U4                          .004
	WMSYS                   .0065625
	XDB                      .060875


3)‚úÖNow drop u1 schema, cascade means all objects inside it also.

	üîπSQL> drop user u1 cascade;
	
	User dropped.

4)‚úÖNow import schema back {Note:- Before importing any schema or table, please check the tablespace of that user/schema whether it has suffiecient space or not.}

	[oracle@node1 ~]$ impdp schemas=u1 directory=test_dir dumpfile=u1.dmp logfile=u1.log
	 
	 Import: Release 19.0.0.0.0 - Production on Wed May 21 13:30:17 2025
	 Version 19.3.0.0.0
	 
	 Copyright (c) 1982, 2019, Oracle and/or its affiliates.  All rights reserved.
	 
	 Username: / as sysdba
	 Password:
	 
	 Connected to: Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production
	 Master table "SYS"."SYS_IMPORT_SCHEMA_01" successfully loaded/unloaded
	 Starting "SYS"."SYS_IMPORT_SCHEMA_01":  /******** AS SYSDBA schemas=u1 directory=test_dir dumpfile=u1.dmp logfile=u1.log
	 Processing object type SCHEMA_EXPORT/USER
	 Processing object type SCHEMA_EXPORT/SYSTEM_GRANT
	 Processing object type SCHEMA_EXPORT/ROLE_GRANT
	 Processing object type SCHEMA_EXPORT/DEFAULT_ROLE
	 Processing object type SCHEMA_EXPORT/PRE_SCHEMA/PROCACT_SCHEMA
	 Processing object type SCHEMA_EXPORT/TABLE/TABLE
	 Processing object type SCHEMA_EXPORT/TABLE/TABLE_DATA
	 . . imported "U1"."T2"                                   5.593 KB       6 rows
	 . . imported "U1"."T1"                                   5.593 KB       6 rows
	 Processing object type SCHEMA_EXPORT/TABLE/GRANT/OWNER_GRANT/OBJECT_GRANT
	 Processing object type SCHEMA_EXPORT/TABLE/STATISTICS/TABLE_STATISTICS
	 Processing object type SCHEMA_EXPORT/STATISTICS/MARKER
	 Job "SYS"."SYS_IMPORT_SCHEMA_01" successfully completed at Wed May 21 13:31:14 2025 elapsed 0 00:00:46


=============>üìåEXPDP PARAMETERS

1) ‚úÖ{[Content parameter]}

	There are two types of expdp/impdp backup i.e when we dake backup of any table it has two things inside it.
	
	a)Meta-data backup(the table structure)  
	
	So the command will be [oracle@node1 ~]$ expdp tables=u1.t1 directory=test_dir dumpfile=t1.dmp logfile=t1.log content=metadata_only

	b)Data backup(the content)

	So the command will be [oracle@node1 ~]$ expdp tables=u1.t1 directory=test_dir dumpfile=t1.dmp logfile=t1.log content=data_only


2) ‚úÖ[{Query parameter]} (condition)

	expdp u1/password tables=t1 directory=test_dir dumpfile=t1_date_range.dmp logfile=t1_date_range.log \
	query="WHERE created_date BETWEEN TO_DATE('2024-01-01','YYYY-MM-DD') AND TO_DATE('2024-12-31','YYYY-MM-DD')"


3) ‚úÖ{[Flashback parameter]} (to go back in time and take specific backup)

	two types => 

	a) with repect to scn number.

		üîπSQL> select count(*) from u1.t1;
		
		COUNT(*)
		----------
				6
		
		üîπSQL> select current_scn from v$database;
		
		CURRENT_SCN
		-----------
			2562309
		
		üîπSQL> insert into u1.t1 select* from u1.t1;
		
		6 rows created.
		
		üîπSQL> select count(*) from u1.t1;
		
		COUNT(*)
		----------
				12
		üîπSQL> select current_scn from v$database;
		
		CURRENT_SCN
		-----------
			2562336
		
		now we want to take backup till 6 records only where scn number was 2562309.
		
	expdp tables=u1.t1 directory=test_dir dumpfile=u1_scn.dmp logfile=u1_scn.log flashback_scn=2562309
	

	b)with repect to timestamp.
		
	expdp u1/password tables=t1 directory=test_dir dumpfile=t1_old.dmp logfile=t1_old.log \ flashback_time="TO_TIMESTAMP('2025-05-20 10:00:00', 'YYYY-MM-DD HH24:MI:SS')"


4) ‚úÖTo Speed up the export by allowing Oracle to process multiple objects simultaneously we use {[parallel parameter]} execution with 3 threads/workers. This will create more than 
	one dump file of file size of 100MB(can be anything as we set) or less.
	
	[oracle@node1 ~]$ export ORACLE_PDB_SID=pdbprim
	[oracle@node1 ~]$ expdp schemas=u2 directory=test_dir dumpfile=u2_schema_%u.dmp logfile=u2.log filesize=100M parallel=3


5) ‚úÖThe {[REMAP parameter]} in impdp (Data Pump Import) are extremely powerful and are used to redirect or transform schema, table, or tablespace names during the import process.
	They let you import exported data into a different schema, tablespace, or table name than in the original export.
	
	  Parameter	                      Purpose
	a) REMAP_SCHEMA	    Change the schema the objects are imported into
		[oracle@test ~]$ impdp system/oracle@pdbprim directory=test_dir dumpfile=u2_schema_%u.dmp logfile=import.log remap_schema=u2:new_user
	
	
	
	b) REMAP_TABLESPACE	Change the tablespace for table/index data
		[oracle@test ~]$ impdp system/password directory=test_dir dumpfile=u2_schema_%u.dmp logfile=import.log remap_tablespace=old_ts:new_ts
	

	c) REMAP_TABLE	        Rename specific tables during import
		[oracle@test ~]$ impdp system/password directory=test_dir dumpfile=u2_schema_%u.dmp logfile=import.log remap_table=u2.old_table:new_table
	

6) ‚úÖThe {[TABLE_EXISTS_ACTION parameter]} controls what Oracle should do if a table already exists in the target schema.
	
		Value													Description
		
	a) SKIP (default)		Skip importing the table if it already exists. No changes made.
		impdp system/password directory=test_dir dumpfile=u2_schema.dmp logfile=imp.log schemas=u2

	b) APPEND				Adds rows from the dump file into the existing table. Existing data is preserved.
		impdp system/password directory=test_dir dumpfile=u2_schema.dmp logfile=imp.log schemas=u2 table_exists_action=append

	c) TRUNCATE			Deletes all rows in the existing table before importing new data. Table structure stays.
		impdp system/password directory=test_dir dumpfile=u2_schema.dmp logfile=imp.log schemas=u2 table_exists_action=truncate

	d) REPLACE				Drops the existing table and recreates it from the dump file. All data and structure are replaced.
		impdp system/password directory=test_dir dumpfile=u2_schema.dmp logfile=imp.log schemas=u2 table_exists_action=replace


üìå Summary Table:-
-------------------

	Parameter	    	 Used In					Purpose Summary
CONTENT					expdp only		Export data only, metadata only, or both
QUERY					expdp only		Export specific rows using WHERE
FLASHBACK_TIME/SCN		expdp only		Export consistent snapshot of data
PARALLEL					both		Multi-threaded performance
REMAP_*					impdp only		Redirect schema/tablespace/table during import
TABLE_EXISTS_ACTION		impdp only		How to handle existing tables on import



+++++üìåEXPDP MULTIPLE DIRECTORIES+++++

[root@node1 ~]# mkdir -p /u01/expdir1
[root@node1 ~]# mkdir -p /u02/expdir2

[root@node1 /]# chown -R oracle:oinstall /u01
[root@node1 /]# chown -R oracle:oinstall /u02


üîπSQL> CREATE OR REPLACE DIRECTORY dir1 AS '/u01/expdir1';

Directory created.

üîπSQL> CREATE OR REPLACE DIRECTORY dir2 AS '/u02/expdir2';


[oracle@node1 ~]$ expdp schemas=U2 \ dumpfile=dir1:hr_exp1.dmp,dir2:hr_exp2.dmp \ logfile=hr_exp.log \ directory=dir1

[root@node1 expdir1]# ll
total 620856
-rw-r-----. 1 oracle oinstall 635752448 May 24 19:29 hr_exp1.dmp
-rw-r--r--. 1 oracle oinstall      1603 May 24 19:29 hr_exp.log

[root@node1 expdir2]# ll
total 8
-rw-r-----. 1 oracle oinstall 4096 May 24 19:29 hr_exp2.dmp
-rw-r--r--. 1 oracle oinstall  342 May 24 19:27 hr_exp.log

EXAMPLE :- 

SQL> alter session set container = pdbprim;

Session altered.

SQL> create or replace directory dir1 as '/u02/back1';

Directory created.

SQL> create or replace directory dir2 as '/u02/back2';

Directory created.


SQL> GRANT READ, WRITE ON DIRECTORY dir1 TO PUBLIC;

Grant succeeded.

SQL> GRANT READ, WRITE ON DIRECTORY dir2 TO PUBLIC;

Grant succeeded.

[root@node1 ~]# mkdir -p /u02/back1
[root@node1 ~]# mkdir -p /u02/back2
[root@node1 ~]# chmod -R 755 /u02/back1
[root@node1 ~]# chmod -R 755 /u02/back2
[root@node1 ~]# chown oracle:oinstall /u02/back1
[root@node1 ~]# chown oracle:oinstall /u02/back2
[root@node1 ~]# ls -ld /u02/back1
drwxr-xr-x. 2 oracle oinstall 6 Jul 28 22:29 /u02/back1
[root@node1 ~]# ls -ld /u02/back2
drwxr-xr-x. 2 oracle oinstall 6 Jul 28 22:29 /u02/back2

[oracle@node1 data]$ sqlplus u1/u1@pdbprim
SQL> CREATE TABLE employees (
    emp_id     NUMBER,
    emp_name   VARCHAR2(50),
    salary     NUMBER
);
  2    3    4    5
Table created.

SQL> BEGIN
  FOR i IN 1..100 LOOP
    INSERT INTO employees (emp_id, emp_name, salary)
    VALUES (
      i,
      'Employee_' || i,
      30000 + (i * 100)
    );
  END LOOP;
  COMMIT;
END;
/
  2    3    4    5    6    7    8    9   10   11   12
PL/SQL procedure successfully completed.

SQL> select count(*) from employees;

  COUNT(*)
----------
       100

[oracle@node1 ~]$ expdp u1/u1@pdbprim tables=u1.employees directory=dir1 dumpfile=dir1:dump1.dmp,dir2:dump2.dmp logfile=u1_employees.log

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Export: Release 19.0.0.0.0 - Production on Mon Jul 28 23:03:34 2025
Version 19.3.0.0.0

Copyright (c) 1982, 2019, Oracle and/or its affiliates.  All rights reserved.

Connected to: Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production
Starting "U1"."SYS_EXPORT_TABLE_01":  u1/********@pdbprim tables=u1.employees dumpfile=dir1:dump1.dmp,dir2:dump2.dmp logfile=u1_employees.log directory=dir1
Processing object type TABLE_EXPORT/TABLE/TABLE_DATA
Processing object type TABLE_EXPORT/TABLE/STATISTICS/TABLE_STATISTICS
Processing object type TABLE_EXPORT/TABLE/STATISTICS/MARKER
Processing object type TABLE_EXPORT/TABLE/TABLE
. . exported "U1"."EMPLOYEES"                            8.132 KB     100 rows
Master table "U1"."SYS_EXPORT_TABLE_01" successfully loaded/unloaded
******************************************************************************
Dump file set for U1.SYS_EXPORT_TABLE_01 is:
  /u02/back1/dump1.dmp
Job "U1"."SYS_EXPORT_TABLE_01" successfully completed at Mon Jul 28 23:04:06 2025 elapsed 0 00:00:31
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

[oracle@node1 back2]$ ll
total 4
-rw-r-----. 1 oracle oinstall 4096 Jul 28 23:04 dump2.dmp
[oracle@node1 back2]$ cd ../back1
[oracle@node1 back1]$ ll
total 180
-rw-r-----. 1 oracle oinstall 180224 Jul 28 23:04 dump1.dmp
-rw-r--r--. 1 oracle oinstall   1046 Jul 28 23:04 u1_employees.log



[oracle@node1 back1]$ sqlplus u2/u2@pdbprim

SQL> desc employees;
 Name                                      Null?    Type
 ----------------------------------------- -------- ----------------------------
 EMP_ID                                             NUMBER
 EMP_NAME                                           VARCHAR2(50)
 SALARY                                             NUMBER

[oracle@node1 back1]$ impdp u2/u2@pdbprim tables=u1.employees directory=dir1 dumpfile=dir1:dump1.dmp,dir2:dump2.dmp logfile=imp_u2.log remap_schema=u1:u2 table_exists_action=append

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Import: Release 19.0.0.0.0 - Production on Mon Jul 28 23:37:04 2025
Version 19.3.0.0.0

Copyright (c) 1982, 2019, Oracle and/or its affiliates.  All rights reserved.

Connected to: Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production
Master table "U2"."SYS_IMPORT_TABLE_01" successfully loaded/unloaded
Starting "U2"."SYS_IMPORT_TABLE_01":  u2/********@pdbprim tables=u1.employees directory=dir1 dumpfile=dir1:dump1.dmp,dir2:dump2.dmp logfile=imp_u2.log remap_schema=u1:u2 table_exists_action=append
Processing object type TABLE_EXPORT/TABLE/TABLE
Table "U2"."EMPLOYEES" exists. Data will be appended to existing table but all dependent metadata will be skipped due to table_exists_action of append
Processing object type TABLE_EXPORT/TABLE/TABLE_DATA
. . imported "U2"."EMPLOYEES"                            8.132 KB     100 rows
Processing object type TABLE_EXPORT/TABLE/STATISTICS/TABLE_STATISTICS
Processing object type TABLE_EXPORT/TABLE/STATISTICS/MARKER
Job "U2"."SYS_IMPORT_TABLE_01" successfully completed at Mon Jul 28 23:37:09 2025 elapsed 0 00:00:04
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

[oracle@node1 back1]$ sqlplus u2/u2@pdbprim

SQL> select count(*) from employees;

  COUNT(*)
----------
       100


[root@node1 back1]# ll
total 184
-rw-r-----. 1 oracle oinstall 180224 Jul 28 23:04 dump1.dmp
-rw-r--r--. 1 oracle oinstall   1090 Jul 28 23:37 imp_u2.log
-rw-r--r--. 1 oracle oinstall   1046 Jul 28 23:04 u1_employees.log
[root@node1 back1]# pwd
/u02/back1
‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ


üìåRMAN (Recovery Manager)
--------------------------

To take backup of physical entities like Spfile, Controlfile, Datafile, Archive log file  an utility is used known as RMAN and if we want to restore the same backup then 
same RMAN utility is used.
RMAN backup metadata ‚Äî including the names, locations, and statuses of backup files ‚Äî is stored in the control file of the Oracle database (and optionally in a recovery catalog,
if used).

üß† Recovery Catalogue:-
	üî∏The Recovery Catalog is an optional but powerful RMAN feature.
	üî∏It stores backup metadata externally and permanently, making it ideal for large, critical, or multi-database environments.


Two Types:-

1) Full Database Backup:- Backs up the entire database or a specific datafile/block. Taken mostly in weekends.
						  Typically used for quick, one-time full copies or as a baseline without planning further incremental backups.
						  {‚ö†Ô∏èNote:- Use Full Backup for standalone or ad hoc backups not tied to incremental strategies.}
						  =>RMAN> BACKUP DATABASE PLUS ARCHIVELOG INCLUDE CURRENT CONTROLFILE;

2) Incremental Backup:-  

	a) Level 0:- Also backs up all blocks, just like a full backup.It acts as a baseline for future Level 1 incremental backups, which only back up changed blocks.
				{‚ö†Ô∏èNote:- Use Level 0 if you're planning incremental Level 1 backups.}
				 =>RMAN> BACKUP INCREMENTAL LEVEL 0 DATABASE;

	
	b) Level 1:- Backs up only the changed data blocks since the last backup.
				 =>RMAN> BACKUP INCREMENTAL LEVEL 1 DATABASE;

	
3) Archive log Backup :- Which we can take every 2-3 hours.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++üìåBACKUP of spfile+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
	[oracle@node1 ~]$ sqlplus / as sysdba
	üîπüîπSQL> startup
	üîπüîπSQL> alter session set container=pdbprim;
	
	  Session altered.
	
	üîπüîπSQL> exit
	
	[oracle@node1 ~]$ rman target /
	üîπRMAN> backup spfile;
	
	Starting backup at 27-MAY-25
	using target database control file instead of recovery catalog
	allocated channel: ORA_DISK_1
	channel ORA_DISK_1: SID=439 device type=DISK   =============================>channel means no of threads/processes
	channel ORA_DISK_1: starting full datafile backup set
	channel ORA_DISK_1: specifying datafile(s) in backup set
	including current SPFILE in backup set
	channel ORA_DISK_1: starting piece 1 at 27-MAY-25
	channel ORA_DISK_1: finished piece 1 at 27-MAY-25
	piece handle=/data/app/oracle/product/19C/dbhome_3/dbs/013qhh3e_1_1 tag=TAG20250527T201749 comment=NONE  =======>piece handle is the filename (or unique identifier) of a 																									 
	channel ORA_DISK_1: backup set complete, elapsed time: 00:00:01													 backup piece.
	Finished backup at 27-MAY-25
	
	Starting Control File and SPFILE Autobackup at 27-MAY-25
	piece handle=/data/app/oracle/product/19C/dbhome_3/dbs/c-196814088-20250527-00 comment=NONE
	Finished Control File and SPFILE Autobackup at 27-MAY-25


‚úÖNow in "piece handle" the path for backup is "/data/app/oracle/product/19C/dbhome_3/dbs/013qhh3e_1_1 tag=TAG20250527T201749" which is dbs location. But we can change the backup
  location by below command. "013qhh3e_1_1" is the dumpfile name which is auto renamed with help of "%u"(generates random alphanumeric) so the problem of naming resolves.

‚úÖNow it also takes bydefault backup of spfile and control file "Starting Control File and SPFILE Autobackup at 27-MAY-25"

‚úÖTo change backup file destination
	
	üîπRMAN> backup spfile format '/data/backup/spfile_%u';      ==============>"%u"(generates random alphanumeric)
	
	Starting backup at 27-MAY-25
	using target database control file instead of recovery catalog
	allocated channel: ORA_DISK_1
	channel ORA_DISK_1: SID=29 device type=DISK
	channel ORA_DISK_1: starting full datafile backup set
	channel ORA_DISK_1: specifying datafile(s) in backup set
	including current SPFILE in backup set
	channel ORA_DISK_1: starting piece 1 at 27-MAY-25
	channel ORA_DISK_1: finished piece 1 at 27-MAY-25
	piece handle=/data/backup/spfile_033qhn28 tag=TAG20250527T215936 comment=NONE ============> Location changed.
	channel ORA_DISK_1: backup set complete, elapsed time: 00:00:01
	Finished backup at 27-MAY-25

	üîπRMAN> list backup;
	
	using target database control file instead of recovery catalog

	List of Backup Sets
	===================
	
	
	BS Key  Type LV Size       Device Type Elapsed Time Completion Time
	------- ---- -- ---------- ----------- ------------ ---------------
	1       Full    96.00K     DISK        00:00:00     27-MAY-25
			BP Key: 1   Status: AVAILABLE  Compressed: NO  Tag: TAG20250527T201749
			Piece Name: /data/app/oracle/product/19C/dbhome_3/dbs/013qhh3e_1_1
	SPFILE Included: Modification time: 27-MAY-25
	SPFILE db_unique_name: PRIM
	
	BS Key  Type LV Size       Device Type Elapsed Time Completion Time
	------- ---- -- ---------- ----------- ------------ ---------------
	2       Full    17.95M     DISK        00:00:00     27-MAY-25
			BP Key: 2   Status: AVAILABLE  Compressed: NO  Tag: TAG20250527T201751
			Piece Name: /data/app/oracle/product/19C/dbhome_3/dbs/c-196814088-20250527-00
	SPFILE Included: Modification time: 27-MAY-25
	SPFILE db_unique_name: PRIM
	Control File Included: Ckp SCN: 3055277      Ckp time: 27-MAY-25

‚úÖCommand to show tablespace and datafiles file size.

	üîπRMAN> report schema;
	
	Report of database schema for database with db_unique_name PRIM
	
	List of Permanent Datafiles
	===========================
	File Size(MB) Tablespace           RB segs Datafile Name
	---- -------- -------------------- ------- ------------------------
	1    910      SYSTEM               YES     /data/app/oracle/oradata/PRIM/system01.dbf
	3    650      SYSAUX               NO      /data/app/oracle/oradata/PRIM/sysaux01.dbf
	4    345      UNDOTBS1             YES     /data/app/oracle/oradata/PRIM/undotbs01.dbf
	5    270      PDB$SEED:SYSTEM      NO      /data/app/oracle/oradata/PRIM/pdbseed/system01.dbf
	6    330      PDB$SEED:SYSAUX      NO      /data/app/oracle/oradata/PRIM/pdbseed/sysaux01.dbf
	7    5        USERS                NO      /data/app/oracle/oradata/PRIM/users01.dbf
	8    100      PDB$SEED:UNDOTBS1    NO      /data/app/oracle/oradata/PRIM/pdbseed/undotbs01.dbf
	9    370      PDBPRIM:SYSTEM       NO      /data/app/oracle/oradata/PRIM/pdbprim/system01.dbf
	10   370      PDBPRIM:SYSAUX       NO      /data/app/oracle/oradata/PRIM/pdbprim/sysaux01.dbf
	11   1075     PDBPRIM:UNDOTBS1     NO      /data/app/oracle/oradata/PRIM/pdbprim/undotbs01.dbf
	12   10       PDBPRIM:USERS        NO      /data/app/oracle/oradata/PRIM/pdbprim/users01.dbf
	13   270      PDBPRIM2:SYSTEM      NO      /data/app/oracle/oradata/PRIM/PDBPRIM2/system01.dbf
	14   340      PDBPRIM2:SYSAUX      NO      /data/app/oracle/oradata/PRIM/PDBPRIM2/sysaux01.dbf
	15   100      PDBPRIM2:UNDOTBS1    NO      /data/app/oracle/oradata/PRIM/PDBPRIM2/undotbs01.dbf
	16   5        PDBPRIM2:USERS       NO      /data/app/oracle/oradata/PRIM/PDBPRIM2/users01.dbf
	17   5120     PDBPRIM:USERS        NO      /data/app/oracle/oradata/PRIM/pdbprim/users02.dbf
	18   10       PDBPRIM:BIGTBS1      NO      /data/app/oracle/oradata/PRIM/pdbprim/bigtbs01.dbf
	19   10       PDBPRIM:NEW_TBS      NO      /data/app/oracle/oradata/PRIM/pdbprim/newtbsfile01.dbf
	20   10       PDBPRIM:NEW_TBS      NO      /data/app/oracle/oradata/PRIM/pdbprim/newtbsfile02
	
	List of Temporary Files
	=======================
	File Size(MB) Tablespace           Maxsize(MB) Tempfile Name
	---- -------- -------------------- ----------- --------------------
	1    32       TEMP                 32767       /data/app/oracle/oradata/PRIM/temp01.dbf
	2    36       PDB$SEED:TEMP        32767       /data/app/oracle/oradata/PRIM/pdbseed/temp012025-04-26_20-53-08-652-PM.dbf
	3    111      PDBPRIM:TEMP         32767       /data/app/oracle/oradata/PRIM/pdbprim/temp01.dbf
	4    36       PDBPRIM2:TEMP        32767       /data/app/oracle/oradata/PRIM/PDBPRIM2/temp012025-04-26_20-53-08-652-PM.dbf
	5    10       TEMP                 10          /data/app/oracle/oradata/PRIM/pdbprim/temp02.dbf



‚úÖWhile taking backup of Spfile, Controlfile, Datafile, Archive log file etc the DB should be in Archive log mode.
	üî∏How to put DB in Archive log mode?
=>	1) First we need to set archive log destination (path) which has sufficient space.
	2) This is an offline activity so we need to shutdown DB down inorder to put DB in Archive log mode.
	3) Put DB in mount state to perform some activities.
	4) Put DB in Archivelog mode.
	5) DB start.


‚úÖTo check archive log status.

	üîπüîπSQL> archive log list;
	Database log mode              No Archive Mode
	Automatic archival             Disabled
	Archive destination            /data/app/oracle/product/19C/dbhome_3/dbs/arch
	Oldest online log sequence     24
	Current log sequence           26

üî∏Now the location to take backup of sqlplus is "/data/app/oracle/product/19C/dbhome_3/dbs/arch" bydefault. So to change it we need to create it first.

	üîπüîπSQL> !mkdir -p /data/archive           =====> {‚ö†Ô∏èNote:- using "!" we can type linux commands from sql itself}
	
	üîπüîπSQL> alter system set log_archive_dest_1='location=/data/archive' scope=both;
	
	System altered.
	
	Now check again
	
	üîπüîπSQL> alter system set log_archive_dest_1='location=/data/archive' scope=both;
	
	System altered.
	
	üîπüîπSQL> archive log list;
	Database log mode              No Archive Mode
	Automatic archival             Disabled
	Archive destination            /data/archive   =====>path is changed.
	Oldest online log sequence     24
	Current log sequence           26

üî∏Now shutdown DB and again start DB in mount state.

	üîπüîπSQL> shutdown immediate
	üîπüîπSQL> startup mount
	
üî∏Now put Db in archivelog mode and start DB.
	üîπüîπSQL> alter database archivelog;
	
	Database altered.
	
	üîπüîπSQL> alter database open;
	
	Database altered.
	
	üîπüîπSQL> archive log list;
	Database log mode              Archive Mode       ==========>in archive log mode now.
	Automatic archival             Enabled
	Archive destination            /data/archive
	Oldest online log sequence     24
	Next log sequence to archive   26
	Current log sequence           26


‚úÖTo take backup of control, spfile, archived redo log file together using a script.

	üî∏Level 0 Backup - Backup of spfile,control file ,database and archivelog


  üîπRUN
	{
	  ALLOCATE CHANNEL ch11 TYPE DISK MAXPIECESIZE 10G;
	  ALLOCATE CHANNEL ch12 TYPE DISK MAXPIECESIZE 10G;
	  ALLOCATE CHANNEL ch13 TYPE DISK MAXPIECESIZE 10G;
	  BACKUP
	  FORMAT '/data/backup/RMAN_BACKUP/%d_D_%T_%u_s%s_p%p'
	  INCREMENTAL LEVEL 0 DATABASE
	  CURRENT CONTROLFILE
	  FORMAT '/data/backup/RMAN_BACKUP/%d_C_%T_%u'
	  SPFILE
	  FORMAT '/data/backup/RMAN_BACKUP/%d_S_%T_%u'
	  PLUS ARCHIVELOG
	  FORMAT '/data/backup/RMAN_BACKUP/%d_A_%T_%u_s%s_p%p';
	  RELEASE CHANNEL ch11;
	  RELEASE CHANNEL ch12;
	  RELEASE CHANNEL ch13;
	}



‚úÖ Differential Incremental Backup
	üîπWhat it does: Backs up all blocks that have changed since the last incremental backup of the same or lower level.
	=> RMAN> BACKUP INCREMENTAL LEVEL 1 DIFFERENTIAL DATABASE;
	
	Example:
	
		Level 0 on Sunday (full backup)
		
		Level 1 differential on Monday: backs up changes since Sunday
		
		Level 1 differential on Tuesday: backs up changes since Monday
		
		Backup size: Smaller than cumulative (if done frequently)
		
		Restore time: Slower ‚Äì multiple backups may need to be applied during recovery.

‚úÖ Cumulative Incremental Backup
	üîπWhat it does: Backs up all blocks that have changed since the last Level 0 backup, regardless of any other incremental backups taken since.
	=> RMAN> BACKUP INCREMENTAL LEVEL 1 CUMULATIVE DATABASE;
	
	Example:
	
		Level 0 on Sunday (full backup)
		
		Level 1 cumulative on Monday: backs up changes since Sunday
		
		Level 1 cumulative on Tuesday: still backs up all changes since Sunday
		
		Backup size: Grows larger over time until the next Level 0
		
		Restore time: Faster ‚Äì only the Level 0 and the latest Level 1 cumulative are needed
		
‚úÖ Expired Backup

	When RMAN tries to access a backup file (e.g., during a restore or CROSSCHECK operation) and the file is not found at the recorded location (because it was deleted 
	manually or the storage is unavailable), RMAN marks that backup as EXPIRED.
	
	üîπRMAN> crosscheck backup;

	allocated channel: ORA_DISK_1
	channel ORA_DISK_1: SID=225 device type=DISK
	crosschecked backup piece: found to be 'AVAILABLE'
	backup piece handle=/data/backup/spfile_033qhn28 RECID=3 STAMP=1202248776
	crosschecked backup piece: found to be 'AVAILABLE'
	backup piece handle=/data/app/oracle/product/19C/dbhome_3/dbs/c-196814088-20250527-01 RECID=4 STAMP=1202248777
	crosschecked backup piece: found to be 'EXPIRED'
	backup piece handle=/data/backup/RMAN_BACKUP/PRIM_A_20250530_053qofc1_s5_p1 RECID=5 STAMP=1202470273
	crosschecked backup piece: found to be 'EXPIRED'
	backup piece handle=/data/backup/RMAN_BACKUP/PRIM_D_20250530_063qofc3_s6_p1 RECID=6 STAMP=1202470275
	
	üî∏Now, since the control file has expired backup entry because we have deleted the backup manually. So to remove the expired backup.
	
	üîπRMAN> delete expired backup;
	
	üîπRMAN> crosscheck backup;

	allocated channel: ORA_DISK_1
	channel ORA_DISK_1: SID=225 device type=DISK
	crosschecked backup piece: found to be 'AVAILABLE'
	backup piece handle=/data/backup/spfile_033qhn28 RECID=3 STAMP=1202248776
	crosschecked backup piece: found to be 'AVAILABLE'
	backup piece handle=/data/app/oracle/product/19C/dbhome_3/dbs/c-196814088-20250527-01 RECID=4 STAMP=1202248777

	üî∏Now it will show only the available backup since we have deleted the expired backup and the control file is updated.
	
	üîπRecommended way to delete backup is
	=> 	RMAN> delete backup;


‚úÖ Obsolete Backup

	An obsolete backup is a backup that is no longer needed for recovery, based on your retention policy. RMAN marks it as obsolete, so you can safely delete it to free up space.
	
	üî∏ RMAN retention policy (RECOVERY WINDOW or REDUNDANCY)
	
	1. Recovery Window (e.g., 7 days):
		üîπRMAN> CONFIGURE RETENTION POLICY TO RECOVERY WINDOW OF 7 DAYS;
	RMAN keeps all backups needed to recover to any point in the last 7 days. Anything older becomes obsolete.
	
	2. Redundancy (e.g., 1 backup copies):
		üîπRMAN> CONFIGURE RETENTION POLICY TO REDUNDANCY 1;
	RMAN keeps only the most recent backup. Older ones are obsolete.
	
	üîπ How to See Obsolete Backups
		RMAN> REPORT OBSOLETE;
		
	üîπ How to Delete Obsolete Backups
		RMAN> DELETE OBSOLETE;
		
	üîπ To check policies.
		RMAN> show all;
		
-------------------------------------------------------------------------SOFTWARE LEVEL BACKUP------------------------------------------------------------------------------------

üíæ How is tar used in software-level backups?

	A software-level backup means you're backing up the files and folders of an application, such as:
	
	Oracle installation folders
	
	Configuration files (like init.ora, .bash_profile, listener.ora)
	
	Log files
	
	Scripts
	
	Static data files (not live DB files)

üîÅ You do not backup the live database files (like .dbf) this way ‚Äî that needs RMAN.




BACKUP ARCHIVELOG ALL FORMAT '/backup/archivelogs/arch_%d_%T_%s.log';
BACKUP CURRENT CONTROLFILE FORMAT '/backup/controlfile/ctrl_%d_%T_%s.bkp';
BACKUP SPFILE FORMAT '/backup/spfile/spfile_%d_%T_%s.bkp';
BACKUP TABLESPACE users;
BACKUP DATABASE;
BACKUP DATAFILE '/u01/oradata/ORCL/users01.dbf', '/u01/oradata/ORCL/system01.dbf';
BACKUP DATABASE PLUS ARCHIVELOG INCLUDE CURRENT CONTROLFILE FORMAT '/backup/full/full_%d_%T_%s.bkp';
‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ



üìåRESTORATION (RMAN)
---------------------

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
‚úÖTo take RMAN BACKUP Of DB, DROP DB and then RESTORE DB using RMAN.
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

=========================================================================================================
1) Delete old backup.
=========================================================================================================
2) Take new level 0 incremental cumulative DB backup using below script in path /rman/backup.
	  üîπRUN
			{
			ALLOCATE CHANNEL ch11 TYPE DISK MAXPIECESIZE 10G;
			ALLOCATE CHANNEL ch12 TYPE DISK MAXPIECESIZE 10G;
			ALLOCATE CHANNEL ch13 TYPE DISK MAXPIECESIZE 10G;
			BACKUP
			FORMAT '/data/rman/%d_D_%T_%u_s%s_p%p'
			INCREMENTAL LEVEL 0 CUMULATIVE DATABASE
			CURRENT CONTROLFILE
			FORMAT '/data/rman/%d_C_%T_%u'
			SPFILE
			FORMAT '/data/rman/%d_S_%T_%u'
			PLUS ARCHIVELOG
			FORMAT '/data/rman/%d_A_%T_%u_s%s_p%p';
			RELEASE CHANNEL ch11;
			RELEASE CHANNEL ch12;
			RELEASE CHANNEL ch13;
			}
=========================================================================================================
3) Now shutdown DB and start in restrict mode(no user can log in during that period).
	üîπüîπSQL> startup mount restrict;
=========================================================================================================
4) Now Drop DB
	üîπüîπSQL> drop database;

	  Database dropped.
=========================================================================================================
5) Now since we have drop the DB we wont have any spfile, control file or archived redo log file. But in order to retrieve all datafiles we need control file, and to retrieve
   control file we need spfile. 

	[oracle@node1 ~]$ cd $ORACLE_HOME
	[oracle@node1 dbhome_3]$ cd dbs
	[oracle@node1 dbs]$ ls -lrt
	total 18420
	-rw-r--r--. 1 oracle oinstall     3079 May 14  2015 init.ora
	-rw-r-----. 1 oracle oinstall       24 Apr 26 20:47 lkPRIM
	-rw-r-----. 1 oracle oinstall     2048 Apr 26 20:49 orapwprim
	-rw-r--r--. 1 oracle oinstall     1042 Apr 30 23:57 initprim.ora
	-rw-r-----. 1 oracle oinstall 18841600 Jun  6 13:31 c-196814088-20250606-01
	-rw-rw----. 1 oracle oinstall     1544 Jun  6 13:50 hc_prim.dat
	[oracle@node1 dbs]$

	üî∏So we need to start the db in nomount state for which we require spfile but since we know that if the spfile is missing we can use the pfile to start the database in 
	  nomount state, but if pfile is also missing we can create a dummy pfile.txt and put this one parameter "*.db_name='prim'" to start the database in nomount state.
=========================================================================================================
6) Now in our case the pfile(initprim.ora) is present so we can restore the spfile in no mount state

	üîπüîπSQL> startup nomount pfile='initprim.ora';
=========================================================================================================
7) Now exit sql and open rman and restore spfile from path /data/rman

	[oracle@node1 rman]$ ll
	total 4003580
	-rw-r-----. 1 oracle oinstall  82843136 Jun  6 13:30 PRIM_A_20250606_1b3rb502_s43_p1
	-rw-r-----. 1 oracle oinstall   2086400 Jun  6 13:30 PRIM_A_20250606_1c3rb502_s44_p1
	-rw-r-----. 1 oracle oinstall     10240 Jun  6 13:30 PRIM_A_20250606_1d3rb502_s45_p1
	-rw-r-----. 1 oracle oinstall      8192 Jun  6 13:31 PRIM_A_20250606_1q3rb50v_s58_p1
	-rw-r-----. 1 oracle oinstall  18808832 Jun  6 13:31 PRIM_C_20250606_1o3rb50t        ==================> controlfile
	-rw-r-----. 1 oracle oinstall 937549824 Jun  6 13:30 PRIM_D_20250606_1e3rb503_s46_p1
	-rw-r-----. 1 oracle oinstall 833789952 Jun  6 13:30 PRIM_D_20250606_1f3rb503_s47_p1
	-rw-r-----. 1 oracle oinstall  13107200 Jun  6 13:30 PRIM_D_20250606_1g3rb503_s48_p1
	-rw-r-----. 1 oracle oinstall 634298368 Jun  6 13:31 PRIM_D_20250606_1h3rb50j_s49_p1
	-rw-r-----. 1 oracle oinstall 499171328 Jun  6 13:31 PRIM_D_20250606_1i3rb50j_s50_p1
	-rw-r-----. 1 oracle oinstall 266715136 Jun  6 13:31 PRIM_D_20250606_1j3rb50j_s51_p1
	-rw-r-----. 1 oracle oinstall 262995968 Jun  6 13:31 PRIM_D_20250606_1k3rb50q_s52_p1
	-rw-r-----. 1 oracle oinstall 229457920 Jun  6 13:31 PRIM_D_20250606_1l3rb50r_s53_p1
	-rw-r-----. 1 oracle oinstall 228622336 Jun  6 13:31 PRIM_D_20250606_1m3rb50r_s54_p1
	-rw-r-----. 1 oracle oinstall  90079232 Jun  6 13:31 PRIM_D_20250606_1n3rb50t_s55_p1
	-rw-r-----. 1 oracle oinstall    114688 Jun  6 13:31 PRIM_S_20250606_1p3rb50u         =================> spfile
	
	üîπRMAN> restore spfile from '/data/rman/PRIM_S_20250606_1p3rb50u';
	
	[oracle@node1 dbs]$ ll
	total 18424
	-rw-r-----. 1 oracle oinstall 18841600 Jun  6 13:31 c-196814088-20250606-01
	-rw-rw----. 1 oracle oinstall     1544 Jun  6 14:03 hc_prim.dat
	-rw-r--r--. 1 oracle oinstall     3079 May 14  2015 init.ora
	-rw-r--r--. 1 oracle oinstall     1042 Apr 30 23:57 initprim.ora
	-rw-r-----. 1 oracle oinstall       24 Apr 26 20:47 lkPRIM
	-rw-r-----. 1 oracle oinstall     2048 Apr 26 20:49 orapwprim
	-rw-r-----. 1 oracle oinstall     3584 Jun  6 14:07 spfileprim.ora =====================> spfile is backedup
	[oracle@node1 dbs]$
=========================================================================================================
8) Now since the DB is started using the pfile so we need to shutdown it and start in nomount state using spfile.
	üîπüîπSQL> startup nomount;
=========================================================================================================
9) Now exit sql and open rman and restore controlfile from path /data/rman
	üîπRMAN> restore controlfile from '/data/rman/PRIM_C_20250606_1o3rb50t';
	
	[oracle@node1 ~]$ cd /data/app/oracle/oradata/PRIM
	[oracle@node1 PRIM]$ ll
	total 54864
	-rw-r-----. 1 oracle oinstall 18726912 Jun  6 14:12 control01.ctl ==
	-rw-r-----. 1 oracle oinstall 18726912 Jun  6 14:12 control02.ctl =============> controlfile is backedup.
	-rw-r-----. 1 oracle oinstall 18726912 Jun  6 14:12 control03.ctl ==
	drwxr-x---. 2 oracle oinstall        6 Jun  6 13:50 pdbprim
	drwxr-x---. 2 oracle oinstall        6 Jun  6 13:50 PDBPRIM2
	drwxr-x---. 2 oracle oinstall        6 Jun  6 13:50 pdbseed
=========================================================================================================
10) Now since we have the controlfiles we can start the DB in mount state using controlfile.
	üîπüîπSQL> alter database mount;

	Database altered.
=========================================================================================================
11) Now before restoring datafile we need to catalog the path where data files are backedup so the controlfile will know about it.
	üîπRMAN> catalog start with '/data/rman/';
=========================================================================================================
12) To Restore datafiles
	üîπRMAN> restore database;
=========================================================================================================
13) To Restore archive redo log files.
	üîπRMAN> recover database;
	üîπRMAN> alter database open resetlogs; ========> to reset log sequence from 1.

	Statement processed

	üîπRMAN> exit
=========================================================================================================



++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
‚úÖTo take LEVEL 1 BACKUP Of DB and do Point in time RECOVERY for data update after LEVEL 1 using archive redo logs and DROP DB using dbca and then RESTORE DB using RMAN.
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


=========================================================================================================
1) Insert new records in u1.t1 to take level 1 backup.
	üîπüîπSQL> select count(*) from u1.t1;
	
	COUNT(*)
	----------
			24
			
			Now take LEVEL 0 backup
	
	üîπüîπSQL> insert into u1.t1 select * from u1.t1;
	
	24 rows created.
	
	üîπüîπSQL> select count(*) from u1.t1;
	
	COUNT(*)
	----------
			48
	
	üîπüîπSQL> commit;
	
	Commit complete.
=========================================================================================================
2) Now run level 1 backup script 
	üîπRUN
		{
		ALLOCATE CHANNEL ch11 TYPE DISK MAXPIECESIZE 10G;
		ALLOCATE CHANNEL ch12 TYPE DISK MAXPIECESIZE 10G;
		ALLOCATE CHANNEL ch13 TYPE DISK MAXPIECESIZE 10G;
		BACKUP
		FORMAT '/data/rman/%d_LEVEL1_D_%T_%u_s%s_p%p'
		INCREMENTAL LEVEL 1 DATABASE
		CURRENT CONTROLFILE
		FORMAT '/data/rman/%d_LEVEL1_C_%T_%u'
		SPFILE
		FORMAT '/data/rman/%d_LEVEL1_S_%T_%u'
		PLUS ARCHIVELOG
		FORMAT '/data/rman/%d_LEVEL1_A_%T_%u_s%s_p%p';
		RELEASE CHANNEL ch11;
		RELEASE CHANNEL ch12;
		RELEASE CHANNEL ch13;
		}
		
	üî∏Now the LEVEL 1 backup is present in /data/rman
	
	[oracle@node1 rman]$ ll
	total 5417556
	-rw-r-----. 1 oracle oinstall   82843136 Jun  6 23:13 PRIM_LEVEL0_A_20250606_2t3rc74q_s93_p1
	-rw-r-----. 1 oracle oinstall   44328448 Jun  6 23:13 PRIM_LEVEL0_A_20250606_2u3rc74q_s94_p1
	-rw-r-----. 1 oracle oinstall   12155904 Jun  6 23:13 PRIM_LEVEL0_A_20250606_2v3rc74q_s95_p1
	-rw-r-----. 1 oracle oinstall    2099712 Jun  6 23:13 PRIM_LEVEL0_A_20250606_303rc74r_s96_p1
	-rw-r-----. 1 oracle oinstall      20480 Jun  6 23:13 PRIM_LEVEL0_A_20250606_313rc74r_s97_p1
	-rw-r-----. 1 oracle oinstall      19456 Jun  6 23:13 PRIM_LEVEL0_A_20250606_3e3rc75k_s110_p1
	-rw-r-----. 1 oracle oinstall   18808832 Jun  6 23:13 PRIM_LEVEL0_C_20250606_3c3rc75h
	-rw-r-----. 1 oracle oinstall  937549824 Jun  6 23:13 PRIM_LEVEL0_D_20250606_323rc74t_s98_p1
	-rw-r-----. 1 oracle oinstall  865083392 Jun  6 23:13 PRIM_LEVEL0_D_20250606_333rc74t_s99_p1
	-rw-r-----. 1 oracle oinstall 1116512256 Jun  6 23:13 PRIM_LEVEL0_D_20250606_343rc74t_s100_p1
	-rw-r-----. 1 oracle oinstall  635199488 Jun  6 23:13 PRIM_LEVEL0_D_20250606_353rc754_s101_p1
	-rw-r-----. 1 oracle oinstall  501825536 Jun  6 23:13 PRIM_LEVEL0_D_20250606_363rc754_s102_p1
	-rw-r-----. 1 oracle oinstall  356556800 Jun  6 23:13 PRIM_LEVEL0_D_20250606_373rc755_s103_p1
	-rw-r-----. 1 oracle oinstall  262995968 Jun  6 23:13 PRIM_LEVEL0_D_20250606_383rc756_s104_p1
	-rw-r-----. 1 oracle oinstall  229875712 Jun  6 23:13 PRIM_LEVEL0_D_20250606_393rc75e_s105_p1
	-rw-r-----. 1 oracle oinstall  228622336 Jun  6 23:13 PRIM_LEVEL0_D_20250606_3a3rc75e_s106_p1
	-rw-r-----. 1 oracle oinstall   90079232 Jun  6 23:13 PRIM_LEVEL0_D_20250606_3b3rc75e_s107_p1
	-rw-r-----. 1 oracle oinstall     114688 Jun  6 23:13 PRIM_LEVEL0_S_20250606_3d3rc75h
	-rw-r-----. 1 oracle oinstall   82843136 Jun  6 23:15 PRIM_LEVEL1_A_20250606_3g3rc795_s112_p1
	-rw-r-----. 1 oracle oinstall   45173248 Jun  6 23:15 PRIM_LEVEL1_A_20250606_3h3rc795_s113_p1
	-rw-r-----. 1 oracle oinstall   12173824 Jun  6 23:15 PRIM_LEVEL1_A_20250606_3i3rc795_s114_p1
	-rw-r-----. 1 oracle oinstall    2099712 Jun  6 23:15 PRIM_LEVEL1_A_20250606_3j3rc796_s115_p1
	-rw-r-----. 1 oracle oinstall       8192 Jun  6 23:15 PRIM_LEVEL1_A_20250606_403rc79f_s128_p1
	-rw-r-----. 1 oracle oinstall   18808832 Jun  6 23:15 PRIM_LEVEL1_C_20250606_3u3rc79d
	-rw-r-----. 1 oracle oinstall      73728 Jun  6 23:15 PRIM_LEVEL1_D_20250606_3k3rc798_s116_p1
	-rw-r-----. 1 oracle oinstall     942080 Jun  6 23:15 PRIM_LEVEL1_D_20250606_3l3rc798_s117_p1
	-rw-r-----. 1 oracle oinstall     270336 Jun  6 23:15 PRIM_LEVEL1_D_20250606_3m3rc798_s118_p1
	-rw-r-----. 1 oracle oinstall     262144 Jun  6 23:15 PRIM_LEVEL1_D_20250606_3n3rc79b_s119_p1
	-rw-r-----. 1 oracle oinstall      98304 Jun  6 23:15 PRIM_LEVEL1_D_20250606_3o3rc79b_s120_p1
	-rw-r-----. 1 oracle oinstall     114688 Jun  6 23:15 PRIM_LEVEL1_S_20250606_3v3rc79d
=========================================================================================================
3) Now inserting more 48 records in u1.t1 and switching logfile by CDB to move the redo logs in archived redo logs.

	üîπüîπSQL> select count(*) from u1.t1;
	
	COUNT(*)
	----------
			96
	
	üîπüîπSQL> commit;
	
	Commit complete.
			
	üîπüîπSQL> alter session set container=CDB$ROOT;
	
	Session altered.
	
	üîπüîπSQL> alter system switch logfile;
	
	System altered.
	
	Now shutdown DB and start in restrict mode(no user can log in during that period).
	üîπüîπSQL> startup mount restrict;
=========================================================================================================
4) Now dropping the DB using dbca

	{‚ö†Ô∏èNote :- when we drop db using dbca all the physical files are dropped along with their path(folder) so we need to copy the paths first before dropping and 
			   create the same before restoration.}
	mkdir -p /data/app/oracle/oradata/PRIM                   /control01.ctl
	mkdir -p /data/app/oracle/oradata/PRIM/PDBPRIM2          /system01.dbf
	mkdir -p /data/app/oracle/oradata/PRIM/pdbprim           /system01.dbf
	mkdir -p /data/app/oracle/oradata/PRIM/pdbseed           /system01.dbf
=========================================================================================================	
5)Now since the DB is dropped we will create dummy pfile and follow the restore process.
	
	üîπüîπSQL> startup nomount pfile='/data/app/oracle/product/19C/dbhome_3/dbs/initprim.ora';
	
	üîπRMAN> restore spfile from '/data/rman/PRIM_LEVEL1_S_20250606_2r3rc0d1';
	
	Create new pfile.
	üîπüîπSQL> create pfile from spfile;
	
	File created.
	
	Now since the the audit log dump path is not created in spfile so we need to create one.
	
	üîπ[oracle@node1 ~]$ mkdir -p /data/app/oracle/admin/prim/adump
	
	üîπüîπSQL> startup nomount;
	
	üîπRMAN> restore controlfile from '/data/rman/PRIM_LEVEL1_C_20250606_2q3rc0d1';
	
	üîπüîπSQL> alter database mount;
	
	Database altered.
	
	üîπRMAN> catalog start with '/data/rman/';
	
	üîπRMAN> restore database;
	
	üîπRMAN> recover database;
	
	üîπRMAN> alter database open resetlogs; (To reset the archive log sequencing from 1 again)
	
	Statement processed
	
	üîπRMAN> exit
	
üî∏Now since we have done logfile switching by CDB to move the redo logs in archived redo logs so we got our 96 count which is called Point in time recovery.
	
	üîπüîπSQL> select count(*) from u1.t1;
	
	COUNT(*)
	----------
			96
=========================================================================================================
	


üîç What Are Audit Logs?
	Audit logs record who did what in the database. For example:
	
	Who logged in?
	
	Who created or dropped a table?
	
	Who updated sensitive data?
	
	Stored in /adump directory

	eg) /data/app/oracle/admin/prim/adump
	üîπ[oracle@node1 adump]$ cat prim_ora_9806_20250609150743411523712338.aud
	Audit file /data/app/oracle/admin/prim/adump/prim_ora_9806_20250609150743411523712338.aud
	Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production
	Version 19.14.0.0.0
	Build label:    RDBMS_19.14.0.0.0DBRU_LINUX.X64_211224.3
	ORACLE_HOME:    /data/app/oracle/product/19C/dbhome_3
	System name:    Linux
	Node name:      node1.learnomate.org
	Release:        4.14.35-1902.300.11.el7uek.x86_64
	Version:        #2 SMP Tue Mar 17 17:11:47 PDT 2020
	Machine:        x86_64
	Instance name: prim
	Redo thread mounted by this instance: 1
	Oracle process number: 53
	Unix process pid: 9806, image: oracle@node1.learnomate.org (TNS V1-V3)
	
	Mon Jun  9 15:07:43 2025 +05:30
	LENGTH : '269'
	ACTION :[7] 'CONNECT'
	DATABASE USER:[1] '/'
	PRIVILEGE :[6] 'SYSDBA'
	CLIENT USER:[6] 'oracle'
	CLIENT TERMINAL:[5] 'pts/0'
	STATUS:[1] '0'
	DBID:[9] '196814088'
	SESSIONID:[10] '4294967295'
	USERHOST:[20] 'node1.learnomate.org'
	CLIENT ADDRESS:[0] ''
	ACTION NUMBER:[3] '100'
	
	Mon Jun  9 15:07:43 2025 +05:30
	LENGTH : '267'
	ACTION :[6] 'COMMIT'
	DATABASE USER:[1] '/'
	PRIVILEGE :[6] 'SYSDBA'
	CLIENT USER:[6] 'oracle'
	CLIENT TERMINAL:[5] 'pts/0'
	STATUS:[1] '0'
	DBID:[9] '196814088'
	SESSIONID:[10] '4294967295'
	USERHOST:[20] 'node1.learnomate.org'
	CLIENT ADDRESS:[0] ''
	ACTION NUMBER:[2] '44'
	
	Mon Jun  9 15:07:43 2025 +05:30
	LENGTH : '267'
	ACTION :[6] 'COMMIT'
	DATABASE USER:[1] '/'
	PRIVILEGE :[6] 'SYSDBA'
	CLIENT USER:[6] 'oracle'
	CLIENT TERMINAL:[5] 'pts/0'
	STATUS:[1] '0'
	DBID:[9] '196814088'
	SESSIONID:[10] '4294967295'
	USERHOST:[20] 'node1.learnomate.org'
	CLIENT ADDRESS:[0] ''
	ACTION NUMBER:[2] '44'
	
	Mon Jun  9 15:10:28 2025 +05:30
	LENGTH : '407'
	ACTION :[145] 'SELECT SYS_CONTEXT('USERENV','CDB_NAME'),    SYS_CONTEXT('USERENV','CON_NAME'),    SYS_CONTEXT('USERENV','IS_APPLICATION_ROOT')    FROM SYS.DUAL'
	DATABASE USER:[1] '/'
	PRIVILEGE :[6] 'SYSDBA'
	CLIENT USER:[6] 'oracle'
	CLIENT TERMINAL:[5] 'pts/0'
	STATUS:[1] '0'
	DBID:[9] '196814088'
	SESSIONID:[10] '4294967295'
	USERHOST:[20] 'node1.learnomate.org'
	CLIENT ADDRESS:[0] ''
	ACTION NUMBER:[1] '3'
	
	Mon Jun  9 15:16:24 2025 +05:30
	LENGTH : '289'
	ACTION :[27] 'ALTER DATABASE CLOSE NORMAL'
	DATABASE USER:[1] '/'
	PRIVILEGE :[6] 'SYSDBA'
	CLIENT USER:[6] 'oracle'
	CLIENT TERMINAL:[5] 'pts/0'
	STATUS:[1] '0'
	DBID:[9] '196814088'
	SESSIONID:[10] '4294967295'
	USERHOST:[20] 'node1.learnomate.org'
	CLIENT ADDRESS:[0] ''
	ACTION NUMBER:[2] '35'
	
	Mon Jun  9 15:16:24 2025 +05:30
	LENGTH : '276'
	ACTION :[23] 'ALTER DATABASE DISMOUNT'
	DATABASE USER:[1] '/'
	PRIVILEGE :[6] 'SYSDBA'
	CLIENT USER:[6] 'oracle'
	CLIENT TERMINAL:[5] 'pts/0'
	STATUS:[1] '0'
	DBID:[0] ''
	SESSIONID:[10] '4294967295'
	USERHOST:[20] 'node1.learnomate.org'
	CLIENT ADDRESS:[0] ''
	ACTION NUMBER:[2] '35'
	
	Mon Jun  9 15:16:24 2025 +05:30
	LENGTH : '272'
	ACTION :[18] 'SHUTDOWN IMMEDIATE'
	DATABASE USER:[1] '/'
	PRIVILEGE :[6] 'SYSDBA'
	CLIENT USER:[6] 'oracle'
	CLIENT TERMINAL:[5] 'pts/0'
	STATUS:[1] '0'
	DBID:[0] ''
	SESSIONID:[10] '4294967295'
	USERHOST:[20] 'node1.learnomate.org'
	CLIENT ADDRESS:[0] ''
	ACTION NUMBER:[3] '139'


üß† Trace Logs:
Think of trace logs like a black box in an airplane. When something goes wrong in Oracle, trace logs record the exact actions and errors that happened behind the 
scenes ‚Äî super useful for finding out what went wrong and why.
‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ



üìåPATCHING
------------
Patching refers to the process of applying software updates to Oracle components which are provided by oracle support quarterly. These patches fix bugs, improve performance, 
and address security vulnerabilities. Patching is a offline activity.

‚úÖTYPES:--

1) Patch Set Update (PSU) - Cumulative patches that include High priority + Security patches.

2) Critical Patch Update (CPU) - Security-specific patches released quarterly.

3) One-off Patch - Fixes a specific bug. Usually requested through Oracle Support.

üî∏ OPatch is the utility used to perform patching. When you download patch we get one readme.html file which has the information related to patching prerequisites and how to 
	apply.

üî∏ Prerequisites for Patching:-
	‚óà Upgrade the opatch version as per the requirement of patching.
	‚óà Avoid conflict of patches (Overlaps with an existing patch already applied).
	‚óà Enough system space to apply patching.
	‚óà Need to shutdown DB and other services.
	‚óà We can apply patch.
	{‚ö†Ô∏èNote :- Check Invalid object count before and after patching it should be same}
	
üî∏ Command to check opatch version:-
	üîπ [oracle@node1 ~]$ $ORACLE_HOME/OPatch/opatch version
	OPatch Version: 12.2.0.1.17

	OPatch succeeded.
	
‚úÖ Steps for Patching.

1) Download patch from oracle support.

	üî∏ p6880880_122010_Linux-x86-64.zip  ==> Fixed reference number that Oracle uses on its support site to always point to the latest version of a particular tool or patch.
	------------------------------------	 So every time Oracle releases a new OPatch version, they update the files under patch number 6880880.
		‚óà This is the OPatch Utility itself.
		‚óà Patch Number: 6880880 (Permanent patch number for OPatch)
		‚óà Purpose: Updates the OPatch tool inside your $ORACLE_HOME/OPatch directory.
		‚óà Use it when: You need to make sure you have the latest OPatch before applying other patches.
		
	üî∏ p33509923_190000_Linux-x86-64.zip
	-------------------------------------
		‚óà This is an actual Oracle Database / Grid Infrastructure patch.
		‚óà Patch Number: 33509923
		‚óà Purpose: Updates your Oracle Grid Infrastructure and/or Database Home to include new features, security fixes, and bug fixes.
		‚óà Use it when: Update Oracle GI/DB
		
2) Create directory on linux. ==> mkdir -p  /data/patches
3) Upload the patches in /data/patches and unzip them.
4) Now open patch 33509923(CPU) and read the readme.html and check the OPatch utility version before applying. There are many sub patches inside this patch for 
   oracle home and grid home.
	Sub patches ===>
	Patch Number					Description								Applicable Homes
	a)33515361 			Database Release Update 19.14.0.0.220118			Only Oracle home
	b)33529556			OCW Release Update 19.14.0.0.220118			Both Oracle home and Grid home.
	
5) Now the version required to apply this patch is 12.2.0.1.28 or greater and our version is 12.2.0.1.17 so we need to upgrade.
6) We can check the latest OPatch Utility version for p6880880 inside a version.txt file inside the folder in windows (path: p6880880_122010_Linux-x86-64\OPatch\version.txt)
   i.e OPATCH_VERSION:12.2.0.1.29
   
7) Now to upgrade the our opatch version we need to replace the OPatch folder in our linux server with the OPatch folder of the p6880880_122010_Linux-x86-64.zip.
8) Rename our OPatch folder as old.
	üîπ [oracle@node1 ~]$ mv $ORACLE_HOME/OPatch $ORACLE_HOME/OPatch_old
9) Now put the OPatch folder(which we get after unzipping p6880880_122010_Linux-x86-64.zip) from /data/patches to $ORACLE_HOME
	üîπ cp -R OPatch $ORACLE_HOME
10) Now if we check the opatch version.
	üîπ[oracle@node1 OPatch]$ 		
	  OPatch Version: 12.2.0.1.29
	  
	  OPatch succeeded.
	  
11) Now check the prerequisites from readme.html

	‚óà check invalid object count:- (It should be zero before and after applying patch)
		üîπSQL> select count(*) from dba_objects where status='INVALID';
		
		COUNT(*)
		----------
				0
	{‚ö†Ô∏èNote :- if not proper:- run script	cd $ORACLE_HOME/rdbms/admin
											sqlplus /nolog
											üîπSQL> CONNECT / AS SYSDBA
											üîπSQL> @utlrp.sql
	
	‚óà check conflicts:- (run this commands one by one for both subpatches to check any conflicts if it comes "passed" and "OPatch succeeded" then no conflict.)
		üîπ $ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /data/patches/33509923/33515361
		üîπ $ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /data/patches/33509923/33529556
	{‚ö†Ô∏èNote :- if not proper:- $ORACLE_HOME/OPatch/opatch rollback -id <PATCH_NUMBER>}
	
	‚óà check system space:- 
		1) Create temporary file ==> vi /tmp/patch_list_dbhome.txt to Check many patches at once. And insert the following content:
			/data/patches/33509923/33515361
			/data/patches/33509923/33529556
		2) now run command (if it comes "passed" and "OPatch succeeded" then no space issue.)
			üîπ $ORACLE_HOME/OPatch/opatch prereq CheckSystemSpace -phBaseFile /tmp/patch_list_dbhome.txt
	{‚ö†Ô∏èNote :- if not proper:- Clear space}
	
12) To apply software level patch:-

	1) For 33515361 go to that path
	/data/patches/33509923
	üîπ [oracle@node1 33509923]$ ls -lrt
	total 136
	drwxr-x---. 4 oracle oinstall     48 Jan 13  2022 33575402
	drwxr-x---. 5 oracle oinstall     62 Jan 13  2022 33534448
	drwxr-x---. 2 oracle oinstall   4096 Jan 13  2022 automation
	drwxr-x---. 5 oracle oinstall     81 Jan 13  2022 33515361
	-rw-r--r--. 1 oracle oinstall      0 Jan 13  2022 README.txt
	drwxr-x---. 5 oracle oinstall     62 Jan 13  2022 33529556
	drwxr-x---. 4 oracle oinstall     48 Jan 13  2022 33239955
	-rw-rw-r--. 1 oracle oinstall   5824 Jan 13  2022 bundle.xml
	-rw-r--r--. 1 oracle oinstall 123797 Jan 20  2022 README.html
	
	cd 33515361
	/data/patches/33509923/33515361
	
	üîπ [oracle@node1 33515361]$ $ORACLE_HOME/OPatch/opatch apply
	Patch 33515361 successfully applied.
	Sub-set patch [29517242] has become inactive due to the application of a super-set patch [33515361].
	Please refer to Doc ID 2161861.1 for any possible further required actions.
	Log file location: /data/app/oracle/product/19C/dbhome_3/cfgtoollogs/opatch/opatch2025-06-08_23-53-54PM_1.log
	
	OPatch succeeded.


	2) For 33529556 go to that path
	cd /data/patches/33509923/33529556
	
	üîπ [oracle@node1 33529556]$ $ORACLE_HOME/OPatch/opatch apply
	Patch 33529556 successfully applied.
	Sub-set patch [29585399] has become inactive due to the application of a super-set patch [33529556].
	Please refer to Doc ID 2161861.1 for any possible further required actions.
	Log file location: /data/app/oracle/product/19C/dbhome_3/cfgtoollogs/opatch/opatch2025-06-09_00-01-51AM_1.log
	
	OPatch succeeded.
	
13) To apply DB level patch:-
	{‚ö†Ô∏èNote :- For DB level patch start CDB and PDB both}
	Go to $ORACLE_HOME/OPatch and run the datapatch script.
	 üîπ[oracle@node1 OPatch]$ cd $ORACLE_HOME/OPatch
	 üîπ[oracle@node1 OPatch]$ nohup ./datapatch & (run in background)
	Now "nohup.out" output log file is created in same path.
	
	üîπ [oracle@node1 OPatch]$ jobs
	[1]+  Running                 nohup ./datapatch &
	üîπ [oracle@node1 OPatch]$ jobs
	[1]+  Done                    nohup ./datapatch


‚úÖ Frequently Used OPatch Commands

| **Purpose**            | **Command**                                             | **Notes**                                  |
| ---------------------- | ------------------------------------------------------- | ------------------------------------------ |
| Check applied patches  | `opatch lsinventory`                                    | Lists all installed patches                |
| Check OPatch version   | `opatch version`                                        | Shows current OPatch utility version       |
| Apply a patch          | `opatch apply`                                          | Run from inside the patch directory        |
| Rollback a patch       | `opatch rollback -id <patch_number>`                    | Removes the specified patch                |
| Check patch conflicts  | `opatch prereq CheckConflictAgainstOHWithDetail -ph ./` | Run from the patch folder                  |
| Apply multiple patches | `opatch napply -skip_subset -skip_duplicate`            | Used for bundles with multiple sub-patches |
| Validate Oracle Home   | `opatch util validate`                                  | Checks Oracle Home for issues              |
‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ



üìåUPGRADATION
---------------
Upgradation in Oracle Database means moving from an older version of Oracle Database (e.g., 12c, 18c, or 19c) to a newer version (e.g., 21c or later). The goal is to take 
advantage of new features, enhanced performance, bug fixes, and better security.
{‚ö†Ô∏èNote :- Note this is software level upgradation and not DB level i.e 12c software to 19c software.}

‚úÖCOMPATIBILTY CHECKS:-

1) OS LEVEL:- An OS-level compatibility check ensures that your operating system (Linux, Windows, etc.) and its configuration are certified, supported, and capable of running 
			  the target Oracle Database version (like 19c or 21c).
‚û°Ô∏è		  
| Oracle DB Version | Supported OS (Example)                         |
| ----------------- | ---------------------------------------------- |
| 19c               | RHEL/CentOS/OL 7 & 8, Windows Server 2016/2019 |
| 21c               | OL 8+, RHEL 8+, Windows 2019/2022              |

 
2) DB LEVEL:- A DB-level compatibility check is like a health check for your current Oracle Database before upgrading it to a newer version (like from 12c to 19c or 21c).
			  Make sure your source version is directly upgradable to the target version.
‚û°Ô∏è			  
| Upgrade To | Supported From                    |
| ---------- | --------------------------------- |
| 19c        | 11.2.0.4, 12.1.0.2, 12.2.0.1, 18c |
| 21c        | 12.2.0.1, 18c, 19c                |


3) APP lEVEL:- Making sure your business application (like ERP, CRM, custom app, etc.) will work properly after the Oracle Database upgrade (e.g., 12c ‚Üí 19c). All these apps 
			  (ERP, CRM, custom) store or fetch data from the Oracle Database.
			  
‚û°Ô∏è When you upgrade the database, you must make sure:

üîπThese apps still work

üîπTheir queries and reports don‚Äôt break

üîπThey can still connect to the new version safely


‚úÖ Types of Upgrade Methods:-

	1. Manual Upgrade (Using SQL Scripts)
	
		üîπ You run preupgrade.jar which creates =>logfile, preupgrade_fixups.sql, postupgrade_fixups.sql then use catctl.pl and catupgrd.sql to manually upgrade.
	
		üîπ Suitable for experienced DBAs.
	
	2. DBUA (Database Upgrade Assistant)
	
		üîπ GUI-based tool provided by Oracle.
	
		üîπ Simplifies upgrade process.
	
		üîπ Good for non-critical or dev/test environments.
		


-------------------------------------------------------------------------üìå12c DB + Software Installation-----------------------------------------------------------------------------------------

üëâ1) Create new Oracle Linux server.
üëâ2) Login from Root user.
	üîπ yum install oracle-database-server-12cR2-preinstall -y  ===>Packages installation 12c
üëâ3) Now oracle user will be automatically downloaded.
üëâ4) Set bash profile by oracle user for 12c.
üëâ5) Create staging directory from root user where the software will be uploaded.(But in case of 19c we always upload our software in oracle_home).
	üîπ [oracle@node2 ~]$ mkdir -p /u01/staging
üëâ6) Create oracle_home and change group and give permissions
	üîπ [root@node2 ~]# mkdir -p /u01/app/oracle/product/12.2.0/dbhome_1
	üîπ [root@node2 ~]# chown -R oracle:oinstall /u01
	üîπ [root@node2 ~]# chmod -R 755 /u01
üëâ7) upload software to /u01/staging and change group again if not proper and then unzip

	üîπ [oracle@node2 staging]$ ll
	total 3372752
	-rw-rw-r--. 1 oracle oracle 3453696911 Jun 15 21:56 linuxx64_12201_database.zip
	
	üîπ [root@node2 ~]# chown -R oracle:oinstall /u01
	üîπ [root@node2 ~]# chmod -R 755 /u01
	üîπ [oracle@node2 staging]$ ll
	total 3372752
	-rwxr-xr-x. 1 oracle oinstall 3453696911 Jun 15 21:56 linuxx64_12201_database.zip
	üîπ [oracle@node2 staging]$ unzip linuxx64_12201_database.zip

üëâ8) run installer
	üîπ [oracle@node2 staging]$ ls -lrt
	total 3372756
	drwxr-xr-x. 7 oracle oracle         4096 Jan 26  2017 database
	-rwxr-xr-x. 1 oracle oinstall 3453696911 Jun 15 21:56 linuxx64_12201_database.zip
	üîπ [oracle@node2 staging]$ cd database
	üîπ [oracle@node2 database]$ ./runInstaller
	
üëâ9) From root user do entry of node and ip in /etc/hosts
	üîπ [root@node2 ~]# vi /etc/hosts
	üîπ [root@node2 ~]# cat /etc/hosts
	127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
	::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
	192.168.10.100  node2   node2.learnomate.org  <=================== Do this entry.
	
üëâ9) Now in "Recovery Options" section select archive log mode create directory in oracle user to store all archive logs
	üîπ [oracle@node2 ~]$ mkdir -p /u01/archive

üëâ10) Type "oracle" password for all users. and start installation.

üëâ11)Run below scripts with root user when the dialogue box appears.
	üîπ /u01/app/oraInventory/orainstRoot.sh
	üîπ /u01/app/oracle/product/12.2.0/dbhome_1/root.sh
	
close gui dialogue box after successful installation.

-------------------------------------------------------------------------üìå19c Software only Installation-----------------------------------------------------------------------------------------

	
üëâ12) Now create 19c path in oracle user 
	üîπ [oracle@node2 ~]$ mkdir -p  /u01/app/oracle/product/19.0.0/dbhome_1

üëâ13) Login from Root user.
	üîπ [root@node2 ~]# yum install -y oracle-database-preinstall-19c	===>Packages installation 19c

üëâ14) Now put 19c software in /u01/app/oracle/product/19.0.0/dbhome_1 and unzip
	üîπ [oracle@node2 dbhome_1]$ unzip LINUX.X64_193000_db_home.zip

üëâ15) runInstaller
	üîπ [oracle@node2 dbhome_1]$ ./runInstaller

	Now similarly a 19c gui will open now select "Set Up Software Only" in Database installation options.
	=>Set Up Software Only
	=>single instance
	=>root script execution select checkbox and put root password then root scripts will run automatically.
	
	Now the oracle 19c software only is installed.
	
-------------------------------------------------------------------------üìåUpgradation-----------------------------------------------------------------------------------------

üëâ16) open sql and check invalid object count it should be same before and after upgradation.

	üîπ üîπSQL> select count(*) from dba_objects where status='INVALID';
	
	COUNT(*)
	----------
			0

üëâ17) Now startup CDB & PDB and run "pre upgrade.jar"(checks the readiness of your current database for upgrade and gives detailed recommendations.)
	üîπ /u01/app/oracle/product/12.2.0/dbhome_1/jdk/bin/java -jar /u01/app/oracle/product/19.0.0/dbhome_1/rdbms/admin/preupgrade.jar FILE DIR /home/oracle/PRIM/preupgrade.
	
üëâ18) Now run preupgrade_fixups.sql in sql
	üîπ üîπSQL> @/home/oracle/PRIM/preupgrade./preupgrade_fixups.sql
	
üëâ19) Now put DB in archive log mode.

üëâ20) Create Flashback Guaranteed Restore Point

=> A Guaranteed Restore Point is a powerful Oracle feature that allows you to safely rewind your database back to a known good state ‚Äî even after major changes like patching,
   schema changes, or upgrades.
   
	üîπ üîπSQL> !mkdir -p /u01/app/oracle/fast_recovery_area 
	
	üîπ üîπSQL> alter system set db_recovery_file_dest_size=10G;
	
	System altered.
	
	üîπ üîπSQL> alter system set db_recovery_file_dest='/u01/app/oracle/fast_recovery_area';
	
	System altered.
	
	Now create the guarantee restore point.
	
	üîπ üîπSQL> create restore point pre_upgrade guarantee flashback database;

	Restore point created.
	
	üîπ üîπSQL> col name for a20
	col GUARANTEE_FLASHBACK_DATABASE for a10
	col TIME for a60
	set lines 190
	select NAME,GUARANTEE_FLASHBACK_DATABASE,TIME from V$restore_point;
	
		NAME                 GUARANTEE_ TIME
	-------------------- ---------- ------------------------------------------------------------
	PRE_UPGRADE          YES        15-JUN-25 11.59.29.000000000 PM

üëâ21) Now shutdown database.

üëâ22) Now we want to start DB by 19c but since we dont have spfile we will copy the 12c spfile to /u01/app/oracle/product/19.0.0/dbhome_1/dbs/
	üîπ [oracle@node2 dbs]$ cp spfileprim.ora /u01/app/oracle/product/19.0.0/dbhome_1/dbs

üëâ23) Startup DB in Upgrade mode from 19c home
=> Set environment variables

	üîπ [oracle@node2 dbs]$ export ORACLE_SID=prim;
	üîπ [oracle@node2 dbs]$ export ORACLE_HOME=/u01/app/oracle/product/19.0.0/dbhome_1
	üîπ [oracle@node2 dbs]$ PATH=/u01/app/oracle/product/19.0.0/dbhome_1/bin:$PATH; export PATH
	üîπ [oracle@node2 dbs]$ which sqlplus
	üîπ /u01/app/oracle/product/19.0.0/dbhome_1/bin/sqlplus
	
	üîπ üîπSQL> startup upgrade;
	
üëâ24) Run db upgrade.

	üîπ [oracle@node2 dbs]$ mkdir -p /home/oracle/whileupgrade
	üîπ [oracle@node2 dbs]$ cd /u01/app/oracle/product/19.0.0/dbhome_1/rdbms/admin
	üîπ [oracle@node2 admin]$ nohup /u01/app/oracle/product/19.0.0/dbhome_1/perl/bin/perl catctl.pl -l /home/oracle/whileupgrade -n 4 catupgrd.sql &
	üîπ [oracle@node2 admin]$ pwd
	üîπ /u01/app/oracle/product/19.0.0/dbhome_1/rdbms/admin
	üîπ [oracle@node2 admin]$ tail -f nohup.out ====> monitor the upgradation log
	üîπ [oracle@node2 admin]$ jobs
	    [1]+  Running                 nohup /u01/app/oracle/product/19.0.0/dbhome_1/perl/bin/perl catctl.pl -l /home/oracle/whileupgrade -n 4 catupgrd.sql &
	üîπ [oracle@node2 admin]$ jobs
	    [1]+  Done                    nohup /u01/app/oracle/product/19.0.0/dbhome_1/perl/bin/perl catctl.pl -l /home/oracle/whileupgrade -n 4 catupgrd.sql &



-------------------------------------------------------------------------üìåPOST Upgradation-----------------------------------------------------------------------------------------

üëâ25) Set bash_profile to 19c
	# User specific environment and startup programs
	
	PATH=$PATH:$HOME/.local/bin:$HOME/bin
	export ORACLE_BASE=/u01/app/oracle/
	export ORACLE_SID=prim
	export ORACLE_HOME=/u01/app/oracle/product/19.0.0/dbhome_1    <===================== 19c
	export LD_LIBRARY_PATH=\$ORACLE_HOME/lib:/lib:/usr/lib
	export CLASSPATH=\$ORACLE_HOME/jlib:\$ORACLE_HOME/rdbms/jlib
	PATH=$PATH:$HOME/.local/bin:$ORACLE_HOME/bin
	export PATH

	Now open duplicate session so that changes are reflected and open sqlplus
	
		Last login: Mon Jun 16 19:30:30 2025 from 192.168.0.100
	[oracle@node2 ~]$ sqlplus / as sysdba
	
	SQL*Plus: Release 19.0.0.0.0 - Production on Mon Jun 16 19:35:07 2025   <=================== 19c
	Version 19.3.0.0.0
	
	Copyright (c) 1982, 2019, Oracle.  All rights reserved.
	
	Connected to an idle instance.
	
	üîπSQL>

	üîπ üîπSQL> select name,open_mode,cdb,version,status from v$database,v$instance;
	
	NAME      OPEN_MODE            CDB VERSION           STATUS
	--------- -------------------- --- ----------------- ------------
	PRIM      READ WRITE           YES 19.0.0.0.0        OPEN
	
üëâ26) Check the invalid object count it should be zero. If not then run below script.

	üîπ üîπSQL>@/u01/app/oracle/product/19.0.0/dbhome_1/rdbms/admin/utlrp.sql
	
üëâ27) Now run post upgrade script.

	üîπ üîπSQL> @/home/oracle/PRIM/preupgrade./postupgrade_fixups.sql

üëâ28) Check Timezone of DB 

	üîπ üîπSQL> COLUMN version FORMAT 99999;
	SELECT version FROM v$timezone_file;
	üîπSQL>
	VERSION
	-------
		26
	
üëâ29) Run two scripts to change the timezone of DB
	üîπ üîπSQL> @/u01/app/oracle/product/19.0.0/dbhome_1/rdbms/admin/utltz_upg_check.sql
	üîπ üîπSQL> @/u01/app/oracle/product/19.0.0/dbhome_1/rdbms/admin/utltz_upg_apply.sql
	üîπ üîπSQL> COLUMN version FORMAT 99999;
	üîπ SELECT version FROM v$timezone_file;
	üîπSQL>
	VERSION
	-------
		32


-------------------------------------------------------------------------üèÅ Upgradation Successful--------------------------------------------------------------------------------
‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ




üìåAUTOMATIC STORAGE MANAGEMENT(ASM) [aka Volume Manager]
------------------------------------
ASM simplifies and optimizes the storage of Oracle database files (like datafiles, control files, redo logs) by managing them across multiple disks.
Think of it as a smart storage layer that handles:

| Feature                           | Description                                                          |
| --------------------------------- | -------------------------------------------------------------------- |
| Striping  - RBAL Process          | Spreads data evenly across disks to improve performance.             |
| Mirroring                         | Protects against disk failures (normal/high redundancy).             |
| Simplified Storage Management     | No need for file systems or logical volumes ‚Äî ASM handles it all.    |
| Scalability                       | Easily add/remove disks online without downtime.                     |
| Automatic Rebalancing             | Automatically redistributes data when storage configuration changes. |
| Supports CDB/PDB architecture     | Fully compatible with multitenant databases in 19c.                  |
| Redundancy						| Redundancy is the configuration level or policy you choose that 	   |
|									| determines how much mirroring ASM performs.						   |

üî∏ Now after installing ASM we will have two softwares in system 19c DB software & ASM software.

üî∏ So there will be two HOME's ORACLE_HOME & GRID_HOME and two users oracle & grid respectively.

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     ASM Architecture       ‚îÇ       ‚îÇ   Non-ASM (Traditional)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ                                ‚îÇ
              ‚ñº                                ‚ñº
         OS (OEL 7.9)                     OS (OEL 7.9)
              ‚îÇ                                ‚îÇ
              ‚ñº                                ‚ñº
      ASM Software (GRID)             OS File System (ext4/XFS)
              ‚îÇ                                ‚îÇ
              ‚ñº                                ‚ñº
      ASM File System (DGs)               DB Software (ORACLE_HOME)
              ‚îÇ                                ‚îÇ
              ‚ñº                                ‚ñº
     DB Software (ORACLE_HOME)             Database Instance
              ‚îÇ                                ‚îÇ
              ‚ñº                                ‚ñº
       Database Instance                 Database Files (datafiles,
   (+ASM mounts ASM Diskgroups)         redo logs, controlfiles etc.)
              ‚îÇ
              ‚ñº
   Database Files in ASM Diskgroup
      (+DATA, +FRA, etc.)


| ASM Architecture                                              | Non‚ÄëASM Architecture                              |
| ------------------------------------------------------------- | ------------------------------------------------- |
| Uses **ASM software** and **+ASM instance**                   | Uses **OS filesystem** (ext4/XFS)                 |
| Database files stored in **ASM Diskgroups** (`+DATA`, `+FRA`) | Files stored in regular paths like `/u01/oradata` |
| Grid Infrastructure (GI) must be installed                    | Only DB software is required                      |
| More scalable and suitable for RAC                            | Simpler for standalone DBs                        |

		
üß© Example:
	üî∏ You create 3 raw disks: /dev/sdb, /dev/sdc, /dev/sdd
	
	üî∏ ASM instance creates a diskgroup +DATA using these 3 disks.
	
	üî∏ Oracle database stores files like +DATA/ORCL/DATAFILE/system.123.456789 in that diskgroup.
	
‚úÖ NON ASM SCENARIO:-

A user fires a query. The Oracle database instance processes it ‚Äî parsing, verifying, and executing it. If needed, the instance fetches the required data from 
database files (via the OS filesystem in Non-ASM), and then returns the result back to the user.

‚úÖ ASM SCENARIO:- 

A user fires a SQL query. The Oracle database instance receives the query, parses, verifies, and executes it.
If data is needed, the DB instance communicates with the +ASM instance, which manages the ASM disk groups (like +DATA, +FRA).
The ASM instance handles the I/O and retrieves the required data files from the ASM disks.
The database instance then processes the data and returns the result to the user.


üîπ RBAL Process (Rebalance Process):-
----------------------------------------
RBAL stands for ReBalance ALlocation.

It is an ASM background process that coordinates disk rebalancing when:

A disk is added or removed from a disk group.

It tells other processes to move data evenly across disks.


üîπ ASM Power Limit:-
--------------------------
Controls how fast rebalancing happens.

Set using the asm_power_limit parameter (range 1‚Äì1024).

Higher value = faster rebalance, but more CPU usage.


üîπ What is Redundancy in ASM?
---------------------------------
In ASM, redundancy controls how Oracle manages data mirroring (i.e., protecting against disk failures):

| Redundancy Level | ASM Mirrors Data? | Who Provides Redundancy? |
| ---------------- | ----------------- | ------------------------ |
| **External**     | ‚ùå No             | **Storage or OS (RAID)** |
| **Normal**       | ‚úÖ Yes (2 copies) | ASM itself               |
| **High**         | ‚úÖ Yes (3 copies) | ASM itself               |


üîπ Files:-
-------------
spfiles are different because each instance has its own memory settings and parameters.

| File Type      | +ASM Instance   |  Database Instance    |
| -------------- | --------------- |  -------------------- |
| SPFILE         | ‚úÖ Has its own  | ‚úÖ Has its own        |
| Datafiles      | ‚ùå None         | ‚úÖ Yes                |
| Control files  | ‚ùå None         | ‚úÖ Yes                |
| Redo logs      | ‚ùå None         | ‚úÖ Yes                |
| Uses ASM disks | ‚úÖ Manages disks| ‚úÖ Stores data in ASM |

------------------------------------------------------------------------------üìåASM SETUP-----------------------------------------------------------------------------------------

üëâ1) Install 19c packages üîπ => 	
üëâ2) Install ASM package  üîπ => yum -y install oracleasm*
					      üîπ => yum -y install kmod-oracleasm*
üëâ3) Add OS groups
	üîπ=>groupadd -g 54327 asmdba
	    groupadd -g 54328 asmoper
	    groupadd -g 54329 asmadmin
	  
üëâ4) Add oracle user to asmdba as secondary group.
	üîπ => usermod -a -G asmdba oracle
	
üëâ5) Create GRID user
	üîπ => useradd -u 54331 -g oinstall -G dba,asmdba,asmoper,asmadmin,racdba grid
	
üëâ6) Create oracle and grid users password as "oracle" & "grid" respectively.
	üîπ => passwd oracle, passwd grid
	
üëâ7) Create ORACLE_HOME & GRID_HOME
	üîπ => mkdir -p /u02/app/oracle
	üîπ => mkdir -p /u02/app/oracle/product/19.3.0/db_home
	üîπ => chown -R oracle:oinstall /u02/app/oracle
	
	üîπ => mkdir -p /u01/app/grid/product/19.3.0/grid_home
	üîπ => chown -R grid:oinstall /u01/app/grid
	üîπ => chmod -R 775 /u01
	
üëâ8) CONFIGURE ASM

	=> oracleasm configure -i
	
	O/P:-
	------
	Default user to own the driver interface []: grid
	Default group to own the driver interface []: oinstall
	Start Oracle ASM library driver on boot (y/n) [n]: y
	Scan for Oracle ASM disks on boot (y/n) [y]: y
	Writing Oracle ASM library driver configuration: done
	
üëâ9) Load / initiate Oracle ASM
		=> oracleasm init
		
üëâ10) Now add disk
	=> üîπ power off machine -> settings -> storage -> add disk -> create 4 disks -> 2 10GB & 2 5GB disks.
	
üëâ11) Turn on machine login by root and check disk
	=> üîπ [root@node2 oracle]# fdisk -l
	
üëâ12) Format all disks

		Before format disk names:- /dev/sdb /dev/sdc /dev/sdd 
		Format command:- fdisk /dev/sdb fdisk /dev/sdc fdisk /dev/sdd 
		Prompt sequence:- Hit m,n,p,enter,enter,enter,w.
		After format disk names:- /dev/sdb1 /dev/sdc1 /dev/sdd1 

üëâ13) Create separate ASM Disk for each partition

	üîπ oracleasm createdisk CRS1 /dev/sdb1
	üîπ oracleasm createdisk DATA1 /dev/sdc1
	üîπ oracleasm createdisk FRA1 /dev/sdd1
	
	üîπ [root@node2 oracle]# oracleasm listdisks
	 DISK1
	 DISK2
	 DISK3
	 DISK4

	üîπ [root@node2 dev]# ls -lrt /dev/oracleasm/disks
	 total 0
	 brw-rw----. 1 grid oinstall 8, 49 Jun 20 15:23 DISK3
	 brw-rw----. 1 grid oinstall 8, 33 Jun 20 15:23 DISK2
	 brw-rw----. 1 grid oinstall 8, 17 Jun 20 15:23 DISK1
	 brw-rw----. 1 grid oinstall 8, 65 Jun 20 15:23 DISK4

üëâ14) Now to make ASM DISKS we need software so for that login with grid user create bash profile.

	  üîπexport ORACLE_BASE=/u01/app/grid
		export ORACLE_HOME=/u01/app/grid/product/19.3.0/grid_home
		export ORACLE_SID=+ASM
		export LD_LIBRARY_PATH=\$ORACLE_HOME/lib:/lib:/usr/lib
		export CLASSPATH=\$ORACLE_HOME/jlib:\$ORACLE_HOME/rdbms/jlib
		PATH=$PATH:$HOME/.local/bin:$ORACLE_HOME/bin
		export PATH
		umask 022
	
üëâ15) Download oracle grid software put it in GRID_HOME and unzip.

üëâ16) Download one rpm package.
	üîπ [grid@node2 grid_home]$ cd cv/rpm
	üîπ [grid@node2 rpm]$ ls -lrt
	üîπ total 12
	üîπ -rw-r--r--. 1 grid oinstall 11412 Mar 13  2019 cvuqdisk-1.0.10-1.rpm

	Install with root user
	
	[root@node2 rpm]# rpm -ivh cvuqdisk-1.0.10-1.rpm
	Preparing...                          ################################# [100%]
	Using default group oinstall to install package
	Updating / installing...
	1:cvuqdisk-1.0.10-1                ################################# [100%]

üëâ17) Login with Grid go to GRID_HOME and run grid setup script which will launch a GUI for setup.

	üîπ [grid@node2 ~]$ cd /u01/app/grid/product/19.3.0/grid_home
	üîπ [grid@node2 grid_home]$ ls -lrt *grid*
	üîπ -rwxr-x---. 1 grid oinstall       3294 Mar  8  2017 gridSetup.sh
	üîπ [grid@node2 grid_home]$ ./gridSetup.sh
	üîπ Launching Oracle Grid Infrastructure Setup Wizard...

üëâ18) From root user do entry of node and ip in /etc/hosts
	üîπ [root@node2 ~]# vi /etc/hosts
	üîπ [root@node2 ~]# cat /etc/hosts
	127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
	::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
	192.168.56.71  node1   node1.learnomate.org  <=================== Do this entry.
	
üëâ19) Now after successful installation of grid software.

üëâ20) Now run asmca for diskgroup creation.

üëâ21) Login with oracle and create bash profile.
	  üîπexport ORACLE_BASE=/u02/app/oracle
		export ORACLE_HOME=/u02/app/oracle/product/19.3.0/db_home
		export ORACLE_SID=prim
		export LD_LIBRARY_PATH=\$ORACLE_HOME/lib:/lib:/usr/lib
		export CLASSPATH=\$ORACLE_HOME/jlib:\$ORACLE_HOME/rdbms/jlib
		PATH=$PATH:$HOME/.local/bin:$ORACLE_HOME/bin

üëâ22) Create oracle directories

	üîπ mkdir -p /u02/app/oracle
	üîπ mkdir -p /u02/app/oracle/product/19.3.0/db_home
	üîπ chown -R oracle:oinstall /u02
	
üëâ23) Upload 19c db in ORACLE_HOME and unzip it after that ./runinstaller and select software only.

üëâ24) Now call dbca and install DB.


‚úÖ Now since we have successfully installed ASM we will open sqlplus in oracle user and check spfile, control file and data files location.

	üî∏ SQL> show parameter spfile;
	
	NAME                                 TYPE        VALUE
	------------------------------------ ----------- ------------------------------
	spfile                               string      +DATA/PRIM/PARAMETERFILE/spfil
                                                 e.265.1206026185

	üî∏ SQL> select name from v$controlfile;
	
	NAME
	--------------------------------------------------------------------------------
	+DATA/PRIM/CONTROLFILE/current.260.1206025937
	
	
	üî∏ SQL> select file_name from dba_data_files;
	
	FILE_NAME
	--------------------------------------------------------------------------------
	+DATA/PRIM/DATAFILE/users.259.1206025871
	+DATA/PRIM/DATAFILE/undotbs1.258.1206025869
	+DATA/PRIM/DATAFILE/system.256.1206025821
	+DATA/PRIM/DATAFILE/sysaux.257.1206025855


	üî∏ Now if we want to access this location of datafile login with grid user.
	   use below utility.
		üîπ [grid@node1 grid_home]$ asmcmd -p
		üîπ ASMCMD [+] >
		üîπ ASMCMD [+] >
		üîπ ASMCMD [+] > cd DATA/PRIM/
		üîπ ASMCMD [+DATA/PRIM] > ls
			CONTROLFILE/
			DATAFILE/
			ONLINELOG/
			PARAMETERFILE/
			TEMPFILE/
		üîπ ASMCMD [+DATA/PRIM] > cd PARAMETERFILE/
		üîπ ASMCMD [+DATA/PRIM/PARAMETERFILE] > ls
			spfile.265.1206026185
		
	üî∏ To copy spfile or any file from ASM filesystem to normal file system.
		üîπ ASMCMD [+DATA/PRIM/PARAMETERFILE] > cp spfile.265.1206026185 /home/grid
		   copying +DATA/PRIM/PARAMETERFILE/spfile.265.1206026185 -> /home/grid/spfile.265.1206026185
		   
	üî∏ To check disks present and their details.(metadata table:- v$asm_diskgroup)
		üîπASMCMD [+DATA/PRIM] > lsdg
		State    Type    Rebal  Sector  Logical_Sector  Block       AU  Total_MB  Free_MB  Req_mir_free_MB  Usable_file_MB  Offline_disks  Voting_files  Name
		MOUNTED  EXTERN  N         512             512   4096  4194304     10236    10136                0           10136              0             N  CRS/
		MOUNTED  EXTERN  N         512             512   4096  4194304     10236     7680                0            7680              0             N  DATA/
		MOUNTED  EXTERN  N         512             512   4096  4194304     10236    10148                0           10148              0             N  FRA/

	üî∏ To change the archive log destination as +FRA diskgroup.
		SQL> archive log list;
		Database log mode              No Archive Mode
		Automatic archival             Disabled
		Archive destination            /u02/app/oracle/product/19.3.0/db_home/dbs/arch
		Oldest online log sequence     3
		Current log sequence           5
		SQL>
		
		SQL> ALTER SYSTEM SET log_archive_dest_1='LOCATION=+FRA' SCOPE=BOTH;
		
		System altered.
		
		SQL> archive log list;
		Database log mode              No Archive Mode
		Automatic archival             Disabled
		Archive destination            +FRA
		Oldest online log sequence     3
		Current log sequence           5

	üî∏ To add datafile to tablespace we just need to write the command, ASM Oracle mangage file will automatically keep name of that file.
		üîπ SQL> alter tablespace USERS add datafile '+DATA' size 10m;

			Tablespace altered.

		üîπ SQL> select file_name from dba_data_files;

				FILE_NAME
				--------------------------------------------------------------------------------
				+DATA/PRIM/DATAFILE/users.259.1206025871
				+DATA/PRIM/DATAFILE/undotbs1.258.1206025869
				+DATA/PRIM/DATAFILE/system.256.1206025821
				+DATA/PRIM/DATAFILE/sysaux.257.1206025855
				+DATA/PRIM/DATAFILE/users.266.1206029015                             <=================== New File

	üî∏ To check ASM spfile location and create pfile login sql as sysasm

		üîπ [grid@node1 grid_home]$ sqlplus / as sysasm

		üîπ SQL> show parameter spfile;

		NAME                                 TYPE        VALUE
		------------------------------------ ----------- ------------------------------
		spfile                               string      +CRS/ASM/ASMPARAMETERFILE/regi
                                                 stry.253.1206022649
		üîπ SQL> create pfile from spfile;

			File created.
			SQL> exit

			[grid@node1 grid_home]$ cd $ORACLE_HOME/dbs


		üîπ [grid@node1 dbs]$ ls -lrt
			total 16
			-rwxrwxr-x. 1 grid oinstall 3079 May 14  2015 init.ora
			-rw-rw----. 1 grid oinstall 1544 Jul  9 14:17 hc_+ASM.dat
			-rw-rw----. 1 grid oinstall 3955 Jul  9 14:17 ab_+ASM.dat
			-rw-r--r--. 1 grid oinstall  240 Jul  9 16:08 init+ASM.ora 

		{‚ö†Ô∏èNote:- First shutdown DB and then ASM, While starting First Start ASM and then DB.}


	üî∏ If we want to do normal backup of spfile using RMAN

		üîπ RMAN> backup spfile;

	üî∏ If we want to take backup of spfile in +FRA diskgroup.

		üîπ RMAN> backup spfile format '+FRA/spfile_%u';

		üîπ [grid@node1 ~]$ asmcmd -p
			ASMCMD [+] >
			ASMCMD [+] > cd FRA
			ASMCMD [+FRA] > ls
				PRIM/
				spfile_033u5o67
‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ

	

üìåDATAGUARD
---------------
Oracle Data Guard in Oracle 19c is a disaster recovery and high availability solution that ensures data protection and availability by creating and managing one or more 
standby copies of a production (primary) database.
																	   														   
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------																	   
										                         ++++++ORACLE DATAGUARD ARCHITECTURE++++++							   
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
						P R I M A R Y 	S I T E						   |						   				S T A N D B Y	S I T E
																	   |
																	   |
+----------------------------+       +------------+        +-----+     |     +-----+                                     +-----+        +------------------+
|PRIMARY DATABASE TRANSACTION| ----> | REDO BUFFER|  ----- | LNS | --------- | RFS | ---------|                          | MRP |------> | STANDBY DATABASE |
+----------------------------+       +------------+        +-----+     |     +-----+          |                          +-----+        +------------------+
										   |                          t|       ||             |                             |             |              |
										   V                          e|       ||             |                             |             |              |
								     +------------+                   n|       ||             |                             |             |              |
									 |    LGWR    |                    |       ||             |                             |             |              |
									 +------------+                   e|       ||             |                             |             |              |
									       |                          l|       ||             |                             |        +---------+     +--------+
										   V                          c|       ||             V                             |        | REPORTS |     | BACKUP |
								  +------------------+                a|       ||    +-------------------+ (Real-time Apply)|        +---------+     +--------+
								  | ONLINE REDO LOGS |                r|       ||    | STANDBY REDO LOGS |----------------->|
								  +------------------+                o|       ||    +-------------------+                  |
								           |                           |       ||             |                             |
										   V                           |       ||             V                             |
									 +------------+     Gap Resolution |       ||       +------------+                      |
									 |    ARC0    | ------>-------<------------||       |    ARC0    |                      |
									 +------------+                    |        |       +------------+                      |
									       |                           |        |             |                             |
										   V                           |        |             V                             |
							    +---------------------+                |        |  +---------------------+                  |
								| ARCHIVED REDO LOGS  |                |        |--| ARCHIVED REDO LOGS  |------------------|
								+---------------------+                |           +---------------------+
								                                       |
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------																	   

üü• Primary Site
------------------
üî∏ Primary Database Transaction: User-initiated DML/DDL operations that modify data.

üî∏ Redo Buffer: Temporarily stores redo information in memory (SGA).

üî∏ LGWR (Log Writer): Writes redo from buffer to online redo logs.

üî∏ ONLINE REDO LOGS: Disk-based logs storing real-time redo data.

üî∏ ARC0 (Archiver Process): Archives full online redo logs to archive logs.

üî∏ ARCHIVED REDO LOGS: Historical redo log files stored for recovery.

üî∏ LNSn (Log Network Service): Sends redo data in real-time to standby via Oracle Net.


üü© Transport (Network Layer)
-------------------------------

üî∏ Oracle Net: Facilitates redo transmission between primary and standby databases.


üü¶ Standby Site
------------------

üî∏ RFS (Remote File Server): Receives redo data from LNSn and writes to standby redo logs.

üî∏ STANDBY REDO LOGS: Temporary redo logs on standby for real-time apply.

üî∏ ARC0 (on Standby): Archives standby redo logs to local archived redo logs.

üî∏ ARCHIVED REDO LOGS (on Standby): Retained redo logs for recovery or gap resolution.

üî∏ MRP (Managed Recovery Process): Applies redo to maintain synchronization with primary.

üî∏ STANDBY DATABASE: Synchronized copy of primary, ready for failover or read-only access.

üî∏ REPORTS: Run read-only queries (if standby is in read-only or snapshot mode).

üî∏ BACKUP: Create backups without impacting the production database.



‚úÖ TYPES :-
=================

++++++++++++++++++++
1. Physical Standby+
++++++++++++++++++++

üî∏ Exact block-for-block copy of the primary database.

üî∏ Uses Redo Apply to keep in sync.

üî∏ Supports real-time apply and failover.

üî∏ Can be opened read-only for reporting (Active Data Guard).


‚úÖ SETUP STEPS :-
=================

‚û°Ô∏è1. startup primary DB.

	üîπ SQL> alter system set log_archive_dest_1='location=/data/archive' scope=both;

‚û°Ô∏è2. change archive log destination and shutdown DB and startup mount.

	üîπ SQL> startup mount

	üîπ SQL> alter database archivelog;

	   Database altered.

	üîπ SQL> alter database open;

	   Database altered.

‚û°Ô∏è3. Add below entries in /etc/hosts of both node 1 & 2.

	üîπ vi /etc/hosts
	
	  192.168.56.50 node1.learnomate.org node1
	  192.168.56.60 node2.learnomate.org node2

‚û°Ô∏è4. Disable the firewall of both primary and standby machine.

	üîπ [root@node1 ~]# systemctl stop firewalld
	üîπ [root@node1 ~]# systemctl disable firewalld
	
	Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service.
	Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.
	
	üîπ [root@node2 ~]# systemctl stop firewalld
	üîπ [root@node2 ~]# systemctl disable firewalld
	
	Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service.
	Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.


‚û°Ô∏è5. create standby redo logs for switchovers on STANDBY & PRIMARY.

	üîπ SQL> alter database add standby logfile '/data/app/oracle/oradata/STAND/redo04.log' size 200m;
	üîπ SQL> alter database add standby logfile '/data/app/oracle/oradata/STAND/redo05.log' size 200m;
	üîπ SQL> alter database add standby logfile '/data/app/oracle/oradata/STAND/redo06.log' size 200m;
	üîπ SQL> alter database add standby logfile '/data/app/oracle/oradata/STAND/redo07.log' size 200m;
	
	üîπ SQL> alter database add standby logfile '/data/app/oracle/oradata/PRIM/redo04.log' size 200m;
	üîπ SQL> alter database add standby logfile '/data/app/oracle/oradata/PRIM/redo05.log' size 200m;	   <===================|
	üîπ SQL> alter database add standby logfile '/data/app/oracle/oradata/PRIM/redo06.log' size 200m;                           |
	üîπ SQL> alter database add standby logfile '/data/app/oracle/oradata/PRIM/redo07.log' size 200m;                           |
																												               |
‚û°Ô∏è6. To check created standby logs on primary.                                                                                 |
																												               |
	üîπ SQL> SELECT group#, type, member FROM v$logfile WHERE type = 'STANDBY' order by group#;                                 |
	 																												           |
	GROUP# TYPE                                                                                                                |
	---------- -------                                                                                                         |
	MEMBER                                                                                                                     |
	--------------------------------------------------------------------------------                                           |
			4 STANDBY                                                                                                          |
	/data/app/oracle/oradata/PRIM/redo04.log                                                                                   |
																													           |
			5 STANDBY                                                                                                          |
	/data/app/oracle/oradata/PRIM/redo05.log                                                                                   |
																													           |
			6 STANDBY                                                                                                          |
	/data/app/oracle/oradata/PRIM/redo06.log                                                                                   |
																													           |
		7 STANDBY                                                                                                              |
	/data/app/oracle/oradata/PRIM/redo07.log                                                                                   |
																												               |
‚û°Ô∏è7. To check online redo log file size                                                                                        |
																												               |
	üîπ SQL> select GROUP#,THREAD#,SEQUENCE#,bytes/1024/1024,MEMBERS,STATUS from v$log;                                         |
																												               |
		GROUP#    THREAD#  SEQUENCE# BYTES/1024/1024    MEMBERS STATUS                                                         |
	---------- ---------- ---------- --------------- ---------- ----------------        <================ Here we have 3 online redo logs each of size 200 MB so the  
			1          1          4             200          1 INACTIVE                                  standby redo logs size should also be 200 MB only.
			2          1          5             200          1 INACTIVE                         {‚ö†Ô∏èNote:- the no of standby redo log = no of online redo log + 1
			3          1          6             200          1 CURRENT                          thats why we created a standby redo logs on primary. Because when high
																							  high data traffic arrives at online redo logs ==> standby redo logs ==> 
																							 if still more traffic ==> data passed to extra standby log.}

‚û°Ô∏è8. Check DB_NAME & DB_UNIQUE_NAME

	üîπ SQL> show parameter db_name NAME
	
	NAME                                 TYPE        VALUE
	------------------------------------ ----------- ------------------------------
	db_name                              string      prim
	SQL>
	üîπ SQL> show parameter db_unique_name

	NAME                                 TYPE        VALUE
	------------------------------------ ----------- ------------------------------
	db_unique_name                       string      prim

‚û°Ô∏è9. set remote archivelog destination for standby

	üîπ SQL> alter system set log_archive_dest_2= 'service=stand async noaffirm reopen=15  valid_for=(all_logfiles,primary_role) db_unique_name=stand';
																							 

‚û°Ô∏è10. The STANDBY_FILE_MANAGEMENT parameter must be set AUTO (Automatic syncing of files on standby server)	

	üîπ SQL> ALTER SYSTEM SET STANDBY_FILE_MANAGEMENT=AUTO;

	System altered.


‚û°Ô∏è11. Listener configuration on PRIMARY.

	# listener.ora Network Configuration File: /u02/app/oracle/product/19.3.0/db_home/network/admin/tnsnames.ora
	# Generated by Oracle configuration tools.
	
	
	SID_LIST_LISTENER =
	(SID_LIST =
		(SID_DESC =
			(GLOBAL_DBNAME = prim)
			(ORACLE_HOME = /u02/app/oracle/product/19.3.0/db_home)
			(SID_NAME = prim)
		)
		(SID_DESC =
		(GLOBAL_DBNAME = stand)
		(ORACLE_HOME = /u02/app/oracle/product/19.3.0/db_home)
		(SID_NAME = stand)
		)
	)

	LISTENER =
		(DESCRIPTION_LIST =
			(DESCRIPTION =
			(ADDRESS = (PROTOCOL = TCP) (HOST = node1.learnomate.org)(PORT = 1521))
			(ADDRESS = (PROTOCOL = ICP) (KEY = EXTPROC1521))
			)
		)


‚û°Ô∏è12. TNS FIle configuration on PRIMARY.

	PRIM =
	(DESCRIPTION =
		(ADDRESS = (PROTOCOL = TCP)(HOST = node1.learnomate.org)(PORT = 1521))
		(CONNECT_DATA =
		(SERVER = DEDICATED)
		(SERVICE_NAME = prim)
		)
	)
	STAND =
	(DESCRIPTION =
		(ADDRESS = (PROTOCOL = TCP)(HOST = node2.learnomate.org)(PORT = 1521))
		(CONNECT_DATA =
		(SERVER = DEDICATED)
		(SERVICE_NAME = stand)
		)
	)														 
  
 
‚û°Ô∏è13. Set the log_archive_config parameter( This tells that how many nodes are there in our DATAGUARD)

	üîπ SQL> alter system set log_archive_config='dg_config=(prim,stand)';

	System altered.

‚û°Ô∏è14. set remote_login_passwordfile exclusive. (To create seperate password file for STANDBY)

	üîπ SQL> alter system set remote_login_passwordfile='EXCLUSIVE' scope=spfile;

	System altered.

‚û°Ô∏è15. Update the fal_server and fal_client(For switch over/ fail over activity)

	üîπ SQL> alter system set fal_server='stand';

	System altered.

	üîπ SQL> alter system set fal_client='prim';

	System altered.


‚û°Ô∏è16. SCP password file, listener.ora and tnsnames.ora to standby server. and edit the listener.ora and tnsname.ora as node 2

	üîπ [oracle@node1 dbs]$ scp orapwprim oracle@node2:$ORACLE_HOME/dbs/orapwstand
	üîπ [oracle@node1 admin]$ scp listener.ora oracle@node2:$ORACLE_HOME/network/admin/
	üîπ [oracle@node1 admin]$ scp tnsnames.ora oracle@node2:$ORACLE_HOME/network/admin/

	IN listener.ora
	----------------
	
	LISTENER =
		(DESCRIPTION_LIST =                      |
			(DESCRIPTION =                       V
			(ADDRESS = (PROTOCOL = TCP) (HOST = node2.learnomate.org)(PORT = 1521))
			(ADDRESS = (PROTOCOL = ICP) (KEY = EXTPROC1521))
			)
		)
	
	IN tnsname.ora
	----------------
										   |
	LISTENER_PRIM =                        V
	(ADDRESS = (PROTOCOL = TCP)(HOST = node2.learnomate.org)(PORT = 1521))


‚û°Ô∏è17. Standby Configuration Create directory on standby for CDB and PDB datafile also.

	üîπ [root@node2 ~]# mkdir -p /data/app/oracle/oradata/STAND/pdbprim
	üîπ [root@node2 ~]# mkdir -p /data/app/oracle/oradata/STAND/pdbseed
	üîπ [root@node2 ~]# mkdir -p /data/app/oracle/admin/stand/adump
	üîπ [root@node2 ~]# mkdir -p /data/app/oracle/fast_recovery_area/stand/

‚û°Ô∏è18. Create initstand.ora (pfile) in STANDBY server

	üîπ [oracle@node2 dbs]$ vi initstand.ora   (REFER LOGS.txt)

‚û°Ô∏è19. startup database STAND in nomount using pfile.

	üîπSQL> startup nomount pfile='initstand.ora';

‚û°Ô∏è20. Start listener in both servers.

‚û°Ô∏è21. connect with rman with target & auxiliary instance using the following command.

	üîπ[oracle@node2 dbs]$ rman target sys/oracle@prim auxiliary sys/oracle@stand

‚û°Ô∏è22. Run the following duplicate command, that command will start copying all database on the standby server.

	üîπRMAN> Duplicate target database for standby from active database dorecover nofilenamecheck;

‚û°Ô∏è23. Dataguard important Queries Check the database status on primary and standby

	üîπSQL> select status,instance_name,database_role,protection_mode from v$database,v$instance;
	
	STATUS       INSTANCE_NAME    DATABASE_ROLE    PROTECTION_MODE
	------------ ---------------- ---------------- --------------------
	OPEN         prim             PRIMARY          MAXIMUM PERFORMANCE
	
	üîπSQL> select status,instance_name,database_role,protection_mode from v$database,v$instance;
	
	STATUS       INSTANCE_NAME    DATABASE_ROLE    PROTECTION_MODE
	------------ ---------------- ---------------- --------------------
	MOUNTED      stand            PHYSICAL STANDBY MAXIMUM PERFORMANCE


‚û°Ô∏è24. On node2 startup nomount.
	üîπ[oracle@node2 ~]$ sqlplus / as sysdba
	üîπSQL> startup nomount
	üîπSQL> ALTER DATABASE MOUNT STANDBY DATABASE;
	Database altered.
	SQL>

‚û°Ô∏è25. now check the DB status on node1 and node2.
	üîπSQL> select name, open_mode, database_role from v$database;
	
	NAME      OPEN_MODE            DATABASE_ROLE
	--------- -------------------- ----------------
	PRIM      READ WRITE           PRIMARY
	
	üîπSQL> select name, open_mode, database_role from v$database;
	
	NAME      OPEN_MODE            DATABASE_ROLE
	--------- -------------------- ----------------
	PRIM      MOUNTED              PHYSICAL STANDBY

‚û°Ô∏è26. To start the MRP service on standby DB run below command.
	üîπSQL> alter database recover managed standby database disconnect from session;          <=============== START MRP

	Database altered.

‚û°Ô∏è27. Now we can check whether changes made on primary are actually reflecting on standby DB or not.

	On primary
	
	üîπSQL> SELECT SEQUENCE#, APPLIED FROM V$ARCHIVED_LOG;
	SEQUENCE# APPLIED
	---------- ---------
			14 YES
			15 YES
			17 YES
			16 YES
			6 YES
			18 NO
			19 NO
			20 NO
			21 NO
			21 NO
			22 NO           <==================== Same sequence number
	
	
	32 rows selected.
	
	üîπSQL> alter system switch logfile;
	
	System altered.
	
	üîπSQL> SELECT SEQUENCE#, APPLIED FROM V$ARCHIVED_LOG;
	
	On standby
	
	SEQUENCE# APPLIED
	---------- ---------
			14 YES
			15 YES
			17 YES
			16 YES
			6 YES
			18 NO
			19 NO
			20 NO
			21 NO
			21 NO
			22 NO            <==================== Same sequence number That means Changes are reflecting.
			
			

==========================================================================‚úÖ ACTIVE DATAGUARD MODE ===============================================================================

‚úÖ Now since we cannot read any data from standby database so to make it read only mode because it is in mount stage so we have to put primary database in (Active Dataguard Mode).

‚û°Ô∏è1. Cancel the running MRP process on STANDBY

	üîπSQL> alter database recover managed standby database cancel;
	Database altered.
	
‚û°Ô∏è2. Open STANDBY DATABASE	

	üîπSQL> alter database open;
	Database altered.
	
‚û°Ô∏è3. Now again start MRP to view the changes on STANDBY.

	üîπSQL> alter database recover managed standby database disconnect from session;
	Database altered.
	
‚û°Ô∏è4. To check whether changes done to primary are reflecting on standby or not.

	On Primary creating a table and inserting values.
	
		üîπSQL> CREATE TABLE guys (
		id   NUMBER,
		name VARCHAR2(100));
		
		üîπSQL> INSERT INTO guys (id, name) VALUES (1, 'Alice');
		üîπSQL> INSERT INTO guys (id, name) VALUES (2, 'Bob');
		
		üîπSQL> commit;
		
		üîπSQL> select * from guys;
		
			ID NAME
	---------- ----------------------------------------------------------------------------------------------------
			1 Alice
			2 Bob


‚û°Ô∏è5. Now on standby check the changes

	üîπSQL> select * from guys;
		
			ID NAME
	---------- ----------------------------------------------------------------------------------------------------
			1 Alice
			2 Bob
	



+++++++++++++++++++++++++++++
2. Snapshot Standby Database+
+++++++++++++++++++++++++++++

üî∏ Description: A physical standby database temporarily converted into a read/write database for testing.

üî∏ Data Sync: Redo logs are received but not applied until the snapshot is converted back to a physical standby.

üî∏ Use Case: Ideal for testing changes in a production-like environment without affecting replication.


‚úÖ SETUP STEPS :-
=================

‚û° 1. Cancel the existing Recovery Process i.e MRP

	üîπ SQL> alter database recover managed standby database cancel;
 
Database altered.

‚û° 2. Shutdown database to enable flashback and start again in mount stage.

	üîπ SQL> shu immediate;
	üîπ SQL> startup mount;

‚û° 3. Check if recovery area is already set with required size.

	üîπ SQL> show parameter recover;

	NAME                                 TYPE        VALUE
	------------------------------------ ----------- ------------------------------
	db_recovery_file_dest                string      /data/app/oracle/fast_recovery <====|
													_area/                              ====> Before creating guarantee restore point these 2 parameters must be set properly.
	db_recovery_file_dest_size           big integer 4800M                          <====|
	db_unrecoverable_scn_tracking        boolean     TRUE
	recovery_parallelism                 integer     0
	remote_recovery_file_dest            string


‚û° 4. Now the below command will convert it to snapshot standby

	üîπ SQL> alter database convert to snapshot standby;
 
Database altered.

	üîπ SQL> alter database open;
 
Database altered.

	üîπ SQL> select name,open_mode from v$database;
 
	NAME      OPEN_MODE
	--------- --------------------
	PRIM      READ WRITE

==========================================================================‚úÖ SNAPSHOT STANDBY USE CASE ===========================================================================


‚úÖ Now since snapshot standby is generally used for testing purpose we will see the use case.

üî∏ Consider primary db is up and running.

üî∏ We opened standby db in mount stage.

	üîπ SQL> startup mount;
	
üî∏ Convert standby db to physical standby / active dataguard mode.

	üîπ SQL> alter database convert to physical standby.
	üîπ SQL> alter database open;
	üîπ SQL> select name,open_mode from v$database;
 
	NAME      OPEN_MODE
	--------- --------------------
	PRIM      READ ONLY

üî∏ Now Create a table emp on primary db.

	üîπ SQL> create table emp (name char(10));
	üîπ SQL> insert into emp values ('primary');
	üîπ SQL> insert into emp values ('primary');
	üîπ SQL> commit;
	
	üîπSQL> select * from emp;
	
	NAME
	---------
	primary
	primary
	
üî∏ Now go to standby db and start mrp so that the logs are applied to standby db.

	üîπ SQL> alter database recover managed standby database disconnect from session;
	üîπ SQL> select * from emp;
	
	NAME
	---------
	primary
	primary

üî∏ Now kill mrp and to convert physical standby into snapshot standby for testing purpose.
	üîπ SQL>	 ALTER DATABASE RECOVER MANAGED STANDBY DATABASE CANCEL;
	üîπ SQL> shu immediate;
	üîπ SQL> startup mount;
	üîπ SQL> alter database convert to snapshot standby.
	üîπ SQL> alter database open;
	üîπ SQL> select name,open_mode from v$database;
	
	NAME      OPEN_MODE
	--------- --------------------
	PRIM      READ WRITE
	
	üîπ SQL> select * from emp;
	
	NAME
	---------
	primary
	primary

üî∏ Now for testing the application team inserts some record inside emp table of stanby db.

	üîπ SQL> insert into emp values ('testing');
    üîπ SQL> insert into emp values ('testing');
    üîπ SQL> commit;
	
	üîπ SQL> select * from emp;
	
	NAME
	---------
	primary
	primary
	testing
	testing
	
üî∏ Now if we insert new records in emp from primary the changes wont go to standby because it is in snapshot standby mode where MRP is not started.

	üîπ SQL> insert into emp values ('after snap');
	üîπ SQL> insert into emp values ('after snap');
	üîπ SQL> commit;

	üîπ SQL> select * from emp;
	
	NAME
	---------
	primary
	primary
	after snap
	after snap
	
üî∏ Now since the testing is done now we can put the snapshot standby to physical standby again.

	üîπ SQL> shu immediate;
	üîπ SQL> startup mount;
	üîπ SQL> alter database convert to physical standby.
	üîπ SQL> alter database open;                           <=========Active Dataguard Mode
	
üî∏ Now to apply "after snap" new records from primary db we have to start MRP on physical standby.

	üîπ SQL> alter database recover managed standby database disconnect from session;
	üîπ SQL> select * from emp;
	
	NAME
	---------
	primary
	primary
	after snap
	after snap
	
	Now all the testing records are gone.
	
	
	
üß© Physical Standby Creation ‚Äì Comparison

| Step                               | **Using RMAN Backup (Traditional Method)**                                                 | **Using RMAN Active Duplicate (Modern Method)**                                                |
| ---------------------------------- | ------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------- |
| **1. Prerequisites**               | Primary must be in ARCHIVELOG + FORCE LOGGING mode.                                        | Same ‚Äî ARCHIVELOG + FORCE LOGGING required.                                                    |
| **2. Network Setup**               | Not mandatory (you just copy files manually).                                              | Mandatory ‚Äî tnsnames and listener must be configured for both primary & standby.               |
| **3. Backup**                      | Take full RMAN backup of datafiles + archivelogs.                                          | No backup needed ‚Äî datafiles copied directly over network.                                     |
| **4. Standby Controlfile**         | Create using:<br>`ALTER DATABASE CREATE STANDBY CONTROLFILE AS '/tmp/standby.ctl';`        | RMAN automatically creates standby controlfile.                                                |
| **5. Copy Files**                  | Manually copy backups and controlfile to standby server.                                   | No manual copy ‚Äî RMAN duplicates directly.                                                     |
| **6. Standby Initialization File** | Create `init.ora` manually with all DG parameters.                                         | Same ‚Äî you create minimal `init.ora` before starting NOMOUNT.                                  |
| **7. Start Standby**               | `STARTUP NOMOUNT;`                                                                         | `STARTUP NOMOUNT;`                                                                             |
| **8. Restore Database**            | Run RMAN commands:<br>`RESTORE CONTROLFILE;`<br>`RESTORE DATABASE;`<br>`RECOVER DATABASE;` | Run single command:<br>`DUPLICATE TARGET DATABASE FOR STANDBY FROM ACTIVE DATABASE DORECOVER;` |
| **9. Managed Recovery**            | Start manually:<br>`ALTER DATABASE RECOVER MANAGED STANDBY DATABASE DISCONNECT;`           | RMAN starts recovery automatically (if `DORECOVER` used).                                      |
| **10. Complexity**                 | More manual ‚Äî suitable when network is slow or restricted.                                 | Easier & faster ‚Äî preferred method in most environments.                                       |
| **11. File Copy Method**           | Using RMAN backupsets or OS copy.                                                          | Through Oracle Net (network connection).                                                       |
| **12. Performance**                | Depends on disk copy speed.                                                                | Depends on network throughput.                                                                 |

	
===================================================================‚úÖSwitchover in Oracle 19C Dataguard==========================================================================


üîÑ PREREQUISITES:-
===================
üî∏ Data Guard is configured and running correctly.

üî∏ Archive log shipping and Redo Apply are working.

üî∏ Both databases are in SYNC.

üî∏ You have a full backup.

‚û° 1. Check Switchover Status on Primary
  +++++++++++++++++++++++++++++++++++++++
	Login to the primary database:
	
	üîπSQL> SELECT SWITCHOVER_STATUS FROM V$DATABASE;
	
	Possible values:
	-----------------

	a. TO STANDBY: Ready for switchover.
	
	b. SESSIONS ACTIVE: Disconnect users.
	
	c. NOT ALLOWED: Some issue exists.

	Ensure the result is TO STANDBY. If not:
                    ============  
	Close user sessions.
	Ensure log shipping and apply are working.

‚û° 2. Perform Switchover on Primary (Making PRIMARY as new STANDBY)
  ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
	üîπSQL> ALTER DATABASE COMMIT TO SWITCHOVER TO STANDBY WITH SESSION SHUTDOWN;
	
	Then shutdown and mount the database:
	
	üîπSQL> SHUTDOWN IMMEDIATE;
	üîπSQL> STARTUP MOUNT;
	üîπSQL> select name, open_mode, database_role from v$database;
	
		NAME      OPEN_MODE            DATABASE_ROLE
		--------- -------------------- ----------------
		PRIM      MOUNTED              PHYSICAL STANDBY

	üîπSQL> alter database recover managed standby database disconnect from session;

‚û° 3. Perform Switchover on Standby (Making STANDBY as new PRIMARY)
  ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
	Connect to the standby database:

	üîπSQL> SELECT SWITCHOVER_STATUS FROM V$DATABASE;

	Ensure the result is TO PRIMARY.

	üîπSQL> ALTER DATABASE COMMIT TO SWITCHOVER TO PRIMARY WITH SESSION SHUTDOWN;
	üîπSQL> SHUTDOWN IMMEDIATE;
	üîπSQL> STARTUP;
	
	üîπSQL> select name, open_mode, database_role from v$database;
	
		NAME      OPEN_MODE            DATABASE_ROLE
		--------- -------------------- ----------------
		PRIM      READ WRITE           PRIMARY						   
‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ




üìåPERFORMANCE TUNING
---------------------
Optimizing and tuning Oracle databases is essential for ensuring efficient and reliable performance. This article will walk you through key techniques and tools to 
enhance your database‚Äôs performance, using real-world scenarios for better understanding.

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ üü• Sample example execution plan ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

üîπ Step 1: Create the Table
-------------------------------
DROP TABLE employees_demo PURGE;

CREATE TABLE employees_demo (
  emp_id     NUMBER PRIMARY KEY,
  emp_name   VARCHAR2(100),
  department VARCHAR2(50),
  salary     NUMBER
);

üîπ Step 2: Insert Sample Data
--------------------------------
BEGIN
  FOR i IN 1..1000 LOOP
    INSERT INTO employees_demo (emp_id, emp_name, department, salary)
    VALUES (
      i,
      'Employee_' || i,
      CASE
        WHEN MOD(i, 3) = 0 THEN 'IT'
        WHEN MOD(i, 3) = 1 THEN 'HR'
        ELSE 'Finance'
      END,
      3000 + MOD(i, 5000)
    );
  END LOOP;
  COMMIT;
END;
/

üîπ Step 3: Run a Sample Query (this is what we‚Äôll analyze)
-------------------------------------------------------------
-- SAMPLE QUERY:
SELECT emp_name, salary
FROM employees_demo
WHERE department = 'IT';


üîπ Step 4: Generate and View the Execution Plan
-----------------------------------------------
SET LINESIZE 200
SET PAGESIZE 1000
SET TRIMSPOOL ON
SET TRIMOUT ON
SET TAB OFF

EXPLAIN PLAN FOR
SELECT emp_name, salary
FROM employees_demo
WHERE department = 'IT';

===>  Explained.

SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY);

PLAN_TABLE_OUTPUT
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Plan hash value: 1271012197

------------------------------------------------------------------------------------
| Id  | Operation         | Name           | Rows  | Bytes | Cost (%CPU)| Time     |
------------------------------------------------------------------------------------
|   0 | SELECT STATEMENT  |                |   333 | 30636 |     3   (0)| 00:00:01 |
|*  1 |  TABLE ACCESS FULL| EMPLOYEES_DEMO |   333 | 30636 |     3   (0)| 00:00:01 |
------------------------------------------------------------------------------------

Predicate Information (identified by operation id):
---------------------------------------------------

   1 - filter("DEPARTMENT"='IT')

Note
-----
   - dynamic statistics used: dynamic sampling (level=2)


========> Observed that it is taking more time to fetch the query as it is using "TABLE ACCESS FULL" scan operation to search. So now we can take suggestion from 
"SQL Tuning Advisor".


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ üü© SQL Tuning Advisor ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


‚û° 1. Let‚Äôs run a sample query

	SQL> SELECT emp_name, salary FROM employees_demo WHERE department = 'IT';

	üî∏ we will get some output for it.

‚û° 2. Now you might want to know the SQL ID of the above command. 

	SQL> select prev_sql_id from v$session where sid=sys_context('userenv','sid');
	
	PREV_SQL_ID
	-------------
	7tsgp76vwvgm0


‚û° 3. You can check if the sql id returned above is correct by checking the SQL TEXT associated with the sql id

	SQL> select sql_id, sql_text from v$sqltext where sql_id in ('7tsgp76vwvgm0');
	
	SQL_ID        SQL_TEXT
	------------- ---------------------------------------------------------------- 
	7tsgp76vwvgm0 SELECT emp_name, salary FROM employees_demo WHERE department = 'IT'


‚û° 4. Run the SQL Advisor Manually

	DECLARE
		l_sql_tune_task_id VARCHAR2(100);
	BEGIN
		l_sql_tune_task_id := DBMS_SQLTUNE.create_tuning_task (
			sql_id => '7tsgp76vwvgm0',
			scope => DBMS_SQLTUNE.scope_comprehensive,
			time_limit => 500,
			task_name => '7tsgp76vwvgm0_tuning_task11',
			description => 'Tuning task1 for statement 7tsgp76vwvgm0'
		);
		DBMS_OUTPUT.put_line('l_sql_tune_task_id: ' || l_sql_tune_task_id);
	END;
	/
	
	-- Execute the SQL Tuning Task
	EXEC DBMS_SQLTUNE.execute_tuning_task(task_name => '7tsgp76vwvgm0_tuning_task11');
	
	-- Retrieve and Display the Tuning Report
	SET LONG 65536
	SET LONGCHUNKSIZE 65536
	SET LINESIZE 100
	SELECT DBMS_SQLTUNE.report_tuning_task('7tsgp76vwvgm0_tuning_task11') FROM dual;


	üî∏ we get this output

		DBMS_SQLTUNE.REPORT_TUNING_TASK('7TSGP76VWVGM0_TUNING_TASK11')
		----------------------------------------------------------------------------------------------------
		GENERAL INFORMATION SECTION
		-------------------------------------------------------------------------------
		Tuning Task Name   : 7tsgp76vwvgm0_tuning_task11
		Tuning Task Owner  : SYS
		Workload Type      : Single SQL Statement
		Scope              : COMPREHENSIVE
		Time Limit(seconds): 500
		Completion Status  : COMPLETED
		Started at         : 07/25/2025 19:49:37
		Completed at       : 07/25/2025 19:49:38
		
		-------------------------------------------------------------------------------
		Schema Name: SYS
		SQL ID     : 7tsgp76vwvgm0
		SQL Text   : SELECT emp_name, salary
					FROM employees_demo
					WHERE department = 'IT'
		
		-------------------------------------------------------------------------------
		FINDINGS SECTION (1 finding)
		-------------------------------------------------------------------------------
		
		1- Statistics Finding
		---------------------
		Table "SYS"."EMPLOYEES_DEMO" was not analyzed.
		
		Recommendation
		--------------
		- Consider collecting optimizer statistics for this table.
			execute dbms_stats.gather_table_stats(ownname => 'SYS', tabname =>
					'EMPLOYEES_DEMO', estimate_percent =>
					DBMS_STATS.AUTO_SAMPLE_SIZE, method_opt => 'FOR ALL COLUMNS SIZE       <====== Observed that SQL Tuning Advisor Suggesting us to 
					AUTO');																		   gather stats for this sql query and table;
		
		Rationale
		---------
			The optimizer requires up-to-date statistics for the table in order to
			select a good execution plan.
		
		-------------------------------------------------------------------------------
		EXPLAIN PLANS SECTION
		-------------------------------------------------------------------------------
		
		1- Original
		-----------
		Plan hash value: 1271012197
		
		------------------------------------------------------------------------------------
		| Id  | Operation         | Name           | Rows  | Bytes | Cost (%CPU)| Time     |
		------------------------------------------------------------------------------------
		|   0 | SELECT STATEMENT  |                |   333 | 30636 |     3   (0)| 00:00:01 |
		|*  1 |  TABLE ACCESS FULL| EMPLOYEES_DEMO |   333 | 30636 |     3   (0)| 00:00:01 |
		------------------------------------------------------------------------------------
		
		Predicate Information (identified by operation id):
		---------------------------------------------------
		
		1 - filter("DEPARTMENT"='IT')
		
		-------------------------------------------------------------------------------
		
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ üü¶ Gather Stats ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


‚û° 1. Run this query suggested by SQL Tuning Advisor.

	SQL> execute dbms_stats.gather_table_stats(ownname => 'SYS', tabname => 'EMPLOYEES_DEMO', estimate_percent => DBMS_STATS.AUTO_SAMPLE_SIZE, method_opt => 
	'FOR ALL COLUMNS SIZE AUTO');
	
	PL/SQL procedure successfully completed.
	
	üî∏ now check whether the statistics has known about this table or not (i.e check the last analysed date)
	
	SQL> select table_name, to_char(last_analyzed, 'DD-MON-YYYY HH24:MI:SS') from dba_tables where owner='SYS' AND TABLE_NAME = 'EMPLOYEES_DEMO';
	
	TABLE_NAME      TO_CHAR(LAST_ANALYZED,'DD-MON
	--------------- -----------------------------
	EMPLOYEES_DEMO  25-JUL-2025 19:56:28                   <============= Now the statistics has known everything till date about the table.

check objects whose gather statistics is stale

SQL> select owner, index_name, table_name, last_analyzed, stale_stats from dba_ind_statistics where owner='SYS' and stale_stats='YES';


OWNER                INDEX_NAME                          TABLE_NAME                     LAST_ANAL STA
-------------------- ----------------------------------- ------------------------------ --------- ---
SYS                  I_UNDO1                             UNDO$                          03-AUG-25 YES
SYS                  I_UNDO2                             UNDO$                          03-AUG-25 YES
SYS                  I_IND1                              IND$                           03-AUG-25 YES
SYS                  I_H_OBJ#_COL#                       HISTGRM$                       03-AUG-25 YES
SYS                  I_PARTOBJ$                          PARTOBJ$                       03-AUG-25 YES
SYS                  I_CONTAINER1                        CONTAINER$                     03-AUG-25 YES
SYS                  I_CONTAINER2                        CONTAINER$                     03-AUG-25 YES
SYS                  I_CONTAINER3                        CONTAINER$                     03-AUG-25 YES
SYS                  SMON_SCN_TIME_SCN_IDX               SMON_SCN_TIME                  03-AUG-25 YES
SYS                  SMON_SCN_TIME_TIM_IDX               SMON_SCN_TIME                  03-AUG-25 YES
SYS                  I_STATS_TARGET1                     STATS_TARGET$                  03-AUG-25 YES
SYS                  I_STATS_TARGET2                     STATS_TARGET$                  03-AUG-25 YES
SYS                  I_COL_USAGE$                        COL_USAGE$                     03-AUG-25 YES
SYS                  PK_COL_GROUP_USAGE$                 COL_GROUP_USAGE$               03-AUG-25 YES
SYS                  I_MON_MODS_ALL$_OBJ                 MON_MODS_ALL$                  03-AUG-25 YES
SYS                  I_WRI$_OPTSTAT_IND_OBJ#_ST          WRI$_OPTSTAT_IND_HISTORY       03-AUG-25 YES


üéØ Scenario: Employee Management System (Oracle 19c)
You have a table: EMPLOYEES


CREATE TABLE employees (
    emp_id        NUMBER PRIMARY KEY,
    name          VARCHAR2(100),
    department_id NUMBER,
    salary        NUMBER,
    hire_date     DATE
);
üß± Step 1: Index Creation
‚úÖ Oracle Automatically Creates:

-- This creates a primary key, so Oracle creates an index on emp_id
ALTER TABLE employees ADD CONSTRAINT emp_pk PRIMARY KEY (emp_id);
‚úÖ DBA Manually Creates:
Suppose many queries use department_id in the WHERE clause:


-- Manual index to speed up lookups by department
CREATE INDEX idx_emp_dept ON employees(department_id);


üîÅ Step 2: Frequent DML Changes
The employees table is very active:

New hires (INSERTs)

Promotions/Transfers (UPDATEs)

Departures (DELETEs)

This causes:

Index fragmentation

Outdated optimizer statistics


üßπ Step 3: Index Rebuild (After Heavy Changes)
You notice queries are slowing down.
You check fragmentation (via DBA_INDEXES) and see high BLEVEL and clustering factor.

‚úÖ You decide to rebuild the index:


-- Rebuild the index to remove fragmentation
ALTER INDEX idx_emp_dept REBUILD;
Or online (without locking the table):

ALTER INDEX idx_emp_dept REBUILD ONLINE;


üìä Step 4: Gather Statistics (After Rebuild or Data Changes)
After heavy DML or index rebuild, Oracle‚Äôs optimizer needs fresh stats.

‚úÖ You gather statistics on the table and its indexes:


BEGIN
  DBMS_STATS.GATHER_TABLE_STATS(
    ownname  => 'HR',
    tabname  => 'EMPLOYEES',
    cascade  => TRUE -- also gathers stats on indexes
  );
END;
/
This helps Oracle:

Estimate rows

Choose the best query plan

Decide whether to use an index or full table scan

üìå Step 5: Summary of the Process
Step	Action	Why We Do It
1	Create indexes	To speed up queries (on PKs or WHERE columns)
2	Perform DML (INSERT/UPDATE/DELETE)	Regular business operations
3	Rebuild indexes	To fix fragmentation after heavy DML
4	Gather statistics	So Oracle optimizer has accurate data
5	Faster queries	Oracle makes smarter decisions with fresh stats

üîé Bonus: A Common Query Before vs After

-- Common query that benefits from the index
SELECT name FROM employees WHERE department_id = 10;
üê¢ Before index rebuild & stats: May do full table scan.

üöÄ After rebuild & stats: Uses index on department_id, much faster!
‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ


üìåOEM(ORACLE ENTERPRISE MANAGER)
---------------------------------
It is a web-based management tool provided by Oracle to monitor and administer Oracle environments ‚Äî databases, listeners, hosts, ASM, etc.
If any database or server level issue then email is sent by OEM and also the OEM is integrated with the sevicenow so a ticket is generated via oem on service now to us.


                 +---------------------+
                 |     OEM Console     |
                 |  (Web-based GUI)    |
                 +---------------------+
                            ‚¨ÜÔ∏è
                            ‚¨ÜÔ∏è
	            |----------------------------------------------------------------|				
	            |				        SEPERATE NODE FOR OEM					 |
                | +---------------------+		+------------------------------+ |
                | |   Oracle Management | ====>	|  OEM Repository Database     | |
                | |Server (OMS) Software| ====>	|  (Stores monitoring & config)| |
                | +---------------------+		+------------------------------+ |
	            |----------------------------------------------------------------|
                            ‚¨ÜÔ∏è
        +-------------------+-------------------+
        ‚¨ÜÔ∏è                                       ‚¨ÜÔ∏è
        ‚¨ÜÔ∏è                                       ‚¨ÜÔ∏è
+---------------------+                +---------------------+
|   Management Agent  |                |   Management Agent  |
| (Installed on Host) |                | (Installed on Host) |
+---------------------+                +---------------------+
        ‚¨ÜÔ∏è                                       ‚¨ÜÔ∏è
        ‚¨ÜÔ∏è                                       ‚¨ÜÔ∏è
+---------------------+                +---------------------+
|  Target Database /  |                |  Target Database /  |
|    Host Systems     |                |    Host Systems     |
+---------------------+                +---------------------+


üîπ Explanation

OEM Console ‚Äì Web interface to monitor and manage targets.

OMS (Oracle Management Server) ‚Äì Core server processing monitoring and management tasks.

Management Agents ‚Äì Installed on each host to collect data from databases or hosts.

Target Databases / Hosts ‚Äì The actual systems you monitor (Oracle DB, ASM, RAC, etc.).

Repository Database ‚Äì Stores historical performance data, alerts, and configuration info.


‚û°Ô∏è To start OEM

üî∏ Check Listener status.
	=> [oracle@oem ~]# lsnrctl start
üî∏ Login to oem server with oracle user.
	=> [oracle@oem ~]# sqlplus / as sysdba
	
üî∏ First start the repository DB.
	=> startup
	=> alter pluggable database all open; (if the repository DB is a PDB)
	
üî∏ Then start the OMS software.
	=> $OMS_HOME/bin/emctl start oms
	

Database Alert Log Location:
------------------------------
/u01/app/oraclebase/diag/rdbms/prim/prim1/trace/alert_prim1.log

Database Size:
----------------
SQL> SELECT ROUND(SUM(bytes)/1024/1024/1024,2) AS total_db_size_gb
FROM (
  SELECT bytes FROM v$datafile
  UNION ALL
  SELECT bytes FROM v$tempfile
  UNION ALL
  SELECT g.bytes FROM v$log g
);
TOTAL_DB_SIZE_GB
----------------
            4.17
‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ


üìåSRVCTL(Server Control Utility)
-----------
=> To start and stop database using srvctl command.

1. To check database status=>

	üîπ [oracle@node1 ~]$ srvctl status database -d prim
	Instance prim1 is running on node node1
	Instance prim2 is running on node node2

2. To down database and all instance together=>

	üîπ[oracle@node1 ~]$ srvctl stop database -d prim

3. To start particular database instance=>

	üîπ[oracle@node2 ~]$ srvctl start instance -i prim1 -d prim
	üîπ[oracle@node1 ~]$ srvctl start instance -i prim2 -d prim

4. To start database and all instance together=>

	üîπ[oracle@node1 ~]$ srvctl start database -d prim
	
5. To start asm instance=>
	üîπ[oracle@node1 ~]$ srvctl start asm -n node1

6. To check status of Listener

	üîπ[oracle@node1 ~]$ srvctl status listener -l LISTENER
Listener LISTENER is enabled
Listener LISTENER is running on node(s): node2,node1

7. To start Listener=>
	üîπ[oracle@node1 ~]$ srvctl start listener -l LISTENER

8. To stop Listener=>
	üîπ[oracle@node1 ~]$ srvctl stop listener -l LISTENER

9. To put database in mount mode=>

	üîπ[oracle@node1 ~]$ srvctl stop database -d prim
	üîπ[oracle@node1 ~]$ srvctl status database -d prim
Instance prim1 is not running on node node1
Instance prim2 is not running on node node2
	üîπ[oracle@node1 ~]$ srvctl start database -d prim -o mount
	
SQL> select name, open_mode from v$database;

NAME      OPEN_MODE
--------- --------------------
PRIM      MOUNTED

Similarly, to put in nomount or open state first shutdown and then:

	üîπ[oracle@node1 ~]$ srvctl start database -d prim -o nomount
	üîπ[oracle@node1 ~]$ srvctl start database -d prim -o open


üìåCRSCTL(Cluster Ready Services Control Utility)
-----------
=> To start and stop cluster services using crvctl.

1. To stop particular node cluster services
	üîπ[root@node2 ~]# crsctl stop crs -f	(-f -> forcefully)
	To Start
	üîπ[root@node2 ~]# crsctl start crs

2. To stop entire RAC cluster 
	üîπ[root@node2 ~]# crsctl stop cluster -all	(-all -> Both node1, node2 and all services inside it).
	To Start
	üîπ[root@node2 ~]# crsctl start cluster

3. To check status of Clusterware resources
	üîπ[root@node2 ~]# crsctl stat res -t	(-t -> Tabular form)
	
4. To check the health of Clusterware services

	üîπ[root@node1 ~]# crsctl check crs
CRS-4638: Oracle High Availability Services is online
CRS-4537: Cluster Ready Services is online
CRS-4529: Cluster Synchronization Services is online
CRS-4533: Event Manager is online
‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ



üìåSCAN & RAC LISTENER
-----------------------

Request from app server
|
-> It will look for hostname in tnsnames.ora(client side) and get hostname as rac-scan
Now to convert/resolve this rac-scan into IP address DNS server or HOST file(/etc/hosts) will resolve rac-scan name into 1 of 3 ip address present in DNS server in Round Robin.
Further three SCAN_LISTENERS will be created for these three ip address.
SCAN_LISTENERS will use that ip and do load balancing and send request to LOCAL_LISTENER of any respective Nodes. 
{‚ö†Ô∏èNote:- If node 1 is down then all connections will be diverted automatically to other nodes.}
{‚ö†Ô∏èNote:- If we want to connect to particular node then provide the hostname as node1 in tnsnames.ora(client side)}
{‚ö†Ô∏èNote:- If we want to connect to pluggable DB then provide the service name as pdbprim in tnsnames.ora(client side)}

                                                  -------------
												  |ROUND ROBIN|
												  -------------
													   ‚Üª					
		------------------	----------------	|---------------|
		| APP SERVER REQ |	| tnsnames.ora |    | DNS SERVER    |		
        ------------------  ----------------    |---------------|                       LOAD BALANCING ADVISOR
				‚¨á‚¨áÔ∏è				 ‚¨á‚¨áÔ∏è                    ‚¨á‚¨áÔ∏è                                         ‚¨á‚¨áÔ∏è		
				
			----------		------------        -----------------		                        		    ------------------
			| user 1 |---->	| RAC_SCAN | =====> | SCAN IP       |		|-----------------|     |---|       | LOCAL_LISTENER |
			----------      ------------        | 192.168.56.91 |-----> | SCAN_LISTENER 1 |     | L |       |     NODE 1     |
												|               |       |-----------------|     |   |       ------------------			
												|---------------|                               | B |       			
			----------		------------        |               |                               |   |       ------------------
			| user 2 |----> | RAC_SCAN | =====> | SCAN IP       |		|-----------------|     | A |       | LOCAL_LISTENER |
			----------      ------------        | 192.168.56.92 |-----> | SCAN_LISTENER 2 |     |   |       |     NODE 2     |
												|               |       |-----------------|     |   |       ------------------			
												|---------------|                               |   |       			
			----------		------------        |               |                               |   |       ------------------
			| user 3 |----> | RAC_SCAN | =====> | SCAN IP       |		|-----------------|     |   |       | LOCAL_LISTENER |
			----------      ------------        | 192.168.56.93 |-----> | SCAN_LISTENER 3 |     |   |       |     NODE 3     |
												|               |       |-----------------|     | L |       ------------------ 			
                                                |---------------|                               |   |                   
																								| B |       ------------------			
																								|   |       | LOCAL_LISTENER |
																								| A |       |     NODE 4     |
																								|---|       ------------------
			                                                                                                
‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ



üìåRMAN_RAC
-----------

1. Put database in archive logmode.
2. The RMAN backup taken on RAC environment should be stored inside common storage of both nodes i.e a common diskgroup.
3. Set common archive log destination.
	SQL> alter system set log_archive_dest_1='location=+FRA' scope=both;
4. Create a diskgroup +FRA using asmcmd.

‚úÖBYDEFAULT DIFFERENTIAL

RUN
	{
	  ALLOCATE CHANNEL ch11 TYPE DISK MAXPIECESIZE 10G;
	  ALLOCATE CHANNEL ch12 TYPE DISK MAXPIECESIZE 10G;
	  ALLOCATE CHANNEL ch13 TYPE DISK MAXPIECESIZE 10G;
	  BACKUP
	  FORMAT '/u01/rman/%d_D_%T_%u_s%s_p%p'
	  INCREMENTAL LEVEL 1 DATABASE
	  CURRENT CONTROLFILE
	  FORMAT '/u01/rman/%d_C_%T_%u'
	  SPFILE
	  FORMAT '/u01/rman/%d_S_%T_%u'
	  PLUS ARCHIVELOG
	  FORMAT '/u01/rman/%d_A_%T_%u_s%s_p%p';
	  RELEASE CHANNEL ch11;
	  RELEASE CHANNEL ch12;
	  RELEASE CHANNEL ch13;
	}

‚úÖ TO MAKE CUMULATIVE

RUN
	{
	  ALLOCATE CHANNEL ch11 TYPE DISK MAXPIECESIZE 10G;
	  ALLOCATE CHANNEL ch12 TYPE DISK MAXPIECESIZE 10G;
	  ALLOCATE CHANNEL ch13 TYPE DISK MAXPIECESIZE 10G;
	  BACKUP
	  FORMAT '/u01/rman/%d_D_%T_%u_s%s_p%p'
	  INCREMENTAL LEVEL 1 CUMULATIVE DATABASE
	  CURRENT CONTROLFILE
	  FORMAT '/u01/rman/%d_C_%T_%u'
	  SPFILE
	  FORMAT '/u01/rman/%d_S_%T_%u'
	  PLUS ARCHIVELOG
	  FORMAT '/u01/rman/%d_A_%T_%u_s%s_p%p';
	  RELEASE CHANNEL ch11;
	  RELEASE CHANNEL ch12;
	  RELEASE CHANNEL ch13;
	}
	
‚úÖ Now to store the RMAN backup on shared location and splitting the channel on both nodes.

RUN
	{
	  ALLOCATE CHANNEL c1 TYPE DISK CONNECT 'sys/oracle@prim1';
	  ALLOCATE CHANNEL c2 TYPE DISK CONNECT 'sys/oracle@prim1';
	  ALLOCATE CHANNEL c3 TYPE DISK CONNECT 'sys/oracle@prim2';
	  ALLOCATE CHANNEL c4 TYPE DISK CONNECT 'sys/oracle@prim2';
	  BACKUP
	  FORMAT '+DATA/PRIM/RMAN/FULL_%d_D_%T_%u_s%s_p%p'
	  INCREMENTAL LEVEL 0 DATABASE
	  CURRENT CONTROLFILE
	  FORMAT '+DATA/PRIM/RMAN/FULL_%d_C_%T_%u'
	  SPFILE
	  FORMAT '+DATA/PRIM/RMAN/FULL_%d_S_%T_%u'
	  PLUS ARCHIVELOG
	  FORMAT '+DATA/PRIM/RMAN/FULL_%d_A_%T_%u_s%s_p%p';
	  RELEASE CHANNEL c1;
	  RELEASE CHANNEL c2;
	  RELEASE CHANNEL c3;
	  RELEASE CHANNEL c4;
	}
RUN {
	ALLOCATE CHANNEL c1 TYPE DISK CONNECT 'sys/oracle@prim1';
	BACKUP CURRENT CONTROLFILE FORMAT '+DATA/PRIM/RMAN/FULL_%d_C_%T_%U';
	RELEASE CHANNEL c1;
  }
  
  
üìåRMAN_RESTORATION_RAC
------------------------

üî∏ First of all, make sure the clusterware is Up and Running.

[grid@node1 ~]# crsctl check crs
[grid@node1 ~]# crsctl status resource -t

ASMCMD [+] > ls -ld +DATA
State    Type    Rebal  Name
MOUNTED  EXTERN  N      DATA/

üî∏ Make sure that we have a backup set of the database.

[oracle@node1 rman]$ ll
total 2715244
-rw-r-----. 1 oracle asmadmin 126724096 Sep 29 20:05 FULL_PRIM_A_20250929_3m44tnjv_s118_p1
-rw-r-----. 1 oracle asmadmin 117346816 Sep 29 20:05 FULL_PRIM_A_20250929_3n44tnk0_s119_p1
-rw-r-----. 1 oracle asmadmin  22060032 Sep 29 20:05 FULL_PRIM_A_20250929_3o44tnk0_s120_p1
-rw-r-----. 1 oracle asmadmin  13993984 Sep 29 20:05 FULL_PRIM_A_20250929_3p44tnk1_s121_p1
-rw-r-----. 1 oracle asmadmin   9806336 Sep 29 20:05 FULL_PRIM_A_20250929_3q44tnk3_s122_p1
-rw-r-----. 1 oracle asmadmin      6656 Sep 29 20:05 FULL_PRIM_A_20250929_4644tnks_s134_p1
-rw-r-----. 1 oracle asmadmin      4608 Sep 29 20:05 FULL_PRIM_A_20250929_4744tnks_s135_p1
-rw-r-----. 1 oracle asmadmin  20086784 Sep 29 20:05 FULL_PRIM_C_20250929_4444tnkm
-rw-r-----. 1 oracle asmadmin 826540032 Sep 29 20:05 FULL_PRIM_D_20250929_3r44tnk7_s123_p1
-rw-r-----. 1 oracle asmadmin 455729152 Sep 29 20:05 FULL_PRIM_D_20250929_3s44tnk7_s124_p1
-rw-r-----. 1 oracle asmadmin   9076736 Sep 29 20:05 FULL_PRIM_D_20250929_3t44tnk7_s125_p1
-rw-r-----. 1 oracle asmadmin 264290304 Sep 29 20:05 FULL_PRIM_D_20250929_3u44tnk7_s126_p1
-rw-r-----. 1 oracle asmadmin 256163840 Sep 29 20:05 FULL_PRIM_D_20250929_3v44tnkc_s127_p1
-rw-r-----. 1 oracle asmadmin 238002176 Sep 29 20:05 FULL_PRIM_D_20250929_4044tnkf_s128_p1
-rw-r-----. 1 oracle asmadmin 229629952 Sep 29 20:05 FULL_PRIM_D_20250929_4144tnkh_s129_p1
-rw-r-----. 1 oracle asmadmin  99090432 Sep 29 20:05 FULL_PRIM_D_20250929_4244tnkk_s130_p1
-rw-r-----. 1 oracle asmadmin  91717632 Sep 29 20:05 FULL_PRIM_D_20250929_4344tnkl_s131_p1
-rw-r-----. 1 oracle asmadmin    114688 Sep 29 20:05 FULL_PRIM_S_20250929_4544tnkm


üî∏ Now restore the spfile to temp location

RMAN> restore spfile to '/tmp/spfileprim.ora' from '/u01/rman/FULL_PRIM_S_20250929_4544tnkm';

üî∏ Shutdown database
SQL> shu immediate;
SQL> exit

Create pfile from spfile
RMAN> create pfile from spfile='/tmp/spfileprim.ora';

üî∏ It will be created at oraclehome dbs location.
[oracle@node1 dbs]$ ls initprim.ora
initprim.ora

üî∏ start database in nomount with the pfile.
[oracle@node1 dbs]$ sqlplus / as sysdba
SQL> startup nomount pfile='initprim.ora';

üî∏ Now restore control file
RMAN> restore controlfile from '/u01/rman/FULL_PRIM_C_20250929_4444tnkm';

Now the controlfile will automatically get restored in +DATA diskgroup as the location specified in pfile as we started database with pfile.

üî∏ start database in mount with the controlfile.
SQL> startup mount
SQL> exit

üî∏ Now create spfile from pfile
RMAN> create spfile='+DATA/PRIM/spfilePRIM.ora' from pfile='/u01/app/oracle/product/19c/dbhome/dbs/initprim.ora';

üî∏ Now we have to start our database with spfile which is in +DATA diskgroup but when we hit startup the database will start with the spfile present in oracle 
home dbs, so we will rename our pfile 'initprim.ora' to 'initprim.ora_bkp' and create new pfile with parameter spfile='+DATA/PRIM/spfilePRIM.ora' and start
the database with this new file so that it knows the location of the spfile in +DATA diskgroup.

üî∏ shutdown and start database in mount.
SQL> shu immediate;
SQL> startup mount

üî∏ Now recover datafile and archive log files, but before that do catalogue start so that rman knows from where to restore the backup.

RMAN> catalogue start with '/u01/rman/';

RMAN> restore database;

RMAN> recover database

üî∏ Now open database in reset logs.

RMAN> alter database open resetlogs;
RMAN> exit

üî∏ Now since ebverything is done node 1 so to inform node 2 about this restoration.
ADD DATABASE TO CLUSTER and Add rac Instanses
[oracle@node1 dbs]$ srvctl add database -d prim -o $ORACLE_HOME
[oracle@node1 dbs]$ srvctl add instance -d prim -i prim1 -n node1
[oracle@node1 dbs]$ srvctl add instance -d prim -i prim2 -n node2

[oracle@node1 dbs]$ srvctl config database -d PRIM

üî∏ Now acknowledge the config file about location of spfile
[oracle@node1 dbs]$ srvctl modify database -d prim -spfile +DATA/PRIM/spfileprim.ora

üî∏ Now create password file

[oracle@node1 dbs]$ orapwd file='+DATA' dbuniquename='prim' password=oracle
‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ


üìåRAC_PATCH
---------------

[oracle@node1 dbhome]$ $ORACLE_HOME/OPatch/opatch version
OPatch Version: 12.2.0.1.29

Prechecks
Check Patch Conflict

$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/patches/33509923/33515361
 
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/patches/33509923/33529556
 
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/patches/33509923/33534448
 
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/patches/33509923/33239955
 
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/patches/33509923/33575402


Stop clusterware services
$ORACLE_HOME/crs/install/rootcrs.sh -prepatch

Apply the patch on GRID HOME

$ORACLE_HOME/OPatch/opatch apply -oh $ORACLE_HOME -local -silent /u01/patches/33509923/33515361
$ORACLE_HOME/OPatch/opatch apply -oh $ORACLE_HOME -local -silent /u01/patches/33509923/33529556
$ORACLE_HOME/OPatch/opatch apply -oh $ORACLE_HOME -local -silent /u01/patches/33509923/33534448
$ORACLE_HOME/OPatch/opatch apply -oh $ORACLE_HOME -local -silent /u01/patches/33509923/33239955
$ORACLE_HOME/OPatch/opatch apply -oh $ORACLE_HOME -local -silent /u01/patches/33509923/33575402

Apply the patch on ORACLE_HOME

$ORACLE_HOME/OPatch/opatch apply -oh $ORACLE_HOME -local -silent /u01/patches/33509923/33515361
$ORACLE_HOME/OPatch/opatch apply -oh $ORACLE_HOME -local -silent /u01/patches/33509923/33529556


[grid@node1 ~]$ $ORACLE_HOME/OPatch/opatch lspatches
33575402;DBWLM RELEASE UPDATE 19.0.0.0.0 (33575402)
33239955;TOMCAT RELEASE UPDATE 19.0.0.0.0 (33239955)
33534448;ACFS RELEASE UPDATE 19.14.0.0.0 (33534448)
33529556;OCW RELEASE UPDATE 19.14.0.0.0 (33529556)
33515361;Database Release Update : 19.14.0.0.220118 (33515361)


Start the clusterware services on Node 1
$ORACLE_HOME/crs/install/rootcrs.sh -postpatch
‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ



üìåCACHE FUSION
---------------
üî∏ Without Cache Fusion:

	If Node 1 modifies a data block, and Node 2 needs the same block,

	Node 2 would have to read it from disk ‚Äî which is slow.

üî∏ What Cache Fusion Does

	Cache Fusion ‚Äúfuses‚Äù all buffer caches from the cluster into one logical global cache. Instead of reading from disk:

	Global Cache Service (GCS) and Global Enqueue Service (GES) coordinate:

	GCS knows which node has the current block version.

	Node 1 sends the latest version directly to Node 2 via interconnect(high-speed private network) , not disk directly from one instance‚Äôs memory to another.

	This inter-node block transfer keeps all nodes synchronized and improves performance dramatically.
	
	Global Cache Service (GCS) and Global Enqueue Service (GES) coordinate through the Global Resource Directory (GRD) ‚Äî a distributed in-memory directory that tracks which 
	instance holds each data block and its current state (Shared, Exclusive, or Invalid).

	GCS checks the GRD to know which node currently owns the latest version of the requested block.
	
| Component | Full Form              | Purpose                                                        |
| --------- | ---------------------- | -------------------------------------------------------------- |
| **GCS**   | Global Cache Service   | Manages **data block access and transfer** between instances.  |
| **GES**   | Global Enqueue Service | Manages **locks and enqueues** for all other shared resources. |

üî∏ Example Scenario:

	Instance 1 has a data block in Exclusive mode.

	Instance 2 wants to read or modify that block.

	Instance 2 asks GES (via LMD) for permission.

	GES checks GRD to see who owns it ‚Üí finds Instance 1.

	GCS (via LMS) coordinates block transfer from Instance 1 ‚Üí Instance 2.

	GRD is updated with the new ownership and state.

‚úÖ Result: Both instances stay consistent without disk I/O.
‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ


üìåVOTING DISK
---------------
Voting Disk is a special file in Oracle RAC that stores the heartbeat information of all cluster nodes and helps determine which nodes are part of the active cluster.

Number of Voting Disks:	Typically 3 voting disks (odd number for majority voting) ‚Äî can be stored in Oracle ASM for redundancy.
Location: Usually stored on shared storage accessible by all nodes (ASM disk group, shared file system, or raw devices).
Function: Each node writes a heartbeat to the voting disk at regular intervals. If a node fails to update its heartbeat, Clusterware marks it as dead and evicts it to 
		  protect data consistency.

üîπ Example Scenario

In a 3-node RAC cluster with 3 voting disks:
Each node writes its heartbeat to all 3 disks every few seconds.
If Node 2 stops responding, the other nodes detect the missing heartbeat and vote to evict Node 2 from the cluster.

Two types of heartbeats :-
 1) Network Heartbeat for communication between nodes. CSSD [Cluster Synchronization Services (CSS) daemon]process present on each node to communicate with other node for its 
    presence via heartbeat.
 2) Disc Heartbeat for communication between node and voting disk.

üîπ Firstly voting disk was present in +DATA diskgroup itself

üîπ QUERY to check number of Voting Disks.

	[grid@node1 ~]$ crsctl query css votedisk
##  STATE    File Universal Id                File Name Disk group
--  -----    -----------------                --------- ---------
 1. ONLINE   71abe2761e014fd2bfb98be537c2126a (/dev/oracleasm/disks/DISK1) [DATA]
Located 1 voting disk(s).

üîπ So we create new disks for our new diskgroup +VD

	[root@node2 ~]# fdisk -l

üîπ FORMAT THEM

	[root@node2 ~]# fdisk /dev/sdf
	[root@node2 ~]# fdisk /dev/sdg
	[root@node2 ~]# fdisk /dev/sdh

üîπ REGISTER THEM

	oracleasm createdisk DISK5 /dev/sdf1
	oracleasm createdisk DISK6 /dev/sdg1
	oracleasm createdisk DISK7 /dev/sdh1

üîπ CALL ASMCA and add those disks to +VD DISKGROUP.

üîπ Now since previously voting disk was present in +DATA diskgroup now we will replace it with +VD DISKGROUP

	[grid@node2 ~]$ crsctl replace votedisk +VD
Successful addition of voting disk ce12e9840b774ffabfbcf59a5d34a1e8.
Successful addition of voting disk 408a654e235e4f16bf72e91cd131cc12.
Successful addition of voting disk 645ab6d010084f09bf688d5a0ba63c43.
Successful deletion of voting disk 71abe2761e014fd2bfb98be537c2126a.
Successfully replaced voting disk group with +VD.
CRS-4266: Voting file(s) successfully replaced
	[grid@node2 ~]$
	[grid@node2 ~]$ crsctl query css votedisk
##  STATE    File Universal Id                File Name Disk group
--  -----    -----------------                --------- ---------
 1. ONLINE   ce12e9840b774ffabfbcf59a5d34a1e8 (/dev/oracleasm/disks/DISK5) [VD]
 2. ONLINE   408a654e235e4f16bf72e91cd131cc12 (/dev/oracleasm/disks/DISK6) [VD]
 3. ONLINE   645ab6d010084f09bf688d5a0ba63c43 (/dev/oracleasm/disks/DISK7) [VD]
Located 3 voting disk(s).



üîπ Multiple Voting Disks

	Oracle recommends 3 or 5 voting disks spread across different storage paths.

	This ensures that even if one disk or one storage fails, the cluster can still function.

üîπ Quorum Requirement

	Cluster membership requires a majority of voting disks to be accessible.

	Example: If you have 3 voting disks:

	2 disks must be online to form quorum

	1 disk fails ‚Üí cluster still works

	2 disks fail ‚Üí cluster cannot form quorum ‚Üí nodes evicted

üîπ Quorum is the minimum number of voting disks or nodes required for the cluster to function safely.
‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ




üìåOLR (Oracle Local Registry) & OCR (Oracle Cluster Registry)                               
---------------------------------------------------------------

üß© 1. When the RAC node starts (boot time)
	The first Oracle service to start is OHASD (Oracle High Availability Service Daemon).  
	But at this point, ASM disks (shared storage) are not yet mounted,
	so the node can‚Äôt read the OCR (which is on shared storage).
‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è
‚öôÔ∏è 2. OHASD reads OLR (Local file)

	OLR = Oracle Local Registry
	‚Üí it‚Äôs a small local file stored on every RAC node.
	It has basic info like:

	üîπ Where ASM is installed, How to start ASM, Network info, etc. 

‚úÖ Using OLR, Oracle can start ASM and basic cluster services.
‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è
üíø 3. ASM starts ‚Üí shared storage becomes available

	Once ASM is up, now the node can see shared disks.

	These disks contain:

	üîπ OCR (Oracle Cluster Registry)

	üîπ Voting Disk
‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è	
üìñ 4. Oracle reads OCR

	OCR = Oracle Cluster Registry
	‚Üí it has full cluster configuration, like:

	üîπ Databases, Listeners, VIPs, Services, (basically everything about your RAC setup).

‚úÖ OCR is shared by all nodes and keeps the cluster in sync.
‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è	
üöÄ 5. Cluster fully starts

	Using OCR, Oracle starts:

	CRSD daemon (Cluster Ready Service Daemon)

Now the RAC cluster is fully up and running üéâ
‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è‚¨á‚¨áÔ∏è	
‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ‚ùñ



üìåADD NODE
---------------

1. Install the linux on new machine, download the prerequisites using yum installer.
2. Do entry in the etc/hosts file of the new node as well as previuos nodes.

127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
#Public
192.168.56.71 node1.learnomate.org node1
192.168.56.72 node2.learnomate.org node2
192.168.56.73 node3.learnomate.org node3 --------- new
#Private
192.168.10.1 node1-priv.learnomate.org node1-priv
192.168.10.2 node2-priv.learnomate.org node2-priv
192.168.10.3 node3-priv.learnomate.org node3-priv --------- new
# Virtual
192.168.56.81 node1-vip.learnomate.org node1-vip
192.168.56.82 node2-vip.learnomate.org node2-vip
192.168.56.83 node2-vip.learnomate.org node3-vip --------- new
#SCAN (in production this should be configured in DNS)
192.168.56.91 node-scan.learnomate.org node-scan
192.168.56.92 node-scan.learnomate.org node-scan
192.168.56.93 node-scan.learnomate.org node-scan

3. Create Directories for oracle and grid and set bash profile. Set oracle and asm instance as prim3 and +ASM3

4. Install all asm packages and configure asm on node3.

5. Now attach the shareable asm disks to node3.

6. Now no need to install again the grid software or the database software automatically the softwares and the files will be shared from node1, node2 to the node3
   via the private ips but for that there should be password less connection for grid and oracle users of other nodes and node3.
   
7. ./sshUserSetup.sh -user grid -hosts ‚Äúnode1 node2 node3‚Äù -noPromptPassphrase -confirm -advanced --------- run from either node1 or node2 (deinstall folder inside grid home).

8. Run gridSetup.sh from node1 or node2

	=> Add more node to cluster.
	=> Add public and virtual hostname of new node3 for ssh passwordless connectivity with the new node3.
	=> Root.sh will run.
	=> Install finish.
	
9. After node addition, for database software to know about newly added node run below script.

cd $ORACLE_HOME/addnode
 
./addnode.sh "CLUSTER_NEW_NODES={node3}" [from any one node (node 1 or 2) to put DB software on node 3]

	=> select node 3
	=> set ssh connectivity for node 3 (oracle user) run from node 1.
	./sshUserSetup.sh -user oracle -hosts ‚Äúnode1 node2 node3‚Äù -noPromptPassphrase -confirm -advanced --------- run from either node1 or node2 (deinstall folder inside oracle home).
	=> Root.sh will run.
	=> Install Finish.

10. Add the instance on node using dbca utility (on any existing node)
	cd $ORACLE_HOME/bin
	./dbca 
	
	=> Oracle RAC database instance management
	=> Add an instance
	=> Select the database "prim"
	=> instance name as prim3 on node3
	=> Install Finish.
Instance successfully added.


üìåREMOVE NODE
---------------

1. Remove the instance on node using dbca utility (on any existing node)
	cd $ORACLE_HOME/bin
	./dbca
	
	=> Oracle RAC database instance management
	=> Delete an instance
	=> Select the database "prim"
	=> instance name as prim3 on node3
	=> Delete Finish.
Instance successfully deleted.
	
2. Go to node 3 and run deinstall. (Will delete oracle software and oracle home on node 3)
	[oracle@node3 ~]# cd $ORACLE_HOME/deinstall
	[oracle@node3 ~]# ./deinstall -local
	
	{‚ö†Ô∏èNote:- Specify the ‚Äú-local‚Äù flag as not to remove more than just the local node‚Äôs software.}
	
3. Deinstall grid infrastructure home of node3 from any existing node with grid user.
	[grid@node2 ~]# cd $ORACLE_HOME/
	[grid@node2 ~]# ./gridSetup.sh
	
	=> Remove node from the cluster.
	=> select node to remove grid "node 3"
	=> Root.sh will run.
	=> Deinstall Finish.

